sentence,np,vp,ner_rich
"IBM Services  White Paper
","['IBM Services White Paper']
","[] 
",0
"Beyond the hype:   A guide to understanding and  successfully implementing artificial  intelligence within your business
","['hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"2     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"Contents  2 Introduction
","['Contents', 'Introduction']
","[] 
",0
" 3 What is AI?
","['AI']
","[] 
",0
" 5 How does an AI system learn?
","['How AI system learn']
","[] 
",0
" 5 What has driven the development of AI?
","['driven development AI']
","[] 
",0
" 7 Where are we today with AI?
","['today AI']
","[] 
",0
" 8 What are the areas in which AI provides the most   value today?
","['areas', 'value today']
","['AI provides'] 
",0
" 8 What are some examples of successful implementations?
","['successful implementations']
","['examples'] 
",0
" 9 Best practices to successfully implement   AI within an organization
","['practices', 'implement AI', 'organization']
","[] 
",0
" 11  Pitfalls of AI implementation
","['Pitfalls AI implementation']
","[] 
",0
"14 Summary
","[]
","[] 
",0
"15 IBM Services
","['IBM']
","[] 
",0
"18 About the authors
","['authors']
","[] 
",0
"18 Acknowledgements
","['Acknowledgements']
","[] 
",0
" 18 Appendix
","['Appendix']
","[] 
",0
"Introduction To implement AI within your organization successfully you  need to understand what AI is, where it currently stands,  what value can provide to businesses and how it can be  successfully adopted.
","['Introduction', 'AI', 'organization', 'need understand AI', 'value', 'businesses']
","['implement', 'currently stands', 'provide', 'successfully adopted'] 
",1
"This white paper is written for  business leaders looking for practical advice on how to  leverage artificial intelligence (AI) for their organizations.
","['This white paper', 'business leaders', 'practical advice leverage', 'artificial intelligence', 'AI', 'organizations']
","['written', 'looking'] 
",1
"The fact that AI has been hyped doesn’t take away from its  capabilities as a real value driver.
","['The fact AI', '’', 'capabilities', 'real value driver']
","['hyped', 'take'] 
",1
"Heavy investments have  been made in AI across multiple industries; the Chinese  government even made it one of their core sectors.
","['Heavy investments', 'AI', 'multiple industries', 'Chinese government', 'core sectors']
","['made', 'even made'] 
",1
"And  companies like IBM, Microsoft, Google and Amazon are  leading the pack when it comes to utilizing data and AI.
","['companies', 'IBM', 'Microsoft', 'Google Amazon', 'pack', 'utilizing data AI']
","['leading', 'comes'] 
",1
"AI provides enormous amounts of value in multiple  industries.
","['AI', 'enormous amounts value multiple industries']
","['provides'] 
",0
"Because of its high value potential, many  companies have been scrambling to implement AI within  their organizations.
","['high value potential', 'many companies', 'implement AI', 'organizations']
","['scrambling'] 
",0
"And the projects, when implemented  properly, have shown significant returns and improved  competitive edge.
","['projects', 'significant returns', 'competitive edge']
","['implemented', 'shown', 'improved'] 
",1
"If your company hasn’t started  implementing AI, it may lag behind its competitors, so it’s  critical to evaluate what AI can do for your organization.
","['company ’', 'AI', 'competitors', '’', 'critical evaluate AI organization']
","['started implementing', 'lag'] 
",1
"But this doesn’t mean you should hire data scientists or  acquiring data science solutions without a clear strategy.
","['’ mean hire data scientists', 'data science solutions', 'clear strategy']
","['acquiring'] 
",0
"Implementing AI should be a carefully thought out process.
","['AI', 'process']
","['Implementing', 'carefully thought'] 
",1
"Otherwise it may turn out to be a costly failure.
","['costly failure']
","['turn'] 
",0
"The authors of this paper want to provide you with the  knowledge you need to evaluate what type of AI solutions you  can implement to give your company a competitive advantage.
","['The authors paper', 'knowledge need', 'type AI solutions', 'give company', 'competitive advantage']
","['want', 'evaluate', 'implement'] 
",1
"IBM Services     3
","['IBM']
","['Services'] 
",0
"What is AI?
","['AI']
","[] 
",0
"When people hear AI they often think about sentient  robots and magic boxes.
","['people', 'AI', 'sentient robots', 'magic boxes']
","['hear', 'often think'] 
",1
"AI today is much more mundane  and simple—but that doesn’t mean it’s not powerful.
","['AI today', 'mundane simple—but ’ mean ’']
","[] 
",0
"Another misconception is that high-profile research  projects can be applied directly to any business situation.
","['Another misconception', 'high-profile research projects', 'business situation']
","['applied'] 
",0
"AI done right can create extreme return on investments  (ROIs)—for instance through automation or precise  prediction.
","['AI', 'right create', 'extreme return investments', 'ROIs', 'instance automation precise prediction']
","['done', '—for'] 
",1
"But it does take thought, time and proper  implementation.
","['thought', 'time', 'proper implementation']
","['take'] 
",0
"We have seen that success and value  generated by AI projects is increased when there is a  grounded understanding and expectation of what the  technology can deliver from the C-suite down.
","['success value', 'AI projects', 'grounded understanding expectation technology', 'C-suite']
","['seen', 'generated', 'increased'] 
",1
"We are now at the brink of the fourth Industrial Revolution.
","['fourth Industrial Revolution']
","['brink'] 
",0
"AI is one of the biggest facets of this revolution, and it  will affect almost all sectors, as did previous Industrial  Revolutions.1 AI’s abilities have increased significantly  since its inception in 1955; it can now detect patterns  more accurately, continuously and based on more data.
","['AI', 'facets revolution', 'sectors', 'previous Industrial Revolutions.1 AI ’ abilities', 'inception', 'detect patterns', 'data']
","['affect', 'increased', 'continuously based'] 
",1
"Currently, AI has surpassed human intelligence in some  specific domains.
","['AI', 'human intelligence', 'specific domains']
","['surpassed'] 
",0
"These domains can be split in three  categories: general tasks, formal tasks and expert tasks.
","['These domains', 'categories', 'general tasks', 'formal tasks', 'expert tasks']
","['split'] 
",0
"General tasks could include visual recognition, speech  recognition, natural language processing and translation.
","['General tasks', 'visual recognition', 'speech recognition', 'natural language processing translation']
","['include'] 
",0
"Formal tasks are related to games where some theorem  and learning is involved.
","['Formal tasks', 'games']
","['related', 'learning involved'] 
",1
"And expert tasks are those that  would otherwise be executed by a domain expert.
","['expert tasks', 'domain expert']
","['otherwise executed'] 
",0
"(Think  of tasks such as diagnosing disease and engineering.2)
","['tasks', 'disease engineering.2']
","['Think', 'diagnosing'] 
",1
"As already stated, AI was first named in 1955 and was  defined as the ability of machines to perform human-like  tasks.
","['AI', 'defined ability machines', 'human-like tasks']
","['already stated', 'first named', 'perform'] 
",1
"The term has gained popularity ever since its first  mention.
","['The term', 'popularity', 'first mention']
","['gained'] 
",0
"However, there is still quite a bit of confusion about  the difference between AI, machine learning and deep  learning—but simply stated, AI encompasses the latter two.
","['bit confusion difference AI', 'machine', 'deep learning—but', 'AI']
","['learning', 'simply stated', 'encompasses'] 
",1
"AI
","['AI']
","[] 
",0
"Artificial intelligence A program that can sense, reason,
","['Artificial intelligence', 'A program sense', 'reason']
","[] 
",0
"act and adapt.
","['act adapt']
","[] 
",0
"Machine learning Algorithms whose performance improve
","['Machine', 'Algorithms', 'performance improve']
","['learning'] 
",0
"as they are exposed to more data over time.
","['data time']
","['exposed'] 
",0
"Deep learning Subset of machine learning in
","['Deep learning Subset machine learning']
","[] 
",0
"which multipayered neutral  networks learn from  vast amount of data.
","['neutral networks', 'vast amount data']
","['multipayered', 'learn'] 
",1
"Figure 1: The distinction between AI, Machine Learning and Deep Learning.
","['Figure', 'The distinction AI', 'Machine Learning Deep Learning']
","[] 
",0
"“Artificial Intelligence (AI) is a science and a set of  computational technologies that are inspired by—but  typically operate quite differently from—the ways people  use their nervous systems and bodies to sense, learn,  reason and take action.”3 Lately there has been a big rise in  the day-to-day use of machines powered by AI.
","['“ Artificial Intelligence', 'AI', 'science', 'computational technologies', 'by—but', 'from—the ways people', 'nervous systems bodies sense', 'learn', 'reason', 'action.', 'big rise', 'day-to-day use machines', 'AI']
","['set', 'inspired', 'use', 'take', 'powered'] 
",1
"These  machines are wired using cross-disciplinary approaches  based on mathematics, computer science, statistics,  psychology and more.4 Virtual assistants are becoming  more common, most of the web shops predict your  purchases, many companies make use of chatbots in their  customer service and many companies use algorithms to  detect fraud.
","['These machines', 'cross-disciplinary approaches', 'mathematics', 'computer science', 'statistics', 'psychology more.4', 'Virtual assistants', 'web shops', 'purchases', 'many companies', 'use chatbots customer service', 'many companies', 'algorithms detect fraud']
","['wired using', 'based', 'becoming', 'predict', 'make', 'use'] 
",1
"These are just a few of the examples of how  AI is used every day.
","['These examples', 'every day']
","['AI used'] 
",0
"4     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"Machine learning  Machine learning is enabling a machine to learn from data  without explicitly programming it with rules, because it can  learn from the data it’s given.
","['Machine', 'Machine', 'machine learn data', 'rules', 'data ’']
","['learning', 'learning enabling', 'explicitly programming', 'learn', 'given'] 
",1
"In essence, you could build  an AI consisting of many different rules and it would also be  able to be AI.
","['essence', 'AI', 'many different rules', 'able AI']
","['build', 'consisting'] 
",1
"But instead of programming all the rules, you  feed the algorithm data and let the algorithm adjust itself to  improve the accuracy of the algorithm.
","['programming rules', 'algorithm data let algorithm', 'accuracy algorithm']
","['feed', 'adjust improve'] 
",1
"Traditional science  algorithms mainly process, whereas machine learning is  about applying an algorithm to fit a model to the data.
","['Traditional science algorithms', 'process', 'machine', 'algorithm fit model data']
","['learning applying'] 
",0
"Examples of machine-learning algorithms that are used a  lot and that you might be familiar with are decision trees,  random forest, Bayesian networks, K-mean clustering,  neural networks, regression, artificial neural networks,  deep learning and reinforcement learning.
","['Examples', 'machine-learning algorithms', 'lot', 'familiar decision trees', 'Bayesian networks', 'K-mean clustering', 'neural networks', 'regression', 'artificial neural networks', 'deep learning reinforcement learning']
","['used'] 
",0
"Artificial neural  networks and deep learning have recently become more  common machine learning algorithms.
","['Artificial neural networks', 'common machine', 'algorithms']
","['deep learning', 'recently become', 'learning'] 
",1
"Implementation examples would be predicting stock market  prices or predicting whether a customer will churn from  your company.
","['Implementation examples', 'stock market prices', 'customer churn company']
","['predicting', 'predicting'] 
",1
"Deep learning  Deep learning (DL) is a relatively new set of methods that  is changing machine learning in fundamental ways.
","['Deep', 'Deep learning', 'DL', 'methods', 'machine', 'fundamental ways']
","['learning', 'set', 'changing', 'learning'] 
",1
"DL isn’t  an algorithm per se, but rather a family of algorithms that  implements deep networks (many layers).
","['DL ’', 'se', 'family', 'algorithms implements', 'deep networks', 'many layers']
","[] 
",0
"These networks  are so deep that new methods of computation, such as  graphics processing units (GPUs), are required to train  them, in addition to clusters of compute nodes.
","['These networks', 'new methods computation', 'graphics', 'units', 'GPUs', 'train', 'addition clusters', 'nodes']
","['deep', 'processing', 'required', 'compute'] 
",1
"DL works very well with large amounts data, and whenever   a problem is too complex to understand and engineer  features (due to unstructured data, for instance).
","['DL', 'large amounts data', 'problem', 'complex understand engineer features', 'data', 'instance']
","['works', 'unstructured'] 
",1
"DL almost  always outperforms the other types of algorithms when it  comes to image classification, natural language processing  and speech recognition.
","['DL', 'types', 'image classification', 'natural language processing speech recognition']
","['almost always outperforms', 'algorithms comes'] 
",1
"An example would be recognizing  melanoma or conducting machine translation, which was  not possible using previous techniques.
","['An example', 'melanoma', 'machine translation', 'previous techniques']
","['recognizing', 'conducting', 'using'] 
",1
"Figure 2: Deep neural network with five layers.5
","['Figure', 'Deep neural network', 'layers.5']
","[] 
",0
"Currently, the larger the neural network and the more data  that can be added to it, the better the performance a neural  network can provide.
","['neural network data', 'performance', 'neural network provide']
","['added'] 
",0
"DL is very powerful, but it has a couple  of drawbacks.
","['DL', 'couple drawbacks']
","[] 
",0
"It’s almost impossible to determine why the  system came to a certain conclusion.
","['impossible determine system', 'certain conclusion']
","['’', 'came'] 
",1
"This is called the  “black box” problem, though there are now many available  techniques that can increase insights in the inner workings   of the DL model.
","['“ black box ” problem', 'many available techniques', 'insights', 'inner workings DL model']
","['called', 'increase'] 
",1
"Also, deep learning often requires extensive  training times, a lot of data and specific hardware  requirements, and it’s not easy to acquire the specific  skills needed to develop a new DL solution to a problem.
","['deep learning', 'extensive training times', 'lot data specific hardware requirements', '’', 'specific skills', 'new DL solution problem']
","['often requires', 'acquire', 'needed develop'] 
",1
"In conclusion, there is no one algorithm that can fit or solve  all problems.
","['conclusion', 'algorithm fit solve problems']
","[] 
",0
"Success really depends on the problem you  need to solve and the data you have available.
","['Success', 'problem need', 'data']
","['really depends', 'solve'] 
",1
"Sometimes   a problem will need a hybrid approach, where you use  multiple algorithms to solve the problem.
","['problem need', 'hybrid approach', 'multiple algorithms', 'problem']
","['use', 'solve'] 
",1
"Each problem  requires extensive investigation of what constitutes a  best-fit type of algorithm.
","['Each problem', 'extensive investigation', 'best-fit type algorithm']
","['requires', 'constitutes'] 
",1
"You should take into account  transparency and how much data, capabilities and time  you have, because some algorithms take a long time to run.
","['much data', 'capabilities time', 'algorithms', 'long time run']
","['take account', 'take'] 
",1
"Input layer
","['Input layer']
","[] 
",0
"Hidden  layer 1
","['Hidden layer']
","[] 
",0
"Hidden layer 2
","['Hidden layer']
","[] 
",0
"Hidden layer 3
","['Hidden layer']
","[] 
",0
"Output layer
","['Output layer']
","[] 
",0
"IBM Services     5
","['IBM']
","['Services'] 
",0
"How does an AI system learn?
","['AI system learn']
","[] 
",0
"To illustrate how AI system learning works, we’ll next  describe what a data scientist does, and what a machine  does in the process of developing AI solutions.
","['AI system', 'works', '’', 'next describe data scientist', 'machine process', 'AI solutions']
","['illustrate', 'learning', 'developing'] 
",1
"Later, when  we discuss the pitfalls of implementing AI, we’ll explain  what types of skills you’ll need to successfully build a data  science team.
","['pitfalls', 'AI', '’', 'types skills', 'data science team']
","['discuss', 'implementing', 'explain', '’ need', 'successfully build'] 
",1
"Data scientist The data scientist extracts knowledge and interprets data  by using the right tools and statistical methods6.
","['Data scientist', 'The data scientist extracts', 'interprets', 'right tools', 'statistical methods6']
","['knowledge', 'data using'] 
",1
"The data  scientist first helps identify data-analytics problems.
","['The data scientist', 'data-analytics problems']
","['first helps identify'] 
",0
"Next,  he or she defines defines the right algorithm and tools.
","['defines defines', 'tools']
","['right algorithm'] 
",0
"He or she cleans the data and collects the correct data for  the problem.
","['data collects', 'data problem']
","['cleans', 'correct'] 
",1
"The next step is to define hyperparameters  and engineer the features in a way that it fits the model.
","['The next step define hyperparameters', 'features way', 'model']
","['engineer', 'fits'] 
",1
"After the model provides output the data scientist analyzes  and identifies patterns and trends.
","['model', 'output data scientist', 'identifies patterns trends']
","['provides'] 
",0
"Then the data scientist  communicates the results to the stakeholders.
","['data scientist communicates results stakeholders']
","[] 
",0
"Machine The machine learns to recognize patterns in the data   that it is fed to it, and then maps these patterns to future  outcomes.
","['Machine', 'The machine', 'patterns data fed', 'maps', 'future outcomes']
","['learns recognize', 'patterns'] 
",1
"The machine learns through adjusting the  weights and biases in the network from feedback to get to  the correct outcome.
","['The machine', 'weights', 'network feedback get', 'correct outcome']
","['learns adjusting', 'biases'] 
",1
"This feedback must come from a  trainer—the data scientist.
","['This feedback', 'trainer—the data scientist']
","['come'] 
",0
"The data scientist tells the  model what should happen and what shouldn’t happen.
","['The data scientist tells', 'happen ’ happen']
","['model'] 
",0
"This correction is then sent back through the network and  an error rate is computed.
","['This correction', 'network error rate']
","['sent', 'computed'] 
",1
"With each iteration, the model  works to decrease the error rate.
","['iteration', 'model works', 'error rate']
","['decrease'] 
",0
"In the appendix section of this paper, we have a section  that addresses the different types of algorithms’ learning.
","['appendix section paper', 'section addresses', 'different types', '’ learning']
","['algorithms'] 
",0
"There are four main types of learning; supervised,  unsupervised, transferred and reinforcement learning.
","['main types', 'transferred reinforcement learning']
","['learning', 'supervised'] 
",1
"While unsupervised, reinforcement and transfer learning  show great potential, supervised learning is currently the  type that can provide the highest economic value.
","['reinforcement transfer', 'economic value']
","['learning show', 'learning currently type provide'] 
",1
"What has driven the development of AI?
","['development AI']
","['driven'] 
",0
"With increasing computing power and more data, the  potential value of algorithms became higher.
","['power data', 'potential value algorithms']
","['increasing computing', 'became'] 
",1
"People and  companies saw possibilities to embed these smart systems  into their companies to drive strategy and innovation.
","['People companies', 'possibilities', 'smart systems companies', 'strategy innovation']
","['saw', 'embed', 'drive'] 
",1
"As  the power of algorithms, computing and amounts of data  increased companies started to see an increasing amount  of use cases.
","['power algorithms', 'amounts data', 'companies', 'amount use cases']
","['computing', 'increased', 'started see increasing'] 
",1
"AI started to become an essential value.
","['AI', 'essential value']
","['started become'] 
",0
"Companies saw that these systems could move them closer  to their customers, drive efficiency, enhance employee  experience and capability, automatize tasks, decrease  costs and improve revenue.
","['Companies', 'systems', 'customers', 'drive efficiency', 'employee experience capability', 'tasks', 'decrease costs', 'revenue']
","['saw', 'move', 'enhance', 'automatize', 'improve'] 
",1
"But AI went through some lulls and spikes before it became  capable of enabling so many benefits.
","['AI', 'lulls spikes', 'many benefits']
","['went', 'became', 'enabling'] 
",1
"At a certain point the  general public gave up on AI and machine learning as a whole,  which stalled developments and investments.
","['certain point', 'AI machine', 'stalled developments investments']
","['gave', 'learning'] 
",1
"For instance,  when Defense Advanced Research Projects Agency (DARPA)  worked together with Carnegie Mellon to implement speech  recognition for their pilots, they cut the project in 1974 after  having spent millions of dollars on it.
","['instance', 'Defense Advanced Research', 'Agency', 'DARPA', 'Carnegie Mellon implement speech recognition pilots', 'project', 'spent millions dollars']
","['worked', 'cut'] 
",1
"From the 1960s to 1974,  the main funding for AI came from governments.
","['main funding AI', 'governments']
","['came'] 
",0
"But after  1974 there was barely any government funding because
","['government funding']
","[] 
",0
"6     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"of multiple failed AI projects, so the belief in the feasibility of  AI declined.
","['multiple', 'AI projects', 'belief feasibility AI']
","['failed', 'declined'] 
",1
"But after this period, improvements in efficiency  lead to successful business cases, once again proving  value.
","['period', 'improvements', 'lead successful business cases', 'value']
","['efficiency', 'proving'] 
",1
"Today we now see AI as one of the big value drivers  for companies, and to compete most companies must adopt  AI strategies.
","['Today', 'AI', 'big value drivers companies', 'compete companies', 'AI strategies']
","['see', 'adopt'] 
",1
"Three topics have made AI available for many  companies right now:
","['topics', 'AI', 'available many companies']
","['made', 'right'] 
",1
" — The evolution of data: A factor contributing to the  massive adoption of AI is the exponential growth of  available data.
","['The evolution data', 'A factor', 'massive adoption AI', 'exponential growth', 'available data']
","['contributing'] 
",0
"With the introduction of the Internet,  social media, proliferation of sensors and smart devices,  and the fact that data storage became cheaper, it became  more accessible than ever before.
","['introduction Internet', 'social media', 'proliferation sensors', 'smart devices', 'fact data storage']
","['became', 'became'] 
",1
" — The evolution of algorithms: Algorithms have been  around since we could write.
","['The evolution algorithms', 'Algorithms']
","['write'] 
",0
"Recently, the development  of more advanced algorithms has helped AI become  more powerful and efficient.
","['development', 'algorithms', 'AI']
","['advanced', 'helped', 'become'] 
",1
" — The evolution of computing: Another major factor in  AI’s current success is its computing power.
","['The evolution computing', 'Another major factor AI ’', 'current success', 'power']
","['computing'] 
",0
"Back when  AI was just beginning to be developed, the computing  power was minimal.
","['AI beginning', 'power minimal']
","['developed', 'computing'] 
",1
"Computers nowadays can take much  more data and heavier algorithms than in the 1950s.
","['Computers nowadays', 'much data']
","['take'] 
",0
"These developments would not have taken place without  significant investments and proven business value.
","['These developments', 'place', 'significant investments', 'business value']
","['taken'] 
",0
"Figure 3: AI timeline.7
","['Figure', 'AI timeline.7']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"●
","['●']
","[] 
",0
"Turing publishes the Turing-test.
","['publishes Turing-test']
","['Turing'] 
",0
"“The point at which a machine  has answers like a human”
","['The point machine answers', 'human ”']
","['“'] 
",0
"AI first named by John McCarthy
","['AI', 'John McCarthy']
","['first named'] 
",0
"“First” AI algorithm Logic Theorist by Simon and Newell
","['“ First ” AI', 'Logic Theorist Simon Newell']
","['algorithm'] 
",0
"Rosenblatt invents the first self learning algorithm with  the perceptron
","['Rosenblatt invents', 'algorithm perceptron']
","['first self learning'] 
",0
"IBM 305, the first hard drive, 5 MB
","['IBM', 'hard drive', 'MB']
","[] 
",0
"Backpropagation, one of the most important areas of a neural  network, is proposed
","['Backpropagation', 'important areas', 'neural network']
","['proposed'] 
",0
"IBM 1330, 100MB
","['IBM']
","[] 
",0
"Intel produces second generation general purpose chips First AI winter, the belief in machine learning and AI had dropped  after multiple unsuccessful experiments combined with insufficient  computing power, network capabilities and database capacity
","['Intel', 'second generation', 'general purpose chips First AI winter', 'belief machine', 'AI', 'multiple unsuccessful experiments', 'power', 'network capabilities', 'capacity']
","['produces', 'learning', 'dropped', 'combined', 'computing', 'database'] 
",1
"IBM 0665 hard drive, 40 MB.
","['IBM', 'hard drive', 'MB']
","[] 
",0
"But much smaller than the 1330
","[]
","[] 
",0
"First convolutional neural network developed  (used a lot in image recognition)
","['First', 'convolutional neural network', 'lot image recognition']
","['developed', 'used'] 
",1
"The internet is open for the public
","['The internet', 'open public']
","[] 
",0
"First versions of  natural language solutions set up.
","['First versions', 'natural language solutions']
","['set'] 
",0
"IBM’s deep blue defeats Kasparov in Chess
","['IBM ’', 'deep blue defeats Kasparov Chess']
","[] 
",0
"Google’s Page rank is published
","['Google ’ Page rank']
","['published'] 
",0
"The adoption of Internet by the masses
","['The adoption Internet masses']
","[] 
",0
"Amazon brings cloud computing to the masses
","['Amazon', 'cloud computing masses']
","['brings'] 
",0
"Google develops an algorithm that can handle large amounts  of data faster.
","['Google', 'algorithm handle large amounts data']
","['develops'] 
",0
"Stanford Robot drives automatically
","['Stanford Robot']
","['drives'] 
",0
"IBM introduces Watson.
","['IBM introduces Watson']
","[] 
",0
"A question answering machine that  later wins from a Jeopardy champion
","['A question', 'machine', 'Jeopardy champion']
","['answering', 'later wins'] 
",1
"Worldwide IP traffic exceeds 20 exabytes (20 billion gigabytes) per month
","['Worldwide IP traffic', 'exabytes', 'gigabytes', 'month']
","['exceeds'] 
",0
"Facebook gets a billion users
","['Facebook', 'users']
","['gets'] 
",0
"There are more mobile devices than humans in the world
","['mobile devices humans world']
","[] 
",0
"Project debater of IBM shows ability to process very large data  sets, including millions of news articles across dozens of subjects,  and then turn snippets of arguments into full flowing prose—a  challenging task for a computer
","['Project debater IBM', 'ability process', 'large data sets', 'millions news articles', 'dozens subjects', 'snippets arguments', 'prose—a', 'task computer']
","['shows', 'including', 'turn', 'flowing', 'challenging'] 
",1
"1950
","[]
","[] 
",0
"1955
","[]
","[] 
",0
"1956
","[]
","[] 
",0
"1957
","[]
","[] 
",0
"1958
","[]
","[] 
",0
"1969
","[]
","[] 
",0
"1970
","[]
","[] 
",0
"1974
","[]
","[] 
",0
"1974-1980
","[]
","[] 
",0
"1985
","[]
","[] 
",0
"1989
","[]
","[] 
",0
"1991
","[]
","[] 
",0
"1992
","[]
","[] 
",0
"1997
","[]
","[] 
",0
"1998
","[]
","[] 
",0
"2000
","[]
","[] 
",0
"2002
","[]
","[] 
",0
"2004
","[]
","[] 
",0
"2005
","[]
","[] 
",0
"2006
","[]
","[] 
",0
"2010
","[]
","[] 
",0
"2012
","[]
","[] 
",0
"2014
","[]
","[] 
",0
"2018
","[]
","[] 
",0
"IBM Services     7
","['IBM']
","['Services'] 
",0
"Where are we today with AI?
","['today AI']
","[] 
",0
"We can split the term AI into three categories: general,  broad and narrow.
","['term AI', 'categories', 'broad narrow']
","['split'] 
",0
"General AI encompasses all the human- like capabilities, whereas narrow AI can only do a certain  task—and it can do it quite well—but narrow AI can’t  transfer its knowledge to different sorts of problems.
","['General AI', 'human-', 'capabilities', 'whereas', 'AI', 'certain task—and', 'well—but narrow AI ’ transfer knowledge', 'different sorts problems']
","['encompasses', 'narrow'] 
",1
"Narrow AI Narrow AI is focused on addressing very focused tasks  (such as buying a book with a voice-based device) based  on “common knowledge.” That’s the reason narrow AI is  scaling very quickly in the consumer world where there are  a lot of common tasks and data to train these systems.
","['Narrow AI Narrow AI', 'focused tasks', 'book', 'voice-based device', '“ common knowledge. ”', 'reason', 'narrow AI', 'consumer world lot', 'common tasks data', 'systems']
","['focused addressing', 'buying', 'based', '’', 'scaling'] 
",1
"Narrow or weak AI is, contrary to the naming, very powerful   at routine jobs.
","['Narrow', 'weak AI', 'contrary naming', 'powerful routine jobs']
","[] 
",0
"Figure 4: The three categories of AI.
","['Figure', 'categories AI']
","[] 
",0
"Narrow
","['Narrow']
","[] 
",0
"2010-2015
","[]
","[] 
",0
"Broad   (AI for Enterprise)
","['Broad', 'AI Enterprise']
","[] 
",0
"We are here
","[]
","[] 
",0
"General AI
","['General AI']
","[] 
",0
"2050 and beyond
","[]
","[] 
",0
"Broad AI What we see today in self driving cars is still defined as narrow  AI.
","['Broad AI', 'today', 'cars', 'narrow AI']
","['see', 'driving', 'still defined'] 
",1
"You can see it as a collection of narrow AI systems that  make decisions.
","['systems', 'decisions']
","['see', 'make'] 
",1
"This is what we call broad AI.
","['This call', 'broad AI']
","[] 
",0
"Another  example of broad AI includes a system within a bank that  analyzes the balance sheet of corporate customers to  recommend the best currency hedging strategy.
","['Another example', 'broad AI', 'system', 'bank', 'analyzes balance sheet', 'corporate customers', 'currency', 'strategy']
","['includes', 'recommend', 'hedging'] 
",1
"Another  example would be a system that supports engineers who  work on complex maintenance tasks on a platform in the  middle of the Atlantic Ocean.
","['Another example', 'system', 'engineers', 'complex maintenance tasks', 'middle Atlantic Ocean']
","['supports', 'work', 'platform'] 
",1
"Broad AI is about integrating  AI within a specific business process of an enterprise where  you need business- and enterprise-specific knowledge and  data to train this type of system.
","['Broad AI', 'AI', 'specific business process enterprise', 'business- enterprise-specific knowledge data', 'type system']
","['integrating', 'need', 'train'] 
",1
"These tasks are very different  from the narrow AI used in the consumer world because the  data and knowledge available in the enterprise are much more  limited in terms of volumes, very industry specific and in most  of the cases private (for example owned by an enterprise).
","['These tasks', 'different narrow AI', 'consumer world data knowledge', 'limited terms volumes', 'industry', 'specific cases', 'example', 'enterprise']
","['used', 'owned'] 
",1
"This is what we believe is currently the most valuable type of  AI currently for the enterprise.
","['valuable type AI']
","['believe', 'currently enterprise'] 
",1
"General AI General AI is far from reaching its potential.
","['General AI General AI']
","['far reaching'] 
",0
"The expectations  are that it will take at least another couple of decades.
","['The expectations', 'another couple decades']
","['take'] 
",0
"General  AI refers to machines that can perform any intellectual task  a human can.
","['General AI refers machines', 'intellectual task human']
","['perform'] 
",0
"Currently AI does not have the ability to think  abstractly, strategize and use previous experiences to come  up with new creative ideas as humans do.
","['AI ability', 'previous experiences', 'new creative ideas humans']
","['think', 'strategize use', 'come'] 
",1
"Some people think we will have general AI in a couple of  decades others like IBM’s Rob High and Google’s Peter Norvig  believe we don’t need broad AI at all.8
","['Some people', 'general AI couple decades others', 'IBM ’ Rob High Google ’ Peter Norvig', '’', 'broad AI all.8']
","['think', 'believe', 'need'] 
",1
"8     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"What are the areas in which AI provides  the most value today?
","['areas', 'value today']
","['AI provides'] 
",0
"While relevant AI use cases span various areas across  virtually every industry, there are three main macro domains  that continue to drive the adoption as well as the most  economies across businesses.
","['relevant AI use cases', 'various areas', 'every industry', 'main macro domains', 'drive adoption', 'businesses']
","['span', 'continue', 'well economies'] 
",1
"They are:
","[]
","[] 
",0
" — Cognitive engagement: Involves how to deliver new ways  for humans to engage with machines, moving from pure  digital experiences (such as the ability to run transactions  digitally) into human-like natural conversations.
","['Cognitive engagement', 'new ways humans', 'machines', 'pure digital experiences', 'ability', 'transactions', 'human-like natural conversations']
","['Involves deliver', 'engage', 'moving', 'run'] 
",1
" — Cognitive insights and knowledge: Addresses how to  augment humans who are overwhelmed with information  and knowledge.
","['Cognitive insights knowledge', 'Addresses', 'humans', 'overwhelmed information knowledge']
","['augment'] 
",0
" — Cognitive automation: Relates to how to move from process  automation to mimicking human intelligence to facilitate  complex and knowledge-intense business decisions.
","['Cognitive automation', 'Relates', 'process automation', 'human intelligence facilitate', 'complex knowledge-intense business decisions']
","['move', 'mimicking'] 
",1
"What are some examples of successful  implementations?
","['successful implementations']
","['examples'] 
",0
"There’s a vast amount of problems AI is already addressing  to deliver business value across the three macro domains  described in the previous section.
","['’', 'vast amount problems AI', 'deliver business value', 'macro domains', 'previous section']
","['already addressing', 'described'] 
",1
"We want to explain   a couple of use cases our IBM team has successfully  completed to demonstrate where AI can bring value.
","['explain couple use cases IBM team', 'demonstrate AI bring value']
","['want', 'successfully completed'] 
",1
"Manufacturer: engine anomaly detection using   a neural network  Using the many different available sensor measurements  from large truck engines, a neural network was trained to  recognize normal and abnormal engine behavior.
","['Manufacturer', 'engine anomaly detection', 'neural network', 'many different available sensor measurements', 'large truck engines', 'neural network', 'normal abnormal engine behavior']
","['using', 'Using', 'trained recognize'] 
",1
"In the  huge, high dimensional (many variables) dataset the  neural network learned the natural correlations and  relationships between all different readings.
","['high dimensional', 'many variables', 'neural network', 'natural correlations', 'different readings']
","['dataset', 'learned', 'relationships'] 
",1
"The resulting
","[]
","['resulting'] 
",0
"model was able to predict “normal” values given certain  operating conditions and could thus also be used to detect  when specific measurements were out of the ordinary.
","['model', 'able predict “', 'normal ” values', 'certain operating conditions', 'detect', 'specific measurements']
","['given', 'thus also used'] 
",1
"Anomalous sensor readings are highly predictive of  pending engine failures.
","['Anomalous sensor readings', 'engine failures']
","['pending'] 
",0
"Car manufacturer: predictive failure detection for welding  robots and predictive maintenance assessment Through supervised learning techniques, predictive models  were developed that could provide an early warning of  failure based on the different system messages and sensor  readings that continuously stream from the production line.
","['Car manufacturer', 'predictive failure detection', 'robots', 'predictive maintenance assessment', 'learning techniques', 'predictive models', 'early warning failure', 'different system messages', 'readings', 'stream production line']
","['welding', 'supervised', 'developed', 'provide', 'based', 'sensor'] 
",1
"This early warning could be used to prioritize maintenance  and reduce both downtime as well as false positives and  needless efforts.
","['This early warning', 'maintenance', 'downtime', 'false positives', 'needless efforts']
","['used prioritize', 'reduce'] 
",1
"Working through this first proof of value,  the data scientists uncovered many data quality challenges  that could be worked around to realize more value.
","['proof value', 'data scientists', 'many data quality challenges', 'value']
","['Working', 'uncovered', 'worked', 'realize'] 
",1
"Figure 5: The most valuable AI implementations.
","['Figure', 'The valuable AI implementations']
","[] 
",0
"Designing and  delivering new
","[]
","['Designing delivering'] 
",0
"customer engagement
","['customer engagement']
","[] 
",0
"Cognitive   engagement
","['Cognitive engagement']
","[] 
",0
"Elevating and   scaling knowledge
","['knowledge']
","['Elevating scaling'] 
",0
"and expertise
","['expertise']
","[] 
",0
"Cognitive   insights &
","['Cognitive insights']
","[] 
",0
"knowledge
","['knowledge']
","[] 
",0
"Designing and  delivering agility and  operational efficiency
","['agility operational efficiency']
","['Designing delivering'] 
",0
"Cognitive   automation
","['Cognitive automation']
","[] 
",0
"IBM Services     9
","['IBM']
","['Services'] 
",0
"Utility company: micro-grid energy forecasting and  production mix optimization The output of machine learning-based predictive models  with prescriptive, mathematical optimization models to  prescribe the optimal mix of power production sources to  meet predicted demand and to minimize costs.
","['Utility company', 'micro-grid energy', 'production mix optimization', 'The output machine', 'learning-based predictive models', 'mathematical optimization models', 'optimal mix power production sources', 'predicted demand minimize costs']
","['forecasting', 'prescriptive', 'prescribe'] 
",1
"This required  both the prediction of demand as well as prediction of  available solar and wind energy capacity.
","['This required prediction demand', 'prediction', 'available solar wind energy capacity']
","[] 
",0
"Material producer: insights dashboard IBM worked with the client’s sourcing experts to understand  the business dynamics and create inventory of possibly  relevant data sources.
","['Material producer', 'insights', 'IBM', 'client ’', 'experts', 'business dynamics', 'inventory', 'relevant data sources']
","['dashboard', 'worked', 'sourcing', 'understand', 'create'] 
",1
"Several machine learning models  were then trained to learn the price behavior and forecast  future price development.
","['Several machine', 'models', 'learn price behavior forecast', 'future price development']
","['learning', 'trained'] 
",1
"The models also enabled  buyers to evaluate their own “what if” scenarios.
","['The models', 'buyers', '“ ” scenarios']
","['also enabled', 'evaluate'] 
",1
"This was  further supplemented with IBM® Watson Discovery News  service, which identified the most relevant news articles  related to the material of interest.
","['IBM® Watson Discovery News service', 'relevant news articles', 'material interest']
","['supplemented', 'identified', 'related'] 
",1
"This all came together  for the user in an interactive dashboard to consume the  insights and interact with the data and models to make  buying decisions.
","['user interactive dashboard consume insights', 'interact data models', 'buying decisions']
","['came', 'make'] 
",1
"Best practices to successfully   implement AI within an organization  Let’s discuss what you need to do before implementing AI.
","['practices', 'implement AI', 'organization Let ’', 'AI']
","['discuss', 'implementing'] 
",1
"Currently, many companies are scrambling to implement AI  within their environments because they believe it will keep  them ahead of the game—which, if thought through, is the  case.
","['many companies', 'implement AI', 'environments', 'case']
","['scrambling', 'believe keep', 'thought'] 
",1
"But here are a few steps you need to take.
","['steps']
","['need take'] 
",0
"We’ve defined three main steps to implement AI in your  company.
","['main steps', 'implement AI company']
","['’ defined'] 
",0
"These steps are:
","['These steps']
","[] 
",0
" — Develop an AI strategy and roadmap  — Establish AI capabilities and skills  — Start small and scale quickly
","['— Develop AI strategy roadmap — Establish AI capabilities', '— Start', 'small scale']
","['skills'] 
",0
"Develop an AI strategy and roadmap First, it’s important to understand AI and to research what  it can and can’t do for your organization.
","['Develop AI strategy roadmap First', '’', 'important understand AI research ’ organization']
","[] 
",0
"You can get more  familiar with AI by collaborating with a data scientist, because  it’s important that the C-level has a good understanding of   AI and its implementation difficulties before they define  where and how to implement.
","['familiar AI', 'data scientist', '’ important C-level', 'good understanding AI implementation difficulties', 'implement']
","['get', 'collaborating', 'define'] 
",1
"What often happens if AI  is not holistically understood the overall project won’t  provide value.
","['AI', 'overall project ’', 'value']
","['often happens', 'holistically understood'] 
",1
"Once AI is understood, the next question you should ask  yourself is: “What specific problem do I want to solve, or what  opportunity do I want to take?” Is your company looking to  drive efficiency in the back office, differentiate its digital  proposition, generate new revenue streams by leveraging  customers’ insights or even reinvent its entire business?
","['AI understood', 'next question ask', 'specific problem', 'solve', 'opportunity', '”', 'company', 'drive efficiency', 'office', 'digital proposition', 'new revenue streams', 'customers', 'insights', 'entire business']
","['“', 'want', 'want take', 'Is', 'looking', 'differentiate', 'generate', 'leveraging', '’', 'even reinvent'] 
",1
"10     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"After having thought this through, you’ll probably have  many different use cases.
","['’', 'many different use cases']
","['thought'] 
",0
"At this point, it’s critical to  prioritize these cases into a transformation roadmap that  covers both a long-term vision as well as concrete feasible  quick wins.
","['point', '’', 'critical prioritize cases transformation roadmap', 'long-term vision', 'concrete feasible quick wins']
","['covers'] 
",0
"Next, you should think about what data you  have available.
","['data']
","['think'] 
",0
"To solve most of the problems with AI you  need to have relevant data.
","['problems AI', 'relevant data']
","['solve', 'need'] 
",1
"Without data, AI will not provide  any value.
","['data', 'AI', 'value']
","[] 
",0
"For many companies it’s a task in and of itself  to keep track of the type of data—as well as where it’s  stored and in what way.
","['many companies', 'track type data—as', 'stored way']
","['’', 'keep'] 
",1
"Often the first step will be to  understand the data you currently have and the type you  need to implement your AI case.
","['Often', 'first step', 'implement AI case']
","['understand data', 'need'] 
",1
"Establish AI capabilities and skills AI requires a completely new set of capabilities and skills  which may be in short supply in your organization.
","['Establish AI capabilities', 'AI', 'capabilities skills', 'supply organization']
","['skills', 'requires', 'set', 'short'] 
",1
"To build  the required in-house AI skills, it’s important to plan,  establish and grow a dedicated Center of Competence or  leverage the IBM Garage concept to perform in partnership.
","['in-house AI skills', 'important plan', 'grow', 'Center Competence leverage IBM Garage concept perform partnership']
","['build required', 'establish', 'dedicated'] 
",1
"Not only this dedicated team is important, but you also  need to assure the right mindset and way of working in the  rest of the organization.
","['team', 'right mindset way', 'rest organization']
","['Not dedicated', 'also need', 'working'] 
",1
"It’s critical that these functions  occur in conjunction with developing and integrating an AI  platform within your current IT architecture to implement  and scale AI.
","['critical functions', 'conjunction', 'AI platform', 'current IT architecture implement scale AI']
","['’', 'occur', 'developing integrating'] 
",1
"Start small and scale quickly  — Start with minimal valuable products (MVPs)   In this phase you want to bring in experts to help quickly  develop solutions to your business problems.
","['Start', 'small scale', '— Start minimal', 'valuable products', 'MVPs', 'phase', 'bring experts', 'solutions business problems']
","['want', 'help quickly develop'] 
",1
"This can  only be done once the before-mentioned steps are  completed and the business is ready organizationally  and technologically.
","['before-mentioned steps', 'business']
","['done', 'completed'] 
",1
"This also means that the experts  you bring in should be both business and technologically  savvy.
","['experts', 'business']
","['also means', 'bring'] 
",1
"A good duration for a MVP is normally between two  and three months.
","['A good duration MVP', 'months']
","[] 
",0
"Our experience shows that starting  with large-scale, complex and very long AI implementation  projects normally lead to failure.
","['experience', 'AI implementation projects', 'lead failure']
","['shows starting'] 
",0
" — Set understandable key performance indicators (KPIs)  To make sure that a project will succeed, you need to  define KPIs that are understandable for your business— including employees and other stakeholders.
","['— Set', 'understandable key performance indicators', 'KPIs', 'sure project', 'KPIs', 'understandable business—', 'employees stakeholders']
","['make', 'succeed', 'define', 'including'] 
",1
"These KPIs  will help you evaluate whether a project is successful.
","['These KPIs help', 'project']
","['evaluate'] 
",0
"In  general, we suggest taking a second look at these KPIs  after an appropriate duration to decide whether the  project is successful or if you should discontinue it.
","['second look KPIs', 'appropriate duration', 'project', 'successful discontinue']
","['suggest taking'] 
",0
"If  your business can’t pinpoint the right KPIs to measure  success, the project is too complex.
","['business', 'pinpoint right KPIs measure success', 'project complex']
","['’'] 
",0
" — Roll-out through company (culture)  Once agreement is reached about which projects would  be worth working on, it’s time to implement the MVP  within your company.
","['— Roll-out company', 'culture', 'agreement', 'projects', '’ time', 'implement MVP', 'company']
","['reached', 'worth working'] 
",1
"It’s important that the way you  implement it is looked at from both the business and  the technical side.
","['important way implement', 'business', 'technical side']
","['looked'] 
",0
"IBM Services     11
","['IBM']
","['Services'] 
",0
"Pitfalls of AI implementation With the experience of implementing many of these   cases we normally see a couple of problems organizations  have when implementing AI.
","['Pitfalls AI implementation', 'experience', 'many cases', 'couple problems organizations', 'AI']
","['implementing', 'normally see', 'implementing'] 
",1
"We’ve listed them because  we feel it’s important to know what you should consider  when implementing AI.
","['feel', 'important know', 'AI']
","['’ listed', 'consider implementing'] 
",1
"Culture Pitfalls: Looking at the advances we’ve made over the last  decade, gathering data is easy.
","['Culture Pitfalls', 'advances', 'last decade', 'data']
","['Looking', '’ made', 'gathering'] 
",1
"But it’s what’s done with  the data that provides the most value.
","['’ ’', 'data', 'value']
","['done', 'provides'] 
",1
"The biggest pitfall  we often encounter is a culture that’s not committed to  making data-driven decisions.
","['pitfall', 'encounter culture ’', 'data-driven decisions']
","['committed making'] 
",0
"Examples are cultures that  can’t innovate in an agile fashion or can’t leave room for  trial and error, as are cultures that have traditionally been  unwilling to transform a process.
","['Examples cultures', 'innovate agile fashion ’', 'room trial error', 'unwilling transform process']
","['’', 'leave', 'cultures'] 
",1
"This reluctance usually  has to do with fear of job loss, skepticism or a knowledge  gap.
","['This reluctance', 'fear job loss', 'skepticism knowledge gap']
","[] 
",0
"It’s a challenge to get your organization ready to  embrace a data-driven culture, and for many of your  employees it can feel like a counter intuitive process.
","['challenge get organization', 'ready embrace', 'data-driven culture', 'many employees', 'counter', 'intuitive process']
","['’', 'feel'] 
",1
"Recommendation: Digital change management, training  and preparation for the shift in thinking is required.
","['Recommendation', 'Digital change management', 'preparation shift thinking']
","['training', 'required'] 
",1
"You  should start with small wins that are visible for relevant  departments.
","['small wins', 'visible relevant departments']
","['start'] 
",0
"The business users should be your starting  point for agile development and in your design thinking  process.
","['The business users', 'point agile development design', 'process']
","['starting', 'thinking'] 
",1
"All the results that come out of the project should  be measurable; this way you can easily show your wins.
","['All results', 'project', 'way', 'wins']
","['come', 'easily show'] 
",1
"Then, for a data-driven culture to take hold, the whole  organization must embrace it.
","['data-driven culture take hold', 'whole organization']
","['embrace'] 
",0
"The message must be clear  for all employees: “Decision are made based on data.”
","['The message', 'employees', '“ Decision', 'data', '”']
","['clear', 'made based'] 
",1
"Building trust within the company Pitfalls: This step is often overlooked, but when you want  to implement AI you need get project stakeholders involved  and on board.
","['Building trust', 'company Pitfalls', 'This step', 'implement AI need get project stakeholders', 'board']
","['often overlooked', 'want', 'involved'] 
",1
"In Design Thinking, IBM starts with the  business and its users.
","['Design Thinking', 'IBM', 'business users']
","['starts'] 
",0
"A data scientist will require domain  knowledge and access to data, and the stakeholders should  accommodate this need to help to speed up the process.
","['A data scientist require domain knowledge access data', 'stakeholders', 'need', 'process']
","['accommodate', 'help speed'] 
",1
"Also, consider the need for AI education and devote time  to considering the right user interface.
","['need AI education devote time', 'right user interface']
","['considering'] 
",0
"Recommendation: Use a form of change management to  establish user adoption.
","['Recommendation', 'Use form change management', 'user adoption']
","['establish'] 
",0
"IBM’s best practice is to leverage  its digital change approach to involve the users in the  development of the project through studio’s in which we  envision and co-create together.
","['IBM ’', 'practice leverage', 'digital change approach involve users development project studio', '’ envision co-create']
","[] 
",0
"AI is not something  everyone will be able to grasp immediately.
","['AI something everyone', 'able grasp']
","[] 
",0
"Working with  AI should therefore be carefully implemented in the  business environment.
","['AI', 'business environment']
","['Working', 'therefore carefully implemented'] 
",1
"Expectation management Pitfalls: In many cases we work on, we see that employees  or other stakeholders don’t believe in AI or think it’s a magical  box we take from our office that will quickly solve all the  problems a company.
","['Expectation management Pitfalls', 'many cases', 'employees stakeholders', 'AI', '’', 'magical box', 'office', 'problems company']
","['work', 'see', '’ believe', 'think', 'take', 'quickly solve'] 
",1
"This leads to disappointment when  an AI project is not delivered in a short timeframe or if it  doesn’t deliver the expected results.
","['disappointment AI project', 'short timeframe ’', 'results']
","['leads', 'delivered', 'deliver expected'] 
",1
"And this disappointment  can lead to a lack of belief that will eventually diminish  the will to implement AI and experience the benefits of its  long-term possibilities.
","['disappointment lead lack belief', 'diminish implement AI experience benefits', 'long-term possibilities']
","[] 
",0
"Recommendation: Start with developing a solid strategy  and roadmap.
","['Recommendation', 'Start', 'solid strategy roadmap']
","['developing'] 
",0
"Define where you need to go and what you  need to add to the organization to get there.
","['Define', 'add organization get']
","['need go need'] 
",0
"First steps  often include mundane items such as data governance and  warehousing, but you need to take these steps to properly  implement AI.
","['First steps', 'mundane items data governance warehousing', 'steps', 'implement AI']
","['often include', 'need take'] 
",1
"It’s therefore important to implement proper  change management to guide the company.
","['important implement', 'change management guide company']
","['’'] 
",0
"12     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"Bad data Pitfalls: One problem we often come across is bad-quality  data.
","['Bad data Pitfalls', 'problem', 'bad-quality data']
","['often come'] 
",0
"This problem derails, limits and complicates many  machine learning and AI projects.
","['This problem', 'limits complicates', 'many machine', 'AI projects']
","['derails', 'learning'] 
",1
"Bad or “dirty”data can  mean fields are missing, that there are duplicates in the  data, or that it’s outdated data, contains spelling or  punctuation errors and is generally incorrect.
","['Bad “ dirty ” data mean fields', 'data', '’', 'data', 'contains', 'punctuation errors']
","['missing', 'duplicates', 'outdated', 'spelling', 'generally incorrect'] 
",1
"As we are  moving toward more data-driven decision making in  enterprises, it’s absolutely essential to have clean data.
","['data-driven decision making enterprises', '’', 'essential clean data']
","['moving'] 
",0
"Outcomes derived from bad data will lead to incorrect  decision making.
","['bad data lead', 'incorrect decision making']
","['Outcomes derived'] 
",0
"Recommendation: To overcome incorrect decision making  based on bad data we suggest the enterprise incorporate  standardization of data, monitoring of data, cleaning of  incoming data and a centralized control of data.
","['Recommendation', 'incorrect decision making', 'bad data', 'enterprise incorporate standardization data', 'monitoring data', 'data', 'control data']
","['overcome', 'based', 'suggest', 'cleaning incoming', 'centralized'] 
",1
"Sponsorship Pitfalls: When implementing an AI strategy, it’s important  that the right people, such as department heads, CxOs or  managers support the project.
","['Sponsorship Pitfalls', 'AI strategy', '’', 'important right people', 'department heads', 'CxOs managers support project']
","['implementing'] 
",0
"Implementing AI through the  organization can be a long process, and without support of  the right people there’s a higher probability that the project  will fail.
","['AI organization', 'process', 'support right people', 'probability project fail']
","['Implementing', '’'] 
",1
"What you might see when this problem occurs is  that your employees might not put enough time into problem  definition and subject knowledge sharing.
","['problem', 'employees', 'enough time problem definition subject knowledge sharing']
","['see', 'occurs', 'put'] 
",1
"Recommendation: Align the right people before you start  in a “garage” concept.
","['Recommendation', 'Align', 'right people', '“ garage ” concept']
","['start'] 
",0
"The key stakeholders should be  identified and should bring input and willingness to the  table.
","['The key stakeholders', 'input willingness table']
","['identified bring'] 
",0
"Create buy-in and support with employees, other  stakeholders, management and C-suite.
","['Create', 'buy-in support employees', 'stakeholders', 'management C-suite']
","[] 
",0
"Lack of capabilities  Pitfalls: Many companies want to implement machine  learning right off the bat.
","['Lack capabilities Pitfalls', 'Many companies', 'implement machine', 'right bat']
","['want', 'learning'] 
",1
"But to implement AI, you need to  look at two things: the first is acquiring or outsourcing your  own data science talent, and the second is looking at your  current IT infrastructure.
","['implement AI', 'things', 'data science talent', 'current IT infrastructure']
","['need look', 'first acquiring outsourcing', 'looking'] 
",1
"If you choose the in-house route, you’re taking a more  challenging route.
","['choose in-house route', '’', 'route']
","['taking challenging'] 
",0
"This option can be very rewarding but  it’s important to take in account that it will require more  time to set up infrastructures, pipelines and research.
","['This option', '’ important take account', 'require time', 'infrastructures', 'pipelines research']
","['rewarding', 'set'] 
",1
"If  you decide to take this route, you’ll need to acquire the  following skills in house:
","['route', '’', 'skills house']
","['take', 'need acquire following'] 
",1
" — Researchers to create new solutions to your products  — Project managers to keep the team on track  — Domain experts who have knowledge about your  products, customers and the business environment  surrounding the product
","['— Researchers', 'new solutions products', 'Project managers', 'team track — Domain experts knowledge products', 'customers business environment', 'product']
","['create', '—', 'keep', 'surrounding'] 
",1
" — Data engineers and machine learning engineers who  can scale the algorithms
","['— Data engineers machine', 'engineers', 'scale algorithms']
","['learning'] 
",0
" — Data analysts who can process the outcome  — Statisticians to help ensure quality results  — Software engineers to turn all you’ve created into  something that can be used by the masses—be it your  customers or your employees
","['— Data analysts process', '—', 'help', 'quality results', 'Software engineers', 'something', 'masses—be customers employees']
","['outcome', 'ensure', '—', 'turn ’ created', 'used'] 
",1
"While these roles don’t all need to be filled by individual  employees, it’s essential to have all these skills in house.
","['roles', 'need', 'individual employees', '’', 'essential skills house']
","['’', 'filled'] 
",1
"The second option is easier and quicker to implement.
","['The second option', 'quicker implement']
","[] 
",0
"In  this case you’d make use of the capabilities of an external  party such as through the IBM Garage offering, which can  give you the ability to use these capabilities without having  to set up a complete internal department.
","['case ’', 'use capabilities', 'external party IBM Garage offering', 'ability use capabilities', 'complete internal department']
","['make', 'give', 'set'] 
",1
"IBM Services     13
","['IBM']
","['Services'] 
",0
"Recommendation: Before starting an AI project, you should  evaluate the capabilities you currently have inhouse, and  then define the cost you’ll occur acquiring the capabilities  needed to close any gaps.
","['Recommendation', 'AI project', 'capabilities', 'define cost ’', 'capabilities', 'gaps']
","['starting', 'evaluate', 'currently inhouse', 'occur acquiring', 'needed'] 
",1
"Then you can define whether you  want to hire these capabilities internally or use an external  experienced resource to access the required capabilities.
","['want hire capabilities', 'external experienced resource access', 'capabilities']
","['Then define', 'internally use', 'required'] 
",1
"Scalability  Pitfalls: To properly scale the correct architecture,  integration and employees that know how to use them  need be in place.
","['Scalability Pitfalls', 'scale correct architecture', 'integration employees', 'need place']
","['properly', 'know use'] 
",1
"Many data scientists believe that the  research and development (R&D) of a data science project  is similar to a scaled IT implementation, yet the two are  very different.
","['Many data scientists', 'research development', 'R', 'D', 'data science project', 'IT implementation']
","['believe', 'scaled'] 
",1
"Also, because there is increasing enterprise  demand for AI, organizations want to analyze large amounts  of data.
","['enterprise demand AI', 'organizations', 'analyze large amounts data']
","['increasing', 'want'] 
",1
"This can require quite a bit of time to train an  algorithm—days or even weeks depending on the amount  of data involved.
","['bit time train algorithm—days', 'weeks', 'amount data']
","['require', 'depending', 'involved'] 
",1
"We still encounter data scientists trying  to perform this function on their laptops.9
","['data scientists', 'perform function laptops.9']
","['still encounter', 'trying'] 
",1
"Recommendation: Develop a plan to set up the correct   AI architecture, a platform to deploy to, a data integration  strategy and properly trained data scientists.
","['Recommendation', 'Develop plan', 'correct AI architecture', 'platform deploy', 'data integration strategy', 'data scientists']
","['set', 'properly trained'] 
",1
"Not enough (available) data  Pitfalls: Data availability depends on the company and on  how it stores data.
","['data Pitfalls', 'Data availability', 'company stores data']
","['depends'] 
",0
"Some organizations have the data but  don’t have it readily available.
","['Some organizations', '’']
","['data'] 
",0
"Large corporations are  challenged to locate and keep track of the right data.
","['Large corporations', 'track right data']
","['challenged', 'keep'] 
",1
"Smaller companies may be challenged by the amount of  data they produce.
","['Smaller companies', 'amount data']
","['challenged', 'produce'] 
",1
"Recommendation: Not all problems need machine learning  and AI.
","['Recommendation', 'problems', 'machine learning AI']
","['need'] 
",0
"If you find yourself in a situation where you don’t  have enough data, you should carefully consider if you  should launch your product using machine learning.
","['find situation ’', 'data', 'launch product', 'machine learning']
","['carefully consider', 'using'] 
",1
"If you  choose that option but don’t have enough data, you can  overcome the problem by acquiring external data or by  using simpler models.
","['choose option ’', 'data', 'overcome problem', 'external data', 'simpler models']
","['acquiring', 'using'] 
",1
"Unlabeled data  Pitfalls: A common problem when implementing AI is data  that’s not classified by humans or machines, which leaves  you unable to train the system (in the case of a supervised  algorithm).
","['data Pitfalls', 'A common problem', 'AI data ’', 'humans machines', 'unable train system', 'case', 'algorithm']
","['Unlabeled', 'implementing', 'classified', 'leaves', 'supervised'] 
",1
"For instance, if you wanted to predict fraud, but  the historical fraudulent cases weren’t labelled, it would be  impossible for the algorithm to map input to outputs.
","['instance', 'predict fraud', 'historical fraudulent cases ’', 'algorithm map input outputs']
","['wanted', 'labelled', 'impossible'] 
",1
"Recommendation: In this case, define what data you’ll  need to run a sound model.
","['Recommendation', 'case', 'data ’', 'sound model']
","['define', 'need run'] 
",1
"This data will then need to  be labeled—which can be expensive—or you can use  algorithms to accomplish this task.
","['This data', 'labeled—which expensive—or use', 'algorithms accomplish task']
","['need'] 
",0
"It’s a more advanced  technique, but you can use reinforcement learning or  semi-supervised models.
","['advanced technique', 'semi-supervised models']
","['’', 'use', 'learning'] 
",1
"Your data scientist might know  which approach is best.
","['data scientist', 'approach']
","['know'] 
",0
"Explainable results  Pitfalls: In many cases, the business wants and needs to  know why specific outcomes occur.
","['Explainable results Pitfalls', 'many cases', 'business', 'needs', 'specific outcomes']
","['wants', 'know', 'occur'] 
",1
"This is in line with one  of IBMs principles for ethical use of AI is: AI systems must  be transparent and explainable.
","['This line', 'IBMs', 'ethical use AI', 'AI systems']
","['principles', 'transparent'] 
",1
"Depending on what kind  of algorithm is used, an AI can’t show exactly which  variables brought it to a given conclusion.
","['kind algorithm', 'AI ’', 'variables', 'conclusion']
","['Depending', 'used', 'show', 'brought given'] 
",1
"We call these  black-box algorithms.
","['black-box algorithms']
","['call'] 
",0
"While they sometimes may perform  better, they don’t give a lot of explanation.
","['lot explanation']
","['perform', 'give'] 
",1
"For example,  you might have an algorithm that defines whether an  applicant gets a loan.
","['example', 'defines', 'loan']
","['algorithm', 'gets'] 
",1
"According to European law in some  countries, if you deny the applicant, you need to explain  why you did so.
","['European law countries', 'deny applicant', 'explain']
","['According', 'need'] 
",1
"Recommendation: There are several new algorithms that  help explain what happens in the black-box models such   as Local Interpretable Model-Agnostic (LIME).10 But this  doesn’t solve the problem in all cases.
","['Recommendation', 'several new algorithms help', 'black-box models Local Interpretable Model-Agnostic', 'LIME', 'solve problem cases']
","['explain happens', '.10', '’'] 
",1
"You should therefore  define what you’re going to use the model for.
","['define ’', 'use model']
","['therefore', 'going'] 
",1
"If the model  needs to explain precisely why it came to a certain conclusion,  your data scientists should consider other models that provide  the specific information required.
","['model', 'certain conclusion', 'data scientists', 'models', 'specific information']
","['needs explain', 'precisely came', 'consider', 'provide', 'required'] 
",1
"Ethics and AI should go  hand-in-hand.
","['Ethics AI', 'hand-in-hand']
","['go'] 
",0
"14     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"Summary AI has the potential to bring a lot of value to your company  if thought through and implemented properly.
","['Summary AI', 'potential bring lot value company']
","['thought implemented'] 
",0
"The authors  of this paper hope we’ve made it clear how you can achieve  this goal.
","['The authors paper hope ’', 'clear achieve goal']
","['made'] 
",0
"We’ve discussed what AI is what it can do for your  organization, how it should be implemented and what pitfalls  you should avoid once you’ve decided to implement AI.
","['AI organization', 'pitfalls', '’', 'implement AI']
","['’ discussed', 'implemented', 'avoid', 'decided'] 
",1
"To sum up this paper’s key points:
","['paper ’', 'key points']
","['sum'] 
",0
"AI not something of the future, it is real today, and it fuels  the fourth Industrial Revolution: As you will see later in this  paper, there are many cases where AI is being successfully  implemented and driving competitive advantage.
","['AI something future', 'real today', 'fuels', 'fourth Industrial Revolution', 'see', 'paper', 'many cases AI', 'competitive advantage']
","['successfully implemented driving'] 
",0
"Companies  such as IBM, Nvidia, Twitter, Delta Airlines, Walmart, Netflix,  Spotify and Kreditech show that their data-driven approach  produces extremely valuable business models.
","['Companies IBM', 'Nvidia', 'Twitter', 'Delta', 'Walmart', 'Netflix', 'Spotify Kreditech', 'data-driven approach', 'valuable business models']
","['show', 'produces'] 
",1
"But for many  companies, failing to implement a data-driven strategy can  lead to lost market share.
","['many companies', 'implement data-driven strategy lead', 'market share']
","['failing', 'lost'] 
",1
"Properly implementing AI requires careful evaluation and  planning: You need to evaluate how AI can help solve your  problems, where your company is right now in terms of  capabilities and what needs to be done before you can  properly implement AI to address the problems you want  to solve or the opportunities you want to take.
","['AI', 'careful evaluation planning', 'AI help', 'problems', 'company', 'terms capabilities', 'implement AI address problems', 'opportunities', 'take']
","['Properly implementing', 'requires', 'need evaluate', 'solve', 'needs done', 'want solve', 'want'] 
",1
"There is no one magic algorithm that can solve all your  problems: Before implementing AI, you should focus on  the problems you have and how AI can help you solve  them.
","['magic algorithm solve problems', 'AI', 'focus problems AI help solve']
","['implementing'] 
",0
"Next, you need to check whether the data you need  to solve your problems is available.
","['data', 'problems']
","['need check', 'need solve'] 
",1
"Often a hybrid between  algorithms can be the right fit, depending on the problems  you want to solve.
","['hybrid algorithms', 'right fit', 'problems', 'solve']
","['depending', 'want'] 
",1
"Supervised learning provides the most economic value:  Supervised learning is currently the most applied form of  learning and provides the most value for a wide variety of  applications.
","['economic value', 'form', 'value', 'wide variety applications']
","['learning provides', 'Supervised learning', 'currently applied', 'learning provides'] 
",1
"When beginning to implement AI in your  enterprise, you’ll likely be working with supervised learning.
","['implement AI enterprise', '’', 'learning']
","['beginning', 'likely working supervised'] 
",1
"In the next section of this paper, we’ll talk about how IBM  can play a role in implementing AI within your organization.
","['next section paper', '’ talk IBM play role', 'AI', 'organization']
","['implementing'] 
",0
"IBM not only has many years of experience with these types  of projects but has also been a pioneer in the AI arena.
","['IBM', 'many years', 'types projects', 'AI arena']
","['experience', 'also pioneer'] 
",1
"Based  on its experience and knowledge, IBM can help companies of  all sizes implement AI solutions.
","['experience knowledge', 'IBM help companies', 'implement AI solutions']
","['Based', 'sizes'] 
",1
"IBM Services     15
","['IBM']
","['Services'] 
",0
"IBM Services IBM has the experience and knowledge to help guide your  company through a business and technology transformation.
","['IBM', 'IBM experience knowledge help', 'company business technology transformation']
","['guide'] 
",0
"IBM puts this into practice through the “garage” concept.
","['IBM', 'practice', '“ garage ” concept']
","['puts'] 
",0
"The IBM Garage lets you experiment with big ideas, acquire  new expertise and build new enterprise-grade solutions  with modern and emerging technologies for immediate  market impact.
","['The IBM Garage', 'experiment big ideas', 'new expertise', 'build new enterprise-grade solutions', 'technologies', 'immediate market impact']
","['lets', 'acquire', 'emerging'] 
",1
"IBM looks at implementing AI in a holistic way.
","['IBM', 'AI', 'holistic way']
","['looks implementing'] 
",0
"You as   a client and IBM can enter into a strategic alliance to  transform your business by creating a platform for  continuous innovation.
","['client IBM enter', 'strategic alliance transform business', 'platform', 'continuous innovation']
","['creating'] 
",0
"The IBM Garage lets you innovate  and develop with the speed of a start-up, at the scale and  rigor of an enterprise.
","['The IBM Garage', 'speed start-up', 'scale rigor enterprise']
","['lets', 'develop'] 
",1
"It offers an innovation space where  clients and IBM work side-by-side to create first-of-a-kind  strategies and solutions.
","['innovation space clients IBM work', 'side-by-side create first-of-a-kind strategies solutions']
","['offers'] 
",0
"You can then develop the  expertise to transform the way you work.
","['expertise transform way work']
","['develop'] 
",0
"Figure 6: The IBM Garage for AI.
","['Figure', 'The IBM Garage AI']
","[] 
",0
"The IBM Garage as the engine for a Cognitive Enterprise transformation
","['The IBM Garage engine Cognitive Enterprise transformation']
","[] 
",0
"Build and recruit capability: key  profiles, roles, competences &  responsibilities with the use of  an AI Academy
","['Build recruit capability', 'key profiles', 'roles', 'competences', 'responsibilities', 'AI Academy']
","['use'] 
",0
"AI capability  development
","['AI capability development']
","[] 
",0
"Information technology  supporting the AI  infrastructure, data and tools
","['Information technology', 'AI infrastructure', 'data tools']
","['supporting'] 
",0
"Technology
","['Technology']
","[] 
",0
"Design and implement  model to measure and  develop performance
","['Design implement model measure', 'performance']
","['develop'] 
",0
"Performance  management
","['Performance management']
","[] 
",0
"Operating model + integration  for think, transform and thrive Operating model
","['model', '+ integration think', 'thrive Operating model']
","['Operating', 'transform'] 
",1
"Current state assessment  moving to strategic direction  and guiding principles.
","['Current state assessment', 'strategic direction', 'principles']
","['moving', 'guiding'] 
",1
"Implementation roadmap
","['Implementation roadmap']
","[] 
",0
"Ambition & roadmap
","['Ambition', 'roadmap']
","[] 
",0
"Change and integration  management, culture  strategy alignment
","['Change integration management', 'culture strategy alignment']
","[] 
",0
"Change  management &  communication
","['Change management', 'communication']
","[] 
",0
"Service line functional scope,  Geo, BU, process, growth  model, country support
","['Service line', 'functional scope', 'Geo', 'BU', 'process', 'growth model', 'country support']
","[] 
",0
"Organization  structure  governance
","['Organization structure governance']
","[] 
",0
"Design, validate, transform.
","['Design', 'validate', 'transform']
","[] 
",0
"Includes demand  management, prioritisation,  delivery methodology,  assurance and value  management, KPI definition
","['Includes demand management', 'prioritisation', 'delivery methodology', 'assurance value management', 'KPI definition']
","[] 
",0
"Demand  generation
","['Demand generation']
","[] 
",0
"IBM Garage  for AI
","['IBM Garage AI']
","[] 
",0
"16     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"Figure 7: The IBM stages of implementing AI.
","['Figure', 'The IBM', 'AI']
","['stages implementing'] 
",0
"Plan on a page to start the journey with the IBM Garage for AI
","['Plan', 'start journey IBM Garage AI']
","['page'] 
",0
"THINK
","['THINK']
","[] 
",0
"Set ambition  and organization
","['Set ambition organization']
","[] 
",0
"Drive demand  and innovate
","['Drive demand innovate']
","[] 
",0
"TRANSFORM
","['TRANSFORM']
","[] 
",0
"Drive to  production
","['production']
","[] 
",0
"THRIVE
","['THRIVE']
","[] 
",0
"Scale up
","['Scale']
","[] 
",0
"The “Think” phase is a process dedicated to thinking,  experimenting, and proving, with the end user at the heart  of your innovation.
","['The “ Think ” phase process', 'thinking', 'user heart innovation']
","['dedicated', 'experimenting', 'proving', 'end'] 
",1
"We start with ideas and get to working  concepts fast, incorporating feedback in real time.
","['ideas', 'concepts', 'feedback', 'real time']
","['start', 'get working', 'incorporating'] 
",1
"IBM helps you get prepared first, in a fast, pressure-cooker  environment.
","['IBM', 'pressure-cooker environment']
","['helps get'] 
",0
"This helps you to kickstart your AI journey.
","['AI journey']
","['helps kickstart'] 
",0
"IBM works with you to deliver an assessment of your  current AI capabilities.
","['IBM', 'assessment current AI capabilities']
","['works deliver'] 
",0
"In assessing your current AI capabilities, IBM looks at  many different aspects, some of which are:
","['current AI capabilities', 'IBM', 'many different aspects']
","['assessing', 'looks'] 
",1
" — Systems: What does your innovation system look like?
","['innovation system']
","['look'] 
",0
"— People: How skilled is your staff in AI?
","['— People', 'How', 'staff AI']
","['skilled'] 
",0
"— Organization: How do you position AI expertise in   your organization?
","['— Organization', 'position AI expertise organization']
","[] 
",0
" — Culture: Do you operate in an agile fashion?
","['— Culture', 'fashion']
","['Do operate agile'] 
",0
"— Data: How readily available is your data?
","['— Data', 'How', 'available data']
","[] 
",0
"— Technology: Does your current architecture enable AI?
","['— Technology', 'Does', 'current architecture enable AI']
","[] 
",0
"IBM works with you to define your AI Ambition as a high- level AI strategic direction by looking at “big ideas” and  by reflecting on persona’s and their user stories.
","['IBM', 'define AI Ambition', 'high- level AI', 'strategic direction', '“', 'big ideas', 'persona ’ user stories']
","['works', 'looking', '” reflecting'] 
",1
"A persona  can be a marketing manager or a product developer.
","['A persona marketing manager product developer']
","[] 
",0
"This  ambition is translated into a roadmap and a high-level  business case.
","['This ambition', 'roadmap high-level business case']
","['translated'] 
",0
"IBM also supports you to select the most  favorable operating model to move forward.
","['IBM', 'select', 'model move']
","['also supports', 'operating'] 
",1
"Once you are prepared for your garage, IBM uses design  thinking to identify and define use cases.
","['prepared garage', 'IBM', 'design', 'identify define use cases']
","['uses', 'thinking'] 
",1
"All use cases are  conceived based on the notion of creating business value.
","['cases', 'notion', 'business value']
","['use', 'conceived based', 'creating'] 
",1
"In IBM’s experience, design thinking is the most effective  way.
","['IBM ’ experience', 'design', 'effective way']
","['thinking'] 
",0
"This so-called “demand generation” for the garage  should be on-going, creating the backlog and setting the  capacity planning for the garage.
","['This so-called “ demand generation', '” garage', 'backlog', 'capacity planning garage']
","['creating', 'setting'] 
",1
"IBM Services     17
","['IBM']
","['Services'] 
",0
"Once the first use cases have been agreed, the garage  provides the playground for deep technology, accommodating  enterprise-scale ways of working—such as design thinking,  agile, DevOps and lean IT.
","['first use cases', 'garage', 'playground deep technology', 'enterprise-scale ways', 'working—such design thinking', 'agile', 'DevOps', 'IT']
","['agreed', 'provides', 'accommodating', 'lean'] 
",1
"Innovation starts with a Proof  of Value (POV): evaluating the business and technical  feasibility of the use case in a time-boxed agile manner.
","['Innovation', 'Proof Value', 'POV', 'business', 'technical feasibility use case', 'time-boxed agile manner']
","['starts', 'evaluating'] 
",1
"Agile development is at the core of what IBM does in the  garage.
","['Agile development core IBM garage']
","[] 
",0
"The goal is to succeed or fail quickly, with speed   to scale.
","['The goal', 'scale']
","['succeed', 'speed'] 
",1
"Flexibility and speed are key!
","['Flexibility speed key']
","[] 
",0
"A successful POV will  move into a pilot implementation.
","['A successful POV move pilot implementation']
","[] 
",0
"The IBM Garage leverages  IBM’s extensive asset library to more efficiently validate use  cases and accelerate transformative change.
","['The IBM Garage', 'IBM ’', 'extensive asset library', 'validate use cases', 'transformative change']
","['leverages', 'accelerate'] 
",1
"Organizations should be prepared to step out of their comfort  zones and think differently.
","['Organizations', 'prepared step comfort zones']
","['think'] 
",0
"Thinking in a data-driven and AI  approach requires a shift in the way we see.
","['data-driven AI approach', 'shift way see']
","['Thinking', 'requires'] 
",1
"It takes some  effort to change our ways of thinking.
","['effort change ways thinking']
","['takes'] 
",0
"This is where digital  change management plays a role.
","['This digital change management', 'role']
","['plays'] 
",0
"You also need to consider  the buildup of AI capabilities in your organization.
","['buildup AI', 'organization']
","['also need', 'capabilities'] 
",1
"IBM  offers various forms of training and enablement ranging  from Hackathons, planned learning universities for  upskilling and an AI learning academy.
","['IBM', 'various forms', 'Hackathons', 'universities', 'AI', 'academy']
","['offers', 'training', 'ranging', 'planned learning', 'upskilling', 'learning'] 
",1
"In the “Transform” phase, IBM collaborates with experts,  data and emerging technologies, using accelerators to  build minimum, viable products into production and realize  business outcomes and customer adoption within weeks.
","['“ Transform ” phase', 'IBM', 'experts', 'data', 'technologies', 'accelerators', 'viable products production realize business outcomes customer adoption', 'weeks']
","['collaborates', 'emerging', 'using', 'build'] 
",1
"The third and last phase is the factory “Thrive” phase, which is  designed to rapidly scale solutions while establishing methods  and new ways of working across your enterprise that can last  a lifetime.
","['The third last phase factory “ Thrive ” phase', 'scale solutions', 'methods', 'new ways', 'enterprise', 'last lifetime']
","['designed', 'establishing', 'working'] 
",1
"The thrive phase works as a managed service to  embed and maintain data and AI solutions at scale.
","['The thrive phase', 'service', 'maintain data AI solutions scale']
","['works managed', 'embed'] 
",1
"Using a  factory-like approach, you put into production something you  want to be consistent in design and quality, and that doesn’t  require innovation in execution.
","['factory-like approach', 'production something', 'consistent design quality', '’', 'innovation execution']
","['Using', 'put', 'want', 'require'] 
",1
"IBM focuses on successful  delivery of projects aligned to the roadmap and AI platform  technology and helps ensure a clearly defined governance.
","['IBM', 'successful delivery projects', 'roadmap AI platform technology', 'governance']
","['focuses', 'aligned', 'helps ensure', 'clearly defined'] 
",1
"Using this method, IBM has been successful many times  and wants to keep improving the method with each project  delivered.
","['method', 'IBM', 'successful many times', 'method project']
","['Using', 'wants keep improving', 'delivered'] 
",1
"IBM is one of the frontrunners of AI and AI  implementation, and thrives on applying its knowledge and  experience to help improve the world.
","['IBM', 'frontrunners AI AI implementation', 'experience help', 'world']
","['thrives applying knowledge', 'improve'] 
",1
"18     Beyond the hype: A guide to understanding and successfully implementing artificial intelligence within your business
","['Beyond hype', 'A guide', 'artificial intelligence', 'business']
","['understanding successfully implementing'] 
",0
"About the authors Jorn Jansen Schoonhoven, a data scientist at IBM with two  years of data science experience is part of the Advanced  Analytics branch of the IBM Amsterdam office, and part of  the IBM Global Institute of Business Value team.
","['authors Jorn Jansen Schoonhoven', 'data', 'IBM', 'years data science experience part Advanced Analytics branch IBM Amsterdam office', 'part IBM Global Institute Business Value team']
","['scientist'] 
",0
"He holds  a master’s degree in business analytics and big data, and a  master’s degree in management from IE Business School.
","['’ degree business analytics', 'big data', 'master ’ degree management IE Business School']
","['holds'] 
",0
"He is the main author of this paper and can be reached at  Jorn.Jansen.Schoonhoven@ibm.com or +316 22403033.
","['main author paper', 'Jorn.Jansen.Schoonhoven @ ibm.com']
","['reached', '+316'] 
",1
"Marloes Roelands is an Associate Partner with over 20 years’  experience in consulting.
","['Marloes Roelands Associate Partner', 'years', '’ experience consulting']
","[] 
",0
"She is the European leader for the  “IBM Garage for AI.” She loves making innovation happen  with her clients and followed the Executive programme  “Strategy and Innovation” at Saïd Business School at Oxford  University to support her thinking.
","['European leader “ IBM Garage AI. ”', 'innovation', 'clients', 'Executive programme “ Strategy Innovation ” Saïd Business School Oxford University support thinking']
","['loves making', 'happen', 'followed'] 
",1
"She also holds a Master of  Economics from Erasmus University Rotterdam.
","['Master Economics Erasmus University Rotterdam']
","['also holds'] 
",0
"She can be  reached at marloes.roelands@nl.ibm.com.
","['marloes.roelands', '@ nl.ibm.com']
","['reached'] 
",0
"Francesco Brenna, an Executive Partner with over 17 years of  consulting experience, currently leads the AI practice for IBM  Global Business Services in Europe.
","['Francesco Brenna', 'Executive Partner', 'years', 'experience', 'AI practice IBM Global Business Services Europe']
","['consulting', 'currently leads'] 
",1
"He holds a Bachelor of  Science in Computer Science from Zurich University of Applied  Sciences in Zurich and a Master of Business Administration  (with distinction) from Warwick Business School.
","['Bachelor Science Computer Science Zurich University Applied Sciences Zurich Master Business Administration', 'distinction', 'Warwick Business School']
","['holds'] 
",0
"He can be  reached at francesco.brenna@ch.ibm.com.
","['francesco.brenna @ ch.ibm.com']
","['reached'] 
",0
"Acknowledgements The authors thank the advanced analytics practice for  sharing their experience about the implementation of AI,  the IBM Institute for Business value for their advice and  insights, and other IBM branches whose insights are  reflected in this document.
","['Acknowledgements', 'The authors', 'advanced analytics practice', 'experience implementation AI', 'IBM Institute Business value advice insights', 'IBM branches', 'insights', 'document']
","['thank', 'sharing', 'reflected'] 
",1
"The authors are also grateful for the contributions of many  IBM colleagues.
","['The authors', 'grateful contributions', 'many IBM colleagues']
","[] 
",0
"In particular, they thank Mando Rotman,  Wouter Oosterbosch, Damian Brennan and Vanessa van de  Vliet.
","['thank Mando Rotman', 'Wouter Oosterbosch', 'Damian Brennan Vanessa', 'Vliet']
","[] 
",0
"This report would not have been possible without the  help of many other colleagues within the IBM Watson and  advanced analytics department.
","['This report', 'many colleagues', 'IBM Watson', 'analytics department']
","['help', 'advanced'] 
",1
"Finally, special thanks go to Apostolos Mourouzis and  Patricio Fernandez Weisson.
","['special thanks', 'Apostolos Mourouzis Patricio Fernandez Weisson']
","['go'] 
",0
"Appendix Different types of learning Learning.
","['Appendix Different types', 'Learning']
","['learning'] 
",0
"which is one of the fundamentals of artificial  intelligence and machine learning, is when the algorithm  improves itself by looking at the data provided.
","['artificial intelligence machine learning', 'algorithm improves', 'data']
","['fundamentals', 'looking', 'provided'] 
",1
"There are two  elements involved: knowledge and feedback.
","['elements', 'knowledge feedback']
","['involved'] 
",0
"Knowledge  provides information that’s already in the data, and the  algorithm can learn from feedback through interactions with  the user.
","['Knowledge', 'information ’', 'algorithm', 'feedback interactions']
","['provides', 'already data', 'learn', 'user'] 
",1
"This happens when a user gives the model feedback  about correct or falsely predicted outcomes.
","['model feedback', 'outcomes']
","['happens', 'gives', 'correct falsely predicted'] 
",1
"There are four  types of machine learning: supervised, unsupervised,  reinforcement and transfer.
","['types machine learning', 'reinforcement transfer']
","['supervised'] 
",0
"Currently the most often used  type is supervised learning, and thus we can say that the  most economical value is created within this category.
","['type', 'learning', 'economical value', 'category']
","['Currently often used', 'supervised', 'thus say', 'created'] 
",1
"IBM Services     19
","['IBM']
","['Services'] 
",0
"Supervised learning is a learning method that maps an input  to an output using human data and feedback to improve.
","['method maps', 'output', 'human data feedback improve']
","['Supervised learning learning', 'input', 'using'] 
",1
"A  data set is provided with associated correct labels to the  data.
","['A data set', 'associated correct labels data']
","['provided'] 
",0
"An example would be pictures of animals in which all  pictures were correctly labelled as the animal in the pictures.
","['An example', 'animals', 'animal pictures']
","['pictures', 'pictures correctly labelled'] 
",1
"Supervised learning trains based on historical data and  builds rules that can be applied to predict future problems.
","['learning trains', 'historical data builds rules', 'future problems']
","['Supervised', 'based', 'applied predict'] 
",1
"The better the data set, the better the output.
","['data set', 'output']
","[] 
",0
"You may use this type of learning when you want to classify  or predict outcomes.
","['type', 'classify predict outcomes']
","['use', 'learning want'] 
",1
"With regression, you are predicting a  continuous value (“How much will the stock price be?”).
","['regression', 'continuous value', 'How', 'much stock price', '”']
","['predicting', '“'] 
",1
"With classifying, you are assigning a label to an input (“Is  this picture a man or a woman?”).
","['classifying', 'label input', '“', 'picture man woman', '”']
","['assigning', 'Is'] 
",1
"Other examples would  be using speech recognition to examine the sentiments of  people calling your customer service center, or image  recognition to define products in a warehouse so they  could be properly sorted.
","['Other examples', 'speech recognition examine sentiments people', 'customer service center', 'image recognition define products warehouse']
","['using', 'calling', 'properly sorted'] 
",1
"Unsupervised learning occurs when the algorithm is not  given a specific “wrong” or “right” outcome.
","['learning', 'specific “', 'wrong ” “', 'right ” outcome']
","['Unsupervised', 'occurs algorithm given'] 
",1
"Instead, the  algorithm is given unlabeled data.
","['unlabeled data']
","['algorithm given'] 
",0
"Unsupervised learning  is often used when you want to classify data but don’t know  how to do so.
","['learning', 'want classify data ’']
","['Unsupervised', 'often used', 'know'] 
",1
"For example, you’d likely use unsupervised  learning if you had a set of customer data and you didn’t  know what kind of classes they would fit in.
","['example', '’', 'unsupervised learning', 'customer data', 'kind classes']
","['likely use', 'set', '’ know', 'fit'] 
",1
"An unsupervised  learning algorithm can find natural groupings of similar  customers in a database and the user can then describe   and label them.
","['An unsupervised learning algorithm', 'natural groupings', 'similar customers', 'user describe label']
","['find', 'database'] 
",1
"Reinforcement learning is a class in and of itself; it is not  given a specific goal, but rather learns from trial and error.
","['Reinforcement', 'class', 'specific goal', 'trial error']
","['learning', 'given', 'rather learns'] 
",1
"The main concept is that instead of a specific action being  labelled, there is a sequence of actions that is associated  with a reward.
","['The main concept', 'specific action', 'sequence actions', 'reward']
","['labelled', 'associated'] 
",1
"If we take a maze as an example, the  algorithm will be rewarded when it comes closer to its goal  and be penalized every time it gets stuck or moves away  from the completion.
","['maze example', 'algorithm', 'goal', 'every time', 'stuck moves', 'completion']
","['take', 'rewarded comes', 'penalized', 'gets'] 
",1
"A recent example of reinforcement  learning is AlphaGo, where Google trained a deep  reinforcement learning network with many examples of  the game Go, eventually making its performance superior  to that of even the best human.
","['A recent example reinforcement', 'AlphaGo', 'Google', 'deep reinforcement', 'network', 'many examples game Go', 'performance', 'human']
","['learning', 'trained', 'learning', 'eventually making'] 
",1
"This trick is not new, since  it was used in TD-Gammon in 1992, created by Gerald  Tesauro at IBM.
","['TD-Gammon', 'Gerald Tesauro IBM']
","['used', 'created'] 
",1
"TD-Gammon was a backgammon-playing  program that reached the performance of the best human  players at the time.
","['TD-Gammon backgammon-playing program', 'performance', 'human players time']
","['reached'] 
",0
"Reinforcement learning is not currently widely used, but it  does have high potential when developed more extensively.
","['Reinforcement', 'high potential']
","['learning currently widely used', 'developed'] 
",1
"You would need a lot of data (which is not always the case  and takes time to process) to be able to make reinforcement  learning work.
","['lot data', 'case', 'time process', 'reinforcement learning work']
","['need', 'takes', 'make'] 
",1
"Transfer learning is when your algorithm learns to solve  one problem, takes information from this problem and then  solves a new problem with that information.
","['Transfer', 'algorithm learns', 'problem', 'information problem', 'new problem information']
","['learning', 'solve', 'takes', 'solves'] 
",1
"This currently  happens a lot with image recognition.
","['lot image recognition']
","['currently happens'] 
",0
"Pre-trained neural  networks are used to solve new problems.
","['Pre-trained neural networks', 'new problems']
","['used solve'] 
",0
"© Copyright IBM Corporation 2018
","['© Copyright IBM Corporation']
","[] 
",0
"IBM Corporation  New Orchard Road  Armonk, NY 10504
","['IBM Corporation New Orchard Road Armonk', 'NY']
","[] 
",0
"Produced in the United States of America  October 2018
","['Produced United', 'America October']
","[] 
",0
"IBM, the IBM logo, ibm.com, and IBM Watson are trademarks or  registered trademarks of International Business Machines Corp.,  registered in many jurisdictions worldwide.
","['IBM', 'IBM logo', 'ibm.com', 'IBM Watson trademarks', 'trademarks International Business', 'Corp.', 'many jurisdictions']
","['registered', 'registered', 'worldwide'] 
",1
"Other product and   service names might be trademarks of IBM or other companies.
","['Other product service names', 'IBM companies']
","['trademarks'] 
",0
"A current list of IBM trademarks is available on the web at   www.ibm.com/legal/copytrade.shtml.
","['A current list IBM', 'available web www.ibm.com/legal/copytrade.shtml']
","['trademarks'] 
",0
"Microsoft, Windows, Windows NT and the Windows logo are  trademarks of Microsoft Corporation in the United States, other  countries, or both.
","['Microsoft', 'Windows', 'Windows NT Windows logo trademarks Microsoft Corporation United', 'countries']
","[] 
",0
"This document is current as of the initial date of publication and may  be changed by IBM at any time.
","['This document', 'current initial date publication', 'IBM time']
","['changed'] 
",0
"Not all offerings are available in every  country in which IBM operates.
","['offerings', 'every country IBM']
","['operates'] 
",0
"The performance data and client examples cited are presented for  illustrative purposes only.
","['The performance data client examples', 'presented illustrative purposes']
","['cited'] 
",0
"Actual performance results may vary depending  on specific configurations and operating conditions.
","['Actual performance results', 'specific configurations', 'conditions']
","['vary depending', 'operating'] 
",1
"THE INFORMATION  IN THIS DOCUMENT IS PROVIDED “AS IS” WITHOUT ANY WARRANTY,  EXPRESS OR IMPLIED, INCLUDING WITHOUT ANY WARRANTIES OF  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND ANY  WARRANTY OR CONDITION OF NON-INFRINGEMENT.
","['THE INFORMATION IN THIS DOCUMENT IS PROVIDED “ AS IS ” WITHOUT ANY WARRANTY', 'EXPRESS OR IMPLIED', 'INCLUDING WITHOUT ANY WARRANTIES OF MERCHANTABILITY', 'FITNESS', 'A PARTICULAR PURPOSE AND ANY WARRANTY OR CONDITION', 'NON-INFRINGEMENT']
","[] 
",0
"IBM products are  warranted according to the terms and conditions of the agreements under  which they are provided.
","['IBM products', 'terms conditions agreements']
","['warranted according', 'provided'] 
",1
" 1 www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution- what-it-means-and-how-to-respond
","['www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution- what-it-means-and-how-to-respond']
","[] 
",0
" 2 www.quora.com/What-is-artificial-intelligence-What-are-task- domains-in-AI
","['www.quora.com/What-is-artificial-intelligence-What-are-task- domains-in-AI']
","[] 
",0
" 3 ai100.stanford.edu/sites/default/files/ai_100_report_0906fnlc_ single.pdf
","['ai100.stanford.edu/sites/default/files/ai_100_report_0906fnlc_ single.pdf']
","[] 
",0
" 4 www.investopedia.com/terms/a/artificial-intelligence-ai.asp
","[]
","[] 
",0
" 5 neuralnetworksanddeeplearning.com/chap5.html
","['neuralnetworksanddeeplearning.com/chap5.html']
","[] 
",0
" 6 datasciencedegree.wisconsin.edu/data-science/what-do-data- scientists-do
","['datasciencedegree.wisconsin.edu/data-science/what-do-data- scientists-do']
","[] 
",0
" 7 www.interaction-design.org/literature/book/the-social-design-of- technical-systems-building-technologies-for-communities/the- evolution-of-computing
","['www.interaction-design.org/literature/book/the-social-design-of- technical-systems-building-technologies-for-communities/the- evolution-of-computing']
","[] 
",0
" 8 www.forbes.com/sites/blakemorgan/2017/06/13/ethics-and-artificial- intelligence-with-ibm-watsons-rob-high/#72b4a0e3260e  www.forbes.com/sites/gilpress/2016/12/21/artificial-intelligence- pioneers-peter-norvig-google/#6ecd8a2d38c6
","[]
","[] 
",0
" 9 www-01.ibm.com/common/ssi/cgi-bin/ ssialias?htmlfid=KUM12390USEN&, page 67
","['www-01.ibm.com/common/ssi/cgi-bin/ ssialias', 'htmlfid=KUM12390USEN', 'page']
","[] 
",0
" 10 homes.cs.washington.edu/~marcotcr/blog/lime
","['homes.cs.washington.edu/~marcotcr/blog/lime']
","[] 
",0
"39019539-USEN-00
","[]
","[] 
",0
"Please Recycle
","['Please Recycle']
","[] 
",0
"Big Data Analytics with Oracle Advanced Analytics
","['Big Data Analytics Oracle Advanced Analytics']
","[] 
",0
"Making Big Data and Analytics Simple
","['Big Data Analytics Simple']
","['Making'] 
",0
"O R A C L E  W H I T E  P A P E R   |   J U L Y  2 0 1 5
","['O R A C L E W H', 'T E P A P E R | J U L Y']
","[] 
",0
"BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Disclaimer
","['Disclaimer']
","[] 
",0
"The following is intended to outline our general product direction.
","['intended outline general product direction']
","['following'] 
",0
"It is intended for information
","['information']
","['intended'] 
",0
"purposes only, and may not be incorporated into any contract.
","['purposes', 'contract']
","['incorporated'] 
",0
"It is not a commitment to deliver any
","['deliver']
","['commitment'] 
",0
"material, code, or functionality, and should not be relied upon in making purchasing decisions.
","['material', 'code', 'functionality', 'purchasing decisions']
","['relied', 'making'] 
",1
"The
","[]
","[] 
",0
"development, release, and timing of any features or functionality described for Oracle’s products
","['development', 'release', 'features functionality', 'Oracle ’ products']
","['timing', 'described'] 
",1
"remains at the sole discretion of Oracle.
","['remains', 'sole discretion Oracle']
","[] 
",0
"BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Table of Contents
","['Table Contents']
","[] 
",0
"Disclaimer 1
","['Disclaimer']
","[] 
",0
"Executive Summary:  Big Data Analytics with Oracle Advanced Analytics 1
","['Executive Summary', 'Big Data Analytics Oracle Advanced Analytics']
","[] 
",0
"Big Data and Analytics—New Opportunities and New Challenges 3
","['Big Data Analytics—New Opportunities New Challenges']
","[] 
",0
"Predictive Analytics!
","['Predictive Analytics']
","[] 
",0
"3
","[]
","[] 
",0
"Move the Algorithms, Not the Data 4
","['Move Algorithms', 'Data']
","[] 
",0
"SQL and R Support 5
","['SQL R Support']
","[] 
",0
"In-Database Processing with Oracle Advanced Analytics 6
","['In-Database Processing Oracle Advanced Analytics']
","[] 
",0
"Oracle Data Miner Workflow GUI; a SQL Developer extension 8
","['Oracle Data Miner Workflow GUI', 'SQL Developer extension']
","[] 
",0
"Oracle R Enterprise—Integrating Open Source R with the Oracle Database 9
","['Oracle R Enterprise—Integrating Open Source R Oracle Database']
","[] 
",0
"Hadoop, Oracle Big Data Appliance and Big Data SQL 11
","['Hadoop', 'Oracle Big Data Appliance Big Data SQL']
","[] 
",0
"A Platform for Developing Enterprise-wide Predictive Analytics Applications 12
","['A Platform Developing Enterprise-wide Predictive Analytics Applications']
","[] 
",0
"Conclusion 14
","['Conclusion']
","[] 
",0
"1  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"“Essentially, all models are wrong, …but some are useful.”
","['“ Essentially', 'models', '”']
","['wrong'] 
",0
"GEORGE BOX
","['GEORGE BOX']
","[] 
",0
"FAMOUS TWENTIETH CENTURY STATISTICIAN
","['FAMOUS TWENTIETH CENTURY STATISTICIAN']
","[] 
",0
"  Executive Summary:  Big Data Analytics with Oracle Advanced Analytics
","['Executive Summary', 'Big Data Analytics Oracle Advanced Analytics']
","[] 
",0
"The era of “big data” and the “cloud” are driving companies to change.
","['The era “', 'big data ” “ cloud ” driving companies']
","['change'] 
",0
"Just to keep pace, they must
","['pace']
","['Just keep'] 
",0
"learn new skills and implement new practices that leverage those new data sources and technologies.
","['new skills', 'implement new practices', 'new data sources technologies']
","['learn', 'leverage'] 
",1
"Increasing customer expectations from sharing their digital exhaust with corporations in exchange for
","['customer expectations', 'digital exhaust corporations exchange']
","['Increasing', 'sharing'] 
",1
"improved customer interactions and greater perceived value are pushing companies forward.
","['customer interactions', 'value', 'companies']
","['improved', 'perceived', 'pushing'] 
",1
"Big data
","['Big data']
","[] 
",0
"and analytics offer the promise to satisfy these new requirements.
","['analytics', 'satisfy new requirements']
","['offer promise'] 
",0
"Cloud, competition, big data
","['Cloud', 'competition', 'big data']
","[] 
",0
"analytics and next-generation “predictive” applications are driving companies towards achieving new
","['analytics', 'next-generation “ predictive ” applications', 'companies towards']
","['driving', 'achieving'] 
",1
"goals of delivering improved “actionable insights” and better outcomes.
","['goals', 'improved “', 'actionable insights', 'outcomes']
","['delivering', '”'] 
",1
"Traditional BI & Analytics
","['Traditional BI', 'Analytics']
","[] 
",0
"approaches don’t deliver these detailed predictive insights and simply can’t satisfy the emerging
","['approaches', 'detailed predictive insights', '’ satisfy']
","['’', 'emerging'] 
",1
"customer expectations in this new world order created by big data and the cloud.
","['customer expectations', 'new world order', 'big data cloud']
","['created'] 
",0
"Unfortunately, with big data, as the data grows and expands in the three V’s; velocity, volume and
","['big data', 'data grows', 'V ’', 'velocity', 'volume']
","['expands'] 
",0
"variety (data types), new problems emerge.
","['variety', 'data types', 'new problems']
","['emerge'] 
",0
"Data volumes grow and data becomes unmanageable
","['Data volumes', 'data becomes']
","['grow'] 
",0
"and immovable.
","[]
","[] 
",0
"Scalability, security, and information latency become new issues.
","['Scalability', 'security', 'information latency', 'new issues']
","['become'] 
",0
"Dealing with
","[]
","['Dealing'] 
",0
"unstructured data, sensor data and spatial data all introduce new data type complexities.
","['unstructured data', 'sensor data', 'spatial data', 'new data type complexities']
","['introduce'] 
",0
"Traditional advanced analytics has several information technology inherent weak points: data extracts
","['Traditional', 'analytics', 'several information technology', 'inherent weak points', 'data extracts']
","['advanced'] 
",0
"and data movement, data duplication resulting in no single-source of truth, data security exposures,
","['data movement', 'data duplication', 'single-source truth', 'data security exposures']
","['resulting'] 
",0
"separate and many times, depending on the skills of the data analysts/scientists involved, multiple
","['separate many times', 'skills data analysts/scientists', 'multiple']
","['depending', 'involved'] 
",1
"analytical tools (commercial and open source) and languages (SAS, R, SQL, Python, SPSS, etc.
","['analytical tools', 'commercial open source', 'SAS', 'R', 'SQL', 'Python', 'SPSS', 'etc']
","['languages'] 
",0
").
","[]
","[] 
",0
"Problems become particularly egregious during a deployment phase when the worlds of data analysis
","['Problems', 'egregious deployment phase worlds data analysis']
","['become'] 
",0
"and information management collide.
","['information management collide']
","[] 
",0
"Traditional data analysis typically starts with a representative sample or subset of the data that is
","['Traditional data analysis', 'representative sample subset data']
","['typically starts'] 
",0
"exported to separate analytical servers and tools (SAS, R, Python, SPSS, etc.)
","['separate analytical servers tools', 'SAS', 'R', 'Python', 'SPSS']
","['exported'] 
",0
"that have been
","[]
","[] 
",0
"especially designed for statisticians and data scientists to analyze data.
","['statisticians data scientists', 'data']
","['especially designed', 'analyze'] 
",1
"The analytics they perform
","['The analytics']
","['perform'] 
",0
"range from simple descriptive statistical analysis to advanced, predictive and prescriptive analytics.
","['range', 'simple descriptive statistical analysis', 'predictive prescriptive analytics']
","['advanced'] 
",0
"If
","[]
","[] 
",0
"a data scientist builds a predictive model that is determined to be useful and valuable, then IT needs to
","['data scientist builds', 'predictive model', 'IT']
","['determined', 'needs'] 
",1
"2  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"be involved to figure out deployment and enterprise deployment and application integration issues
","['involved figure deployment enterprise deployment application integration issues']
","[] 
",0
"become the next big challenge.
","['next big challenge']
","['become'] 
",0
"The predictive model(s)—and all its associated data preparation and
","['The predictive model', 'data preparation']
","['—and associated'] 
",0
"transformation steps—have to be somehow translated to SQL and recreated inside the database in
","['transformation', 'translated SQL', 'database']
","['steps—have', 'recreated'] 
",1
"order to apply the models and make predictions on the larger datasets maintained inside the data
","['order apply models', 'predictions', 'datasets', 'data']
","['make', 'maintained'] 
",1
"warehouse.
","['warehouse']
","[] 
",0
"This model translation phase introduces tedious, time consuming and expensive manual
","['This model translation phase', 'time', 'expensive manual']
","['introduces', 'consuming'] 
",1
"coding steps from the original statistical language (SAS, R, and Python) into SQL.
","['steps', 'original statistical language', 'SAS', 'R', 'Python', 'SQL']
","['coding'] 
",0
"DBAs and IT must
","['IT']
","['DBAs'] 
",0
"somehow “productionize” these separate statistical models inside the database and/or data warehouse
","['” separate statistical models', 'database and/or data warehouse']
","['productionize'] 
",0
"for distribution throughout the enterprise.
","['distribution', 'enterprise']
","[] 
",0
"Some vendors will charge for specialized products and
","['Some vendors', 'specialized products']
","['charge'] 
",0
"options for just for predictive model deployment.
","['options', 'model deployment']
","['predictive'] 
",0
"This is where many advanced analytics projects fail.
","['This many advanced analytics projects']
","['fail'] 
",0
"Add Hadoop, sensor data, tweets, and expanding big data reservoirs and the entire “data to actionable
","['Add Hadoop', 'sensor data', 'tweets', 'big data reservoirs', 'entire “ data actionable']
","['expanding'] 
",0
"insights” process becomes more challenging.
","['insights', 'process becomes']
","['”', 'challenging'] 
",1
"Not with Oracle.
","['Oracle']
","[] 
",0
"Oracle delivers a big data and analytics platform that eliminates the traditional
","['Oracle delivers', 'big data analytics platform']
","['eliminates'] 
",0
"extract, move, load, analyze, export, move load paradigm.
","['extract', 'move', 'load', 'analyze', 'export', 'load paradigm']
","['move'] 
",0
"With Oracle Database 12c and the Oracle
","['Oracle Database', 'Oracle']
","[] 
",0
"Advanced Analytics Option, big data management and big data analytics are designed into the data
","['Advanced Analytics Option', 'big data management', 'big data analytics', 'data']
","['designed'] 
",0
"management platform from the beginning.
","['management platform beginning']
","[] 
",0
"Oracle’s multiple decades of R&D investment in developing
","['Oracle ’ multiple decades R', 'D investment']
","['developing'] 
",0
"the industry’s leading data management platform, Oracle SQL, Big Data SQL, Oracle Exadata, Oracle
","['industry', 'data management platform', 'Oracle SQL', 'Big Data SQL', 'Oracle Exadata', 'Oracle']
","['’ leading'] 
",0
"Big Data Appliance and integration with open source R are seamlessly combined and integrated into a
","['Big Data Appliance integration', 'open source R']
","['seamlessly combined'] 
",0
"single platform—the Oracle Database.
","['single platform—the Oracle Database']
","[] 
",0
"Oracle’s vision is a big data and analytic
","['Oracle ’ vision', 'big data']
","[] 
",0
"platform for the era of big data and cloud to:
","['platform era', 'big data cloud']
","[] 
",0
" Make big data and analytics simple
","['\uf0b7', 'big data analytics']
","['Make'] 
",0
"(for any data size, on any computer
","['data size', 'computer']
","[] 
",0
"infrastructure and any variety of data, in any
","['infrastructure variety data']
","[] 
",0
"combination) and
","['combination']
","[] 
",0
" Make big data and analytics deployment
","['\uf0b7', 'big data analytics deployment']
","['Make'] 
",0
"simple (as a service, as a platform, as an
","['simple', 'service', 'platform']
","[] 
",0
"application)
","['application']
","[] 
",0
"Oracle Advanced Analytics eliminates data movement and combines big data management with big data analytics.
","['Oracle Advanced Analytics', 'data movement combines', 'big data management', 'big data analytics']
","['eliminates'] 
",0
"Oracle Advanced Analytics offers a wide library of powerful in-database algorithms and integration with
","['Oracle Advanced Analytics offers', 'wide library powerful in-database algorithms integration']
","[] 
",0
"2  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"open source R that together can solve a wide variety of business problems and can be accessed via
","['open source R', 'wide variety business problems']
","['together solve', 'accessed'] 
",1
"SQL, R or GUI.
","['SQL', 'R GUI']
","[] 
",0
"Oracle Advanced Analytics, an option to the Oracle Database Enterprise Edition 12c,
","['Oracle Advanced Analytics', 'option Oracle Database Enterprise Edition']
","[] 
",0
"extends the database into an enterprise-wide analytical platform for data-driven problems such as
","['extends', 'enterprise-wide analytical platform', 'data-driven problems']
","['database'] 
",0
"churn prediction, customer segmentation, fraud and anomaly detection, identifying cross-sell and up-
","['churn prediction', 'customer segmentation', 'fraud', 'anomaly detection']
","['identifying'] 
",0
"sell opportunities, market basket analysis, and text mining and sentiment analysis.
","['sell opportunities', 'market basket analysis', 'text mining sentiment analysis']
","[] 
",0
"Oracle Advanced
","['Oracle Advanced']
","[] 
",0
"Analytics empowers data analyst, data scientists and business analysts to more extract knowledge,
","['Analytics empowers data analyst', 'data scientists business analysts', 'knowledge']
","['extract'] 
",0
"discover new insights and make informed predictions—working directly with large data volumes in the
","['new insights', 'large data volumes']
","['make', 'predictions—working'] 
",1
"Oracle Database.
","['Oracle Database']
","[] 
",0
"Data analysts/scientists have choice and flexibility in how they interact with Oracle Advanced
","['Data analysts/scientists choice flexibility', 'interact Oracle Advanced']
","[] 
",0
"Analytics.
","['Analytics']
","[] 
",0
"Oracle Data Miner is an Oracle SQL Developer extension designed for data analysts that
","['Oracle Data Miner Oracle SQL Developer extension', 'data analysts']
","['designed'] 
",0
"provides an easy to use “drag and drop” workflow GUI to the Oracle Advanced Analytics SQL data
","['easy use “', 'drop ”', 'GUI Oracle Advanced Analytics SQL data']
","['provides', 'drag'] 
",1
"mining functions (Oracle Data Mining).
","['mining functions', 'Oracle Data Mining']
","[] 
",0
"Oracle SQL Developer is a free integrated development
","['Oracle SQL Developer', 'development']
","['integrated'] 
",0
"environment that simplifies the development and management of Oracle Database in both traditional
","['environment simplifies development management Oracle Database']
","[] 
",0
"and Cloud deployments.
","['Cloud deployments']
","[] 
",0
"When Oracle Data Miner users are satisfied with their analytical
","['Oracle Data Miner users']
","['satisfied'] 
",0
"methodologies, they can share their workflows with other analysts and/or generate SQL scripts to hand
","['methodologies', 'share', 'analysts', 'generate SQL scripts hand']
","['workflows', 'and/or'] 
",1
"to their DBAs to accelerate model deployment.
","['DBAs accelerate model deployment']
","[] 
",0
"Oracle Data Miner also provides a PL/SQL API for
","['Oracle Data Miner', 'PL/SQL API']
","['also provides'] 
",0
"workflow scheduling and automation.
","['automation']
","['scheduling'] 
",0
"R programmers and data scientists can use the familiar open source R statistical programming
","['R programmers', 'scientists', 'familiar open source R', 'statistical programming']
","['data', 'use'] 
",1
"language console, RStudio or any IDE to work directly with data inside the database and leverage
","['language console', 'RStudio IDE work', 'data', 'database leverage']
","[] 
",0
"Oracle Advanced Analytics’ R integration with the database (Oracle R Enterprise).
","['Oracle Advanced Analytics ’ R integration database', 'Oracle R Enterprise']
","[] 
",0
"Oracle Advanced
","['Oracle Advanced']
","[] 
",0
"Analytics’ Oracle R Enterprise provides transparent SQL to R translation to equivalent SQL and Oracle
","['Analytics', 'Oracle R Enterprise', 'transparent SQL R translation', 'equivalent SQL Oracle']
","['’', 'provides'] 
",1
"Data Mining functions for in-database performance, parallelism, and scalability—this making R ready
","['Data Mining functions', 'in-database performance', 'parallelism', 'scalability—this making R ready']
","[] 
",0
"for the enterprise.
","['enterprise']
","[] 
",0
"Application developers, using the ODM SQL data mining functions and ORE R integration can build
","['Application developers', 'ODM SQL data mining functions ORE R integration build']
","['using'] 
",0
"completely automated predictive analytic solutions that leverage the strengths of the database and the
","['predictive analytic solutions', 'strengths database']
","['completely automated', 'leverage'] 
",1
"flexibly of R to integrate Oracle Advanced Analytics analytical solutions into BI dashboards and
","['R integrate Oracle Advanced Analytics', 'analytical solutions BI dashboards']
","[] 
",0
"enterprise applications.
","['enterprise applications']
","[] 
",0
"By integrating big data management and big data analytics into the same powerful Oracle Database
","['big data management', 'big data analytics', 'powerful Oracle Database']
","['integrating'] 
",0
"12c data management platform, Oracle eliminates data movement, reduces total cost of ownership
","['data management platform', 'Oracle', 'data movement', 'reduces', 'cost ownership']
","['eliminates', 'total'] 
",1
"and delivers the fastest way to deliver enterprise-wide predictive analytics solutions and applications.
","['delivers', 'way', 'enterprise-wide predictive analytics solutions applications']
","[] 
",0
"3  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Big Data and Analytics—New Opportunities and New Challenges
","['Big Data Analytics—New Opportunities New Challenges']
","[] 
",0
"Gartner characterizes big data as: ""high volume, velocity, and/or variety information assets that demand new,
","['Gartner', 'big data', 'high volume', 'velocity', 'and/or variety information assets']
","['characterizes', 'demand'] 
",1
"innovative forms of processing for enhanced decision making, business insights or process optimization.""
","['innovative forms', 'enhanced decision making', 'business insights process optimization']
","['processing'] 
",0
"However,
","[]
","[] 
",0
"for many, this is not new.
","[]
","[] 
",0
"Companies have been data mining large volumes of data for years.
","['Companies data', 'large volumes data years']
","['mining'] 
",0
"What’s been new
","[]
","['’'] 
",0
"and more challenging is the increasing pace of the “big data” volumes, velocities and varieties of sources coupled
","['pace “', 'big data ” volumes', 'velocities varieties sources']
","['challenging increasing', 'coupled'] 
",1
"with new customer expectations of what new “actionable insights” can be achieved.
","['new customer expectations', 'new “', 'actionable insights']
","['” achieved'] 
",0
"This places new demands on
","['new demands']
","['places'] 
",0
"Information Technology (IT) departments, data scientist and data analysts and the departments and lines of
","['Information Technology', 'IT', 'departments', 'data scientist data analysts departments lines']
","[] 
",0
"business they support e.g.- marketing, customer service, support, R&D and operations.
","['business support', 'e.g.- marketing', 'customer service', 'support', 'R', 'D operations']
","[] 
",0
"Unfortunately, as big data grows and expands over time in its three V’s; velocity, volume and variety, new problems
","['big data grows expands time', 'V ’', 'velocity', 'volume variety', 'new problems']
","[] 
",0
"emerge.
","['emerge']
","[] 
",0
"Data volumes grow and eventually become near immovable.
","['Data volumes']
","['grow eventually become'] 
",0
"Eventually at some point, it becomes
","['point', 'becomes']
","[] 
",0
"impractical to move large data amounts to separate servers for the data analysis.
","['impractical move', 'large data amounts', 'separate servers data analysis']
","[] 
",0
"During the big data explosion,
","['big data explosion']
","[] 
",0
"many problems are experienced such as data movement, data duplication, security, creation of “data analysis
","['many problems', 'data movement', 'data duplication', 'security', 'creation “ data analysis']
","['experienced'] 
",0
"sprawl-marts”, separation of data management from data analysis and worse, information latency expands,
","['sprawl-marts ”', 'separation data management data analysis worse', 'information latency']
","['expands'] 
",0
"oftentimes to multiple days and weeks.
","['multiple days weeks']
","[] 
",0
"Traditional data analysis methods contribute to these problems.
","['Traditional data analysis methods', 'problems']
","['contribute'] 
",0
"Data analysts and data scientist typically have their
","['Data analysts data scientist']
","[] 
",0
"own special “tools” that they’ve learned to use (SAS, R, SPSS or Python, etc.)
","['special “ tools', 'use', 'SAS', 'R', 'SPSS Python']
","['” ’ learned'] 
",0
"so require data extracts from the
","['require data extracts']
","[] 
",0
"database /data warehouse, transforms and loads to dedicated, separate analytical servers.
","['database /data warehouse', 'loads', 'separate analytical servers']
","['transforms', 'dedicated'] 
",1
"If a data scientist builds
","['data scientist builds']
","[] 
",0
"a “good” predictive model, then a new problem emerges.
","['good ”', 'predictive model', 'new problem']
","['emerges'] 
",0
"Deployment of that model to where and when it is most
","['Deployment model']
","[] 
",0
"needed and integration into applications e.g.- BI dashboards, call centers, websites, ATMs and mobile devices
","['integration applications', 'e.g.- BI dashboards', 'call centers', 'websites', 'ATMs mobile devices']
","['needed'] 
",0
"becomes the next big challenge for IT.
","['becomes', 'big challenge IT']
","[] 
",0
"The predictive model(s)—and all the associated data preparation and
","['The predictive model', 'data preparation']
","['—and associated'] 
",0
"transformation steps—have to be recreated in the destination platform to make the predictions on the larger data
","['transformation steps—have', 'destination platform', 'predictions', 'data']
","['recreated', 'make'] 
",1
"tables.
","['tables']
","[] 
",0
"For Oracle environments, this export, data analysis, import results outer loop complicates the data analysis
","['Oracle environments', 'export', 'data analysis', 'import results', 'loop complicates data analysis']
","['outer'] 
",0
"unnecessarily and introduces the time consuming and expensive model deployment phase.
","['introduces time', 'expensive model deployment phase']
","['consuming'] 
",0
"IT is asked to
","['IT']
","['asked'] 
",0
"“productionize” the models and re-implement them using SQL inside the database.
","['“ productionize', '” models', 'SQL', 'database']
","['using'] 
",0
"The challenge is that the models were originally created using a statistical programming language (SAS, R, SPSS
","['The challenge models', 'statistical programming language', 'SAS', 'R', 'SPSS']
","['originally created using'] 
",0
"and Python.)
","['Python']
","[] 
",0
"but to productionize them, they must run as SQL functions inside the database.
","['productionize', 'SQL functions', 'database']
","['run'] 
",0
"This is where the big
","[]
","[] 
",0
"time sink occurs and errors can be introduced.
","['time sink', 'errors']
","['occurs', 'introduced'] 
",1
"For organizations who strive to be leaders, efficient data collection,
","['organizations', 'strive leaders', 'efficient data collection']
","[] 
",0
"data management, analysis, and deployment of predictive models, insights and actionable business intelligence are
","['data management', 'analysis', 'deployment predictive models', 'insights', 'actionable business intelligence']
","[] 
",0
"the keys to their success.
","['keys success']
","[] 
",0
"Traditional data analysis methods just won’t suffice.
","['Traditional data analysis methods', '’ suffice']
","[] 
",0
"Add Hadoop, sensor data, tweets,
","['Add Hadoop', 'sensor data', 'tweets']
","[] 
",0
"and ever expanding new data reservoirs and the whole problem just gets worse.
","['new data reservoirs', 'whole problem']
","['ever expanding', 'gets'] 
",1
"Predictive Analytics!
","['Predictive Analytics']
","[] 
",0
"Predictive analytics is the process of automatically sifting through large amounts of data to find previously hidden
","['Predictive analytics process', 'large amounts data']
","['automatically sifting', 'find previously hidden'] 
",1
"patterns, discover valuable new insights and make informed predictions for data-driven problems such as:
","['patterns', 'valuable new insights', 'informed predictions', 'data-driven problems']
","['make'] 
",0
" Predicting customer behaviors, identifying cross-selling and up-selling opportunities
","['\uf0b7', 'customer behaviors', 'cross-selling up-selling opportunities']
","['Predicting', 'identifying'] 
",1
" Anticipating customer churn, employee attrition and student retention
","['\uf0b7', 'customer churn', 'employee attrition student retention']
","['Anticipating'] 
",0
" Detecting anomalies and combating potential tax, medical or expense fraud,
","['\uf0b7', 'anomalies', 'potential tax', 'medical expense fraud']
","['Detecting', 'combating'] 
",1
" Understanding hidden customer segments and understanding customer sentiment,
","['\uf0b7 Understanding', 'customer segments', 'customer sentiment']
","['hidden', 'understanding'] 
",1
" Identifying key factors that drive outcomes and delivering improved quality
","['\uf0b7 Identifying', 'key factors', 'outcomes', 'improved quality']
","['drive', 'delivering'] 
",1
"4  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Predictive Analytics as a technology has been delivering measurable value for years.
","['Predictive Analytics technology', 'measurable value years']
","['delivering'] 
",0
"Predictive Analytics climbed
","['Predictive Analytics']
","['climbed'] 
",0
"it’s was up Gartner’s Hype Cycle for Emerging Technologies and reached the Gartner’s enviable “plateau of
","['’ Gartner ’ Hype Cycle Emerging', 'Gartner ’', 'enviable “ plateau']
","['reached'] 
",0
"productivity” in 2013.
","['productivity ”']
","[] 
",0
"Today in 2015, predictive analytics are being implemented and deployed in enterprises and
","['Today', 'predictive analytics', 'deployed enterprises']
","['implemented'] 
",0
"applications ranging from predicting churn and employee turnover, to flagging medical fraud and tax non-compliance
","['applications', 'churn employee turnover', 'medical fraud tax non-compliance']
","['ranging predicting', 'flagging'] 
",1
"to targeted selling and real-time recommendation engines.
","['real-time recommendation engines']
","['targeted selling'] 
",0
"As big data analytics technologies and user adoptions
","['big data analytics technologies', 'adoptions']
","['user'] 
",0
"evolve, mature and expand, predictive analytics use cases and integrated “predictive” applications that push “the art
","['evolve', 'mature expand', 'predictive analytics', 'cases', '“ predictive ” applications', 'art']
","['use', 'integrated', 'push'] 
",1
"of the possible” are emerging every day and are constantly raising the bar of new user expectations.
","['possible ”', 'every day', 'bar', 'new user expectations']
","['emerging', 'constantly raising'] 
",1
"Oracle Advanced Analytics provides support for these data driven problems by offering a wide range of powerful
","['Oracle Advanced Analytics', 'support data', 'problems', 'wide range']
","['provides', 'offering'] 
",1
"workhorse data mining algorithms that have been implemented in a relational database environment (RDBMS).
","['workhorse data mining algorithms', 'relational database environment', 'RDBMS']
","['implemented'] 
",0
"Algorithms are implemented as SQL functions inside the database.
","['Algorithms', 'SQL functions', 'database']
","['implemented'] 
",0
"Oracle Advanced Analytics’ data mining
","['Oracle Advanced Analytics ’ data mining']
","[] 
",0
"algorithms hence leverage all related SQL features and can mine data in its original star schema representation
","['algorithms hence leverage', 'SQL features', 'data', 'original star schema representation']
","['related', 'mine'] 
",1
"including standard structured tables and views, transactional data and aggregations, unstructured i.e.- CLOB data
","['standard', 'tables views', 'transactional data aggregations', 'unstructured i.e.- CLOB data']
","['including', 'structured'] 
",1
"types (using Oracle Text to parse out “tokens”) and spatial data.
","['types', 'Oracle Text parse “', '”', 'spatial data']
","['using', 'tokens'] 
",1
"Oracle Advanced Analytics in-database SQL data
","['Oracle Advanced Analytics', 'in-database SQL data']
","[] 
",0
"mining functions take advantage of parallelism inside the database for both model build and model apply, honor all
","['mining functions', 'advantage parallelism', 'database model', 'build model apply', 'honor']
","['take'] 
",0
"security and user privilege schemes, adhere to revision control and audit tracking database features and can mine
","['security user privilege schemes', 'adhere revision control audit', 'database features']
","['tracking', 'mine'] 
",1
"data in its native and potentially encrypted form inside the Oracle Database.
","['data', 'encrypted form', 'Oracle Database']
","[] 
",0
"Oracle Advanced Analytics 12c data mining functions are implemented as SQL functions that can be accessed by SQL, PL/SQL, R
","['Oracle Advanced Analytics', 'data mining functions', 'SQL functions', 'SQL', 'PL/SQL', 'R']
","['implemented', 'accessed'] 
",1
"and the Oracle Data Miner GUI.
","['Oracle Data Miner GUI']
","[] 
",0
"Move the Algorithms, Not the Data
","['Move Algorithms', 'Data']
","[] 
",0
"Data is big; algorithms are small.
","['Data']
","[] 
",0
"Hence, it makes logical sense to move the algorithms to the data rather than
","['Hence', 'logical sense move']
","['makes', 'algorithms data'] 
",1
"moving the data to the algorithms.
","['data']
","['moving'] 
",0
"Oracle realized this big data and analytics data challenge in 1999 when it
","['Oracle', 'big data analytics data challenge']
","['realized'] 
",0
"acquired Thinking Machines Corporation’s data mining technology and development team.
","['Thinking', 'Corporation ’ data mining technology development team']
","['acquired'] 
",0
"At that time, Oracle
","['time', 'Oracle']
","[] 
",0
"commenced on a strategy to develop traditional and cutting edge machine learning algorithms and statistical
","['strategy', 'traditional cutting edge machine']
","['commenced', 'develop', 'learning'] 
",1
"functions as native SQL functions with full SQL language support.
","['functions', 'native SQL functions', 'full SQL language support']
","[] 
",0
"With Oracle Advanced Analytics, data mining
","['Oracle Advanced Analytics', 'data mining']
","[] 
",0
"5  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"algorithms run as native SQL functions; not as PL/SQL scripts, call-outs or extensibility framework add-ins.
","['algorithms', 'native SQL functions', 'PL/SQL scripts', 'call-outs extensibility framework add-ins']
","['run'] 
",0
"Models
","['Models']
","[] 
",0
"are first class database objects that can be built, applied, shared, and audited.
","['class database']
","['objects built', 'applied', 'shared', 'audited'] 
",1
"In the early 2000’s, starting in Oracle Data Mining Release 9.2i, Oracle’s first data mining algorithms took advantage
","['’', 'Oracle Data Mining Release', 'Oracle ’', 'mining algorithms', 'advantage']
","['starting', 'first data', 'took'] 
",1
"of available core Database’s strengths—specifically, counting, parallelism, scalability and other database
","['available core Database ’', 'parallelism', 'scalability database']
","['counting'] 
",0
"architectural underpinnings.
","['architectural underpinnings']
","[] 
",0
"Essentially, the first two Oracle data mining algorithms, Naïve Bayes and A Priori
","['Oracle data mining algorithms', 'Naïve Bayes A Priori']
","[] 
",0
"algorithms, are based on counting principles.
","['algorithms', 'counting principles']
","['based'] 
",0
"They count everything very quickly and then assemble conditional
","['everything']
","['count'] 
",0
"probability predictive models—all 100% inside the database.
","['probability', '%', 'inside database']
","['predictive'] 
",0
"Neither the data, the predictive models nor the results
","['Neither data', 'predictive models results']
","[] 
",0
"ever leave the database.
","['leave database']
","[] 
",0
"OAA Naïve Bayes algorithm can quickly builds predictive models to predict e.g.-, “Who will churn?”, “Which
","['OAA Naïve Bayes', 'builds', 'predictive models', 'Which']
","['algorithm', 'predict', 'churn'] 
",1
"customers are most likely to purchase Product A?”, or “What is the probability that an item will fail?”  Let’s take an
","['customers', 'likely purchase', 'A', '”', 'probability item', '” Let ’']
","['Product', '“', 'fail', 'take'] 
",1
"example in a bit more detail for comprehension.
","['example bit', 'detail comprehension']
","[] 
",0
"Let’s say we are interested in selling Product A (e.g.- a motorcycle
","['’', 'interested selling Product A', 'e.g.- motorcycle']
","['Let', 'say'] 
",1
"or $500 shoes, etc.).
","['shoes']
","[] 
",0
"The Oracle Advanced Analytics data mining algorithms, specifically the Naïve Bayes
","['The Oracle Advanced Analytics data mining algorithms', 'Naïve Bayes']
","[] 
",0
"algorithm, of all the customers who purchased Product A, it counts how many customers were male vs. female.
","['algorithm', 'customers', 'Product A', 'many customers', 'female']
","['purchased', 'counts', 'male'] 
",1
"How many rent an apartment vs. owns their own home?
","['many rent apartment', 'home']
","['owns'] 
",0
"How many have children and how many?
","['many children']
","[] 
",0
"Each of these
","[]
","[] 
",0
"answers involves counts that, taken together, can form a complex conditional probability model that accurately
","['answers', 'counts', 'form', 'complex conditional probability model']
","['involves', 'taken'] 
",1
"predicts whom we should target to increase our likelihood of selling more of Product A.
","['predicts', 'likelihood', 'Product A']
","['target increase', 'selling'] 
",1
"OAA’s A Priori “market basket analysis” algorithm counts items in each customer’s transactional “baskets” while
","['OAA', 'A Priori “ market basket analysis ” algorithm', 'items customer ’', 'transactional “ baskets']
","['’', 'counts', '”'] 
",1
"looking for co-occurring items e.g.- A + B appear together frequently, and then provides conditional probability AR
","['co-occurring items', 'A + B', 'conditional probability AR']
","['looking', 'e.g.-', 'appear', 'provides'] 
",1
"rules.
","['rules']
","[] 
",0
"For example:
","['example']
","[] 
",0
"IF, “Cereal” AND “Bananas” appear in the same customer’s basket,
","['IF', '“ Cereal ” AND “ Bananas ”', 'customer ’ basket']
","['appear'] 
",0
"THEN, the “Milk” is also likely to appear in the basket.
","['THEN', '“ Milk ”', 'basket']
","['appear'] 
",0
"WITH Confidence = 87%, and Support = 11%.
","['WITH Confidence', '%', 'Support', '%']
","['=', '='] 
",1
"Armed with these types of new customer insights from Oracle Advanced Analytics, a store could decide to place the
","['Armed', 'new customer insights Oracle Advanced Analytics', 'store', 'place']
","['types', 'decide'] 
",1
"milk near the cereal and bananas, offer new promotional “breakfast kit” product bundles or make real-time customer
","['milk', 'cereal bananas', 'new promotional “ breakfast kit ” product bundles', 'real-time customer']
","['offer', 'make'] 
",1
"specific recommendations as the customer checks-out.
","['specific recommendations customer checks-out']
","[] 
",0
"This is just a simple example of the types of ways that big
","['This simple example types ways']
","[] 
",0
"data analytics can find “actionable insights” from data.
","['data analytics', '“ actionable insights', 'data']
","['find', '”'] 
",1
"Obviously, more data, more advanced analytics
","['data', 'analytics']
","['advanced'] 
",0
"methodologies and fast enterprise wide deployment can open new doors to many new big data and analytics
","['methodologies', 'enterprise wide deployment', 'open new doors', 'many new big data analytics']
","['fast'] 
",0
"applications and solutions possibilities.
","['applications solutions possibilities']
","[] 
",0
"SQL and R Support
","['SQL R Support']
","[] 
",0
"Where SQL is the standard language for data management and has been for 40+ years, for data analysis, various
","['SQL', 'standard language data management', 'years', 'data analysis']
","[] 
",0
"languages compete—R, SAS, Python and SQL and others.
","['languages', 'SAS', 'Python SQL others']
","['compete—R'] 
",0
"SAS, S+, SQL, SPSS and Matlab have been long time
","['SAS', 'S+', 'SQL', 'SPSS Matlab', 'long time']
","[] 
",0
"favorites, but in recent past years, open source R especially has surged to the top of the pack and Python and
","['favorites', 'recent past years', 'open source R', 'top pack Python']
","['especially surged'] 
",0
"others have emerged.
","['others']
","['emerged'] 
",0
"Per the KDD Nuggets data mining industry community annual polls
","['Per KDD Nuggets', 'mining industry community', 'annual polls']
","['data'] 
",0
"(http://www.kdnuggets.com/polls/), R and SQL currently compete for #1 and #2 positions, respectively.
","['http', '//www.kdnuggets.com/polls/', 'R SQL', 'positions']
","['currently compete'] 
",0
"The good news is that Oracle Advanced Analytics supports both languages—SQL and R.  There are legions of
","['The good news Oracle Advanced Analytics', 'languages—SQL R.', 'legions']
","['supports'] 
",0
"developers who know SQL for data management and Oracle provides support for data mining and advanced
","['developers', 'SQL data management Oracle', 'support data mining']
","['know', 'provides', 'advanced'] 
",1
"analytics via Oracle Advanced Analytics’ SQL data mining functions and provides tight, industry leading integration
","['analytics', 'Oracle Advanced Analytics ’ SQL data mining functions', 'industry', 'integration']
","['provides', 'leading'] 
",1
"with open source R statistical programming language.
","['open source R', 'statistical programming language']
","[] 
",0
"Most Oracle customers are very familiar with SQL as a language for query, reporting, and analysis of structured
","['Oracle customers', 'familiar SQL language query', 'reporting', 'analysis']
","['structured'] 
",0
"data.
","['data']
","[] 
",0
"It is the de facto standard for analysis and the technology that underlies most BI tools.
","['standard analysis technology underlies BI tools']
","[] 
",0
"R is a widely popular
","['R']
","[] 
",0
"open source programming language for statistical analysis that is free and because of that is taught in most data
","['open source', 'language', 'statistical analysis', 'free taught data']
","['programming'] 
",0
"6  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"science educational programs.
","['science', 'educational programs']
","[] 
",0
"A growing number of data analysts, data scientists, researchers, and academics start
","['number data analysts', 'data scientists', 'researchers', 'academics']
","['growing', 'start'] 
",1
"by learning to use R, leading to a growing pool of R programmers who can now work with their data inside the
","['use R', 'pool R programmers', 'data']
","['learning', 'leading growing', 'work'] 
",1
"Oracle Database using either SQL or R languages.
","['Oracle Database', 'SQL R']
","['using', 'languages'] 
",1
"Over the past decade and one-half,  Oracle Advanced Analytics has matured and has been developed to now in
","['past decade one-half', 'Oracle Advanced Analytics']
","['matured developed'] 
",0
"Oracle 12c, the Oracle Advanced Analytics Option delivers nearly twenty scalable, parallelized, in-database
","['Oracle', 'Oracle Advanced Analytics Option delivers']
","[] 
",0
"implementations of workhorse predictive analytics algorithms.
","['implementations', 'predictive analytics']
","['workhorse', 'algorithms'] 
",1
"Oracle Advanced Analytics exposes these data
","['Oracle Advanced Analytics', 'data']
","['exposes'] 
",0
"mining algorithms as SQL functions that are accessible via SQL, R language and the Oracle Data Miner GUI, an
","['mining algorithms SQL functions', 'SQL', 'R language Oracle Data Miner GUI']
","[] 
",0
"extension to Oracle SQL Developer for the most common data driven problems e.g.- clustering, regression,
","['extension Oracle SQL Developer', 'common data', 'problems', 'e.g.- clustering', 'regression']
","[] 
",0
"prediction, associations, text mining, associations analysis, etc.
","['prediction', 'associations', 'text mining', 'associations analysis']
","[] 
",0
"All Oracle Advanced Analytics algorithms are
","['All Oracle Advanced Analytics algorithms']
","[] 
",0
"implemented deep inside the database and take full advantage of the Oracle Database’s industry leading scalability,
","['database', 'full advantage Oracle Database ’ industry', 'scalability']
","['implemented', 'take', 'leading'] 
",1
"security, SQL functions, integration, ETL, Cloud, structured, unstructured and spatial data types features and
","['security', 'SQL functions', 'integration', 'ETL', 'Cloud', 'unstructured spatial data types features']
","['structured'] 
",0
"strengths and can be accessed via both SQL and R—and GUI.
","['strengths', 'SQL R—and GUI']
","['accessed'] 
",0
"Hence, you can think of Oracle Advanced Analytics like this…
","['Oracle Advanced Analytics', 'this…']
","['think'] 
",0
"Oracle Advanced Analytics extends the SQL language to add powerful analytical verbs e.g.- predict, detect, associate, cluster.
","['Oracle Advanced Analytics', 'SQL language', 'powerful analytical verbs', 'e.g.- predict', 'detect', 'associate', 'cluster']
","['extends'] 
",0
"In-Database Processing with Oracle Advanced Analytics
","['In-Database Processing Oracle Advanced Analytics']
","[] 
",0
"Oracle Advanced Analytics extends the database into a comprehensive advanced analytics platform for big data
","['Oracle Advanced Analytics', 'database comprehensive advanced analytics', 'big data']
","['extends', 'platform'] 
",1
"analytics.
","['analytics']
","[] 
",0
"With Oracle, powerful analytics are performed directly on data in the database.
","['Oracle', 'powerful analytics', 'data database']
","['performed'] 
",0
"Results, insights, and real-
","['Results', 'insights', 'real-']
","[] 
",0
"time predictive models are available and managed by the database.
","['time', 'predictive models', 'database']
","['managed'] 
",0
"A data mining model is a schema object in the database, built via a PL/SQL API that prepares the data, learns the
","['A data mining model schema', 'object database', 'PL/SQL API', 'data', 'learns']
","['built', 'prepares'] 
",1
"hidden patterns to build an OAA model which can then be scored via built-in OAA data mining SQL functions.
","['hidden patterns', 'OAA model', 'built-in OAA data mining SQL functions']
","['build', 'scored'] 
",1
"When
","[]
","[] 
",0
"building models, Oracle Advanced Analytics leverages existing scalable technology (e.g.-, parallel execution, bitmap
","['building models', 'Oracle Advanced Analytics', 'scalable technology', 'parallel execution', 'bitmap']
","['leverages existing'] 
",0
"indexes, aggregation techniques) and additional developed new Oracle Advanced Analytics and Oracle Database
","['indexes', 'aggregation techniques', 'new Oracle Advanced Analytics Oracle Database']
","['developed'] 
",0
"technologies (e.g.-, recursion within the parallel infrastructure, IEEE float, automatic data preparation for binning,
","['technologies', 'recursion', 'parallel infrastructure', 'IEEE float', 'automatic data preparation binning']
","[] 
",0
"handling missing values, support for unstructured data i.e.- text, etc.
","['values', 'support', 'data', 'i.e.- text']
","['handling missing', 'unstructured'] 
",1
").
","[]
","[] 
",0
"The true power of embedding data mining functions within the database as SQL functions is most evident when
","['The true power', 'data mining functions', 'database SQL functions evident']
","['embedding'] 
",0
"scoring data mining models.
","['data mining models']
","['scoring'] 
",0
"Once the models have been built by learning the hidden patterns in the historical data,
","['models', 'hidden patterns', 'historical data']
","['built learning'] 
",0
"7  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"applying the models to new data inside the database is blazingly fast.
","['models', 'new data', 'database']
","['applying'] 
",0
"Scoring is then just a row-wise function.
","['row-wise function']
","['Scoring'] 
",0
"Hence, Oracle Advanced Analytics can “score” many millions of records in seconds and is designed to support
","['Hence', 'Oracle Advanced Analytics “', '”', 'many millions records seconds', 'support']
","['score', 'designed'] 
",1
"online transactional processing (OLTP) environments.
","['online transactional processing', 'OLTP', 'environments']
","[] 
",0
"Using Exadata’s “smart scan” technology it gets better.
","['Exadata ’ “', 'smart scan ” technology']
","['Using', 'gets'] 
",1
"With Oracle Advanced Analytics running in an Exadata
","['Oracle Advanced Analytics', 'Exadata']
","['running'] 
",0
"environment, SQL predicates and OAA predictive models get pushed down to the hardware layer for execution.
","['environment', 'SQL', 'OAA', 'predictive models', 'hardware layer execution']
","['predicates', 'get pushed'] 
",1
" For Oracle Exadata environments, pushed to Exadata storage level for execution
","['\uf0b7', 'Oracle Exadata environments', 'Exadata storage level execution']
","['pushed'] 
",0
" For Oracle Big Data Appliance (Hadoop) environments, pushed to BDA storage level for execution.
","['\uf0b7', 'Oracle Big Data Appliance', 'Hadoop', 'environments', 'BDA storage level execution']
","['pushed'] 
",0
"In both cases, only those records that satisfy the predicates are pulled from disk for further processing inside the
","['cases', 'records', 'predicates', 'disk processing']
","['satisfy', 'pulled'] 
",1
"database.
","['database']
","[] 
",0
"For example, find the US customers likely to churn:
","['example', 'US customers', 'likely churn']
","['find'] 
",0
"Automatic Data Preparation, Data Types, Star Schemas and “Nested Tables”
","['Automatic Data Preparation', 'Data Types', 'Star Schemas “ Nested Tables ”']
","[] 
",0
"Typically, in order to perform proper analysis on data, analysts have to make explicit decisions about how to “bin”
","['order perform', 'proper analysis data', 'analysts', 'explicit decisions', 'bin ”']
","['make', '“'] 
",1
"data, deal with missing values and oftentimes reduce the number of variables (feature selection) to be used in the
","['data', 'deal', 'values oftentimes', 'number variables', 'feature selection']
","['missing', 'reduce', 'used'] 
",1
"models.
","['models']
","[] 
",0
"Over the past 15 years, Oracle Advanced Analytics has evolved and now can automate most of the steps
","['years', 'Oracle Advanced Analytics', 'automate steps']
","['evolved'] 
",0
"typically required in data mining projects.
","['data mining projects']
","['typically required'] 
",0
"Today, Automated Data Preparation (ADP) automatically bins numeric
","['Today', 'Automated Data Preparation', 'ADP']
","['automatically bins'] 
",0
"attributes using default and user customizable binning strategies e.g.- equal width, equal count, user-defined and
","['attributes', 'default user', 'customizable binning strategies', 'equal width', 'equal count']
","['using', 'e.g.-'] 
",1
"similarly bins categorical attributes into N top values and “other” or user-defined bins.
","['categorical attributes N', 'top values', '” user-defined bins']
","['similarly bins', '“'] 
",1
"Missing values are
","['values']
","['Missing'] 
",0
"automatically replaced by a statistical value (i.e.- mean, median, mode, etc.)
","['statistical value', 'i.e.- mean', 'mode']
","['automatically replaced'] 
",0
"instead of that record being removed
","['record']
","['removed'] 
",0
"from the analysis.
","['analysis']
","[] 
",0
"ADP is used both for model building and then again for applying the models to new data.
","['ADP', 'model', 'models', 'new data']
","['used', 'building applying'] 
",1
"Users
","['Users']
","[] 
",0
"can of course override ADP settings if they choose.
","['course', 'ADP settings choose']
","[] 
",0
"Oracle Advanced Analytics provides support for attribute reduction (Attribute Importance using the Minimum
","['Oracle Advanced Analytics', 'support attribute reduction', 'Attribute Importance', 'Minimum']
","['provides', 'using'] 
",1
"Description Length algorithm) and feature reduction techniques (Principal Components Analysis and Non-Negative
","['Description Length algorithm', 'feature reduction techniques', 'Principal Components']
","[] 
",0
"Matrix Factorization).
","['Matrix Factorization']
","[] 
",0
"However, each of the Oracle Advanced Analytics algorithms (e.g.- Decision Trees,
","['Oracle Advanced Analytics algorithms', 'e.g.- Decision Trees']
","[] 
",0
"Generalized Linear Regression, Support Vector Machines, Naïve Bayes, K-Means Clustering, Expectation
","['Linear Regression', 'Support Vector', 'Naïve Bayes', 'K-Means Clustering', 'Expectation']
","['Generalized'] 
",0
"Maximization Clustering, Anomaly Detection 1-Class SVMs, etc.)
","['Maximization Clustering', 'Anomaly Detection', '1-Class SVMs']
","[] 
",0
"has their own built-in automated strategies for
","['strategies']
","['automated'] 
",0
"attribute reduction and selection so the an explicit variable reduction step is optional, but not necessary.
","['attribute reduction selection', 'variable reduction step']
","[] 
",0
"Users of
","['Users']
","[] 
",0
"course can control algorithm and data preparation settings or accept the intelligent defaults.
","['course control', 'data preparation settings', 'intelligent defaults']
","['algorithm', 'accept'] 
",1
"Transactional data, e.g.- purchases, transactions, events, etc.
","['Transactional data', 'e.g.- purchases', 'transactions', 'events']
","[] 
",0
"represent much of the data that is important to build
","['represent', 'much data', 'important build']
","[] 
",0
"good predictive models.
","['good predictive models']
","[] 
",0
"Oracle Advanced Analytics mines this data in its native transactional form and leverages
","['Oracle Advanced Analytics mines data', 'native transactional form leverages']
","[] 
",0
"the database’s aggregation functions to summarize it and then feed vector of the data (e.g.- item purchases) and join
","['database ’ aggregation functions', 'feed vector data', 'e.g.- item purchases', 'join']
","['summarize'] 
",0
"it to other customer 2-D data to provide a 360 degree customer view.
","['customer', 'data', 'degree customer view']
","[] 
",0
"Oracle Advanced Analytics models, e.g.-
","['Oracle Advanced Analytics models']
","[] 
",0
"classification, regression and clustering models, ingest this aggregated transactional attribute as a “nested table”.
","['classification', 'regression clustering models', 'transactional attribute “', 'table ”']
","['ingest aggregated', 'nested'] 
",1
"Deep inside the Oracle Advanced Analytics’ in-database processing, records are processed as triplets: Unique_ID,
","['Deep', 'Oracle Advanced Analytics', 'in-database processing', 'records', 'triplets', 'Unique_ID']
","['’', 'processed'] 
",1
"Attribute_name, and Attribute_value.
","['Attribute_name', 'Attribute_value']
","[] 
",0
"That’s just part of the secret sauce of how Oracle Advanced Analytics
","['That ’ part secret sauce Oracle Advanced Analytics']
","[] 
",0
"leverages the core strengths of the Oracle Database.
","['leverages', 'strengths Oracle Database']
","['core'] 
",0
"Market basket analysis would of course mine this data in its
","['Market basket analysis', 'course', 'data']
","['mine'] 
",0
"native transactional data form (typically not aggregated) to find co-occurring items in baskets.
","['native transactional data form', 'co-occurring items baskets']
","['typically aggregated', 'find'] 
",1
"Unstructured data i.e.- text is also processed in a similar fashion inside the database.
","['data', 'i.e.- text', 'similar fashion', 'database']
","['Unstructured', 'also processed'] 
",1
"Oracle Advanced Analytics
","['Oracle Advanced Analytics']
","[] 
",0
"uses Oracle Text’s text processing capabilities and multi-language support to “tokenize” any CLOB data type e.g.-
","['uses Oracle Text ’ text processing capabilities', 'multi-language support “ tokenize ” CLOB data type e.g.-']
","[] 
",0
"8  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"text, Word, Adobe Acrobat, etc.
","['text', 'Word', 'Adobe Acrobat', 'etc']
","[] 
",0
"As Oracle Text is a free feature in every Oracle Database, Oracle Advanced
","['Oracle Text', 'free feature', 'every Oracle Database', 'Oracle Advanced']
","[] 
",0
"Analytics leverages it to pre-process unstructured data to then feed vectors of words and word coefficients (TFIDF—
","['Analytics', 'pre-process', 'unstructured data feed vectors words word coefficients', 'TFIDF—']
","['leverages'] 
",0
"term frequency inverse document frequency) into the algorithms.
","['term frequency', 'document frequency', 'algorithms']
","['inverse'] 
",0
"Oracle Advanced Analytics just treats the
","['Oracle Advanced Analytics treats']
","[] 
",0
"unstructured attributes as additional input attributes e.g.- police comments, physician’s notes, resume, emails, article,
","['additional input', 'e.g.- police comments', 'physician ’ notes', 'resume', 'emails', 'article']
","['attributes', 'attributes'] 
",1
"abstract, etc.
","['abstract']
","[] 
",0
"that get joined with everything else (e.g.- Age, Income, Occupation, etc.)
","['get', 'everything', 'e.g.- Age', 'Income', 'Occupation']
","['joined'] 
",0
"that is being fed into the
","['fed']
","[] 
",0
"Oracle Advanced Analytics data mining algorithms.
","['Oracle Advanced Analytics data mining algorithms']
","[] 
",0
"Spatial data, web clicks and other data types can also be
","['Spatial data', 'web clicks', 'types']
","['data'] 
",0
"joined and included in Oracle Advanced Analytics data mining models.
","['Oracle Advanced Analytics data mining models']
","['joined included'] 
",0
"Oracle Data Miner Workflow GUI; a SQL Developer extension
","['Oracle Data Miner Workflow GUI', 'SQL Developer extension']
","[] 
",0
"Oracle Data Miner GUI, an extension to Oracle SQL Developer 4.1, is designed for users who prefer an easy to use
","['Oracle Data Miner GUI', 'extension Oracle SQL Developer', 'users', 'easy use']
","['designed', 'prefer'] 
",1
"GUI for their data analysis and don’t necessarily want know have to know how to program in either SQL or R—or
","['GUI data analysis', 'know', 'program', 'SQL R—or']
","['’ necessarily want', 'know'] 
",1
"just don’t want to write code.
","['’', 'write code']
","['want'] 
",0
"Oracle Data Miner enables data analysts, business analysts and data scientists to
","['Oracle Data Miner', 'data analysts', 'business analysts', 'scientists']
","['enables', 'data'] 
",1
"work directly with data inside the database using Oracle Data Miner’s graphical “drag and drop” workflow paradigm.
","['work', 'data', 'database', 'Oracle Data Miner ’', 'graphical “ drag drop ” workflow paradigm']
","['using'] 
",0
"Data analysts easily learn how to use Oracle Data Miner and can quickly visualize and explore the data graphically,
","['Data analysts', 'use Oracle Data Miner', 'data']
","['easily learn', 'quickly visualize'] 
",1
"prepare and transform their data as necessary, build and evaluate multiple data mining models using extensive
","['prepare transform data', 'evaluate multiple data mining models']
","['build', 'using'] 
",1
"model viewing and model evaluation viewers.
","['model', 'model evaluation viewers']
","['viewing'] 
",0
"Then they can apply Oracle Data Mining models to new data for
","['Oracle Data Mining models', 'new data']
","['Then apply'] 
",0
"deployment and/or they can generate SQL and PL/SQL scripts to deploy Oracle Data Mining's predictive models
","['deployment and/or generate SQL PL/SQL', 'deploy Oracle Data Mining', 'predictive models']
","['scripts'] 
",0
"throughout the enterprise.
","['enterprise']
","[] 
",0
"Oracle Data Miner work flows capture and document the user's analytical methodology and can be saved and
","['Oracle Data Miner work', 'capture document user', 'analytical methodology']
","['flows', 'saved'] 
",1
"shared with others to automate and publish advanced analytical methodologies.
","['others', 'publish advanced analytical methodologies']
","['shared', 'automate'] 
",1
"When the data analysts are done, Oracle Data Miner generates SQL scripts to pass to their DBAs for immediate
","['data analysts', 'Oracle Data Miner', 'SQL scripts', 'DBAs immediate']
","['done', 'generates', 'pass'] 
",1
"deployment using the Oracle Database for combined data management and predictive analytics.
","['deployment', 'Oracle Database', 'data management', 'predictive analytics']
","['using', 'combined'] 
",1
"Application
","['Application']
","[] 
",0
"developers can programmatically call the workflows using the Oracle Data Miner PL/SQL workflow API to fully
","['developers', 'workflows', 'Oracle Data Miner PL/SQL', 'API']
","['programmatically call', 'using'] 
",1
"automate the discovery and distribution of new business intelligence and actionable insights and to integrate
","['automate discovery distribution', 'new business intelligence', 'actionable insights integrate']
","[] 
",0
"predictive methodologies into applications for wider use throughout the enterprise.
","['predictive methodologies applications', 'use', 'enterprise']
","['wider'] 
",0
"9  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Oracle Data Miner, a SQL Developer extension, provides a drag and drop workflow user interface for data analysts to explore their
","['Oracle Data Miner', 'SQL Developer extension', 'drag drop', 'user interface data analysts']
","['provides', 'explore'] 
",1
"data, build, evaluate and apply predictive models and deploy advanced analytical methodologies as SQL and PL/SQL scripts.
","['data', 'build', 'predictive models', 'advanced analytical methodologies SQL PL/SQL scripts']
","['evaluate', 'deploy'] 
",1
"Data analysts can use Oracle Data Miner to experiment and assemble very simple to complex advanced analytical
","['Data analysts', 'Oracle Data Miner experiment', 'assemble simple complex']
","['use', 'advanced'] 
",1
"methodologies.
","['methodologies']
","[] 
",0
"For example, a data analyst may want to combine transactional data, demographic data, customer
","['example', 'data analyst', 'combine transactional data', 'demographic data', 'customer']
","['want'] 
",0
"service data and customer comments to assemble a 360 degree customer view.
","['service data customer comments', 'degree customer view']
","[] 
",0
"They may decide to perform
","['perform']
","['decide'] 
",0
"clustering on the customers to pre-assign them to customer segments and then, for each segment build separate
","['customers', 'pre-assign customer segments', 'segment build']
","['clustering'] 
",0
"different classification, regression or anomaly detection models for better accuracy and usefulness.
","['different classification', 'regression anomaly detection models', 'accuracy']
","[] 
",0
"Data analysts can quickly build simple to sophisticated analytical methodologies that mine data they have access to in the Oracle
","['Data analysts', 'simple sophisticated analytical methodologies', 'data access Oracle']
","['quickly build', 'mine'] 
",1
"Database.
","['Database']
","[] 
",0
"All data, models and results remain inside the database.
","['All data', 'models results', 'inside database']
","['remain'] 
",0
"Oracle R Enterprise—Integrating Open Source R with the Oracle Database
","['Oracle R Enterprise—Integrating Open Source R Oracle Database']
","[] 
",0
"Oracle R Enterprise, a component of the Oracle Advanced Analytics Option, makes the open source R statistical
","['Oracle R Enterprise', 'component Oracle Advanced Analytics Option', 'open source R statistical']
","['makes'] 
",0
"programming language and environment ready for the enterprise and big data.
","['language environment', 'ready enterprise', 'big data']
","['programming'] 
",0
"“R provides a wide variety of
","['“ R', 'wide variety']
","['provides'] 
",0
"statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering,)
","['classical statistical tests', 'time-series analysis', 'classification']
","['modelling', 'clustering'] 
",1
"and graphical techniques, and is highly extensible” (see https://www.r-project.org/).
","['graphical techniques', 'extensible ”', 'https']
","['see'] 
",0
"R’s strengths are that it is free—
","['R ’ strengths free—']
","[] 
",0
"open source, powerful and extensible, has an extensive array of graphical and statistical packages and is constantly
","['open source', 'extensive array', 'graphical statistical packages']
","[] 
",0
"being expanded by the R user community who author and contribute R “packages”.
","['R user community author contribute R “', '”']
","['expanded', 'packages'] 
",1
"R’s challenges are that it is
","['R ’ challenges']
","[] 
",0
"memory constrained, single threaded, runs an outer loop that can slow down processing and is not generally
","['memory', 'loop slow processing']
","['constrained', 'threaded', 'runs'] 
",1
"considered to be “industrial strength”.
","['“ industrial strength ”']
","['considered'] 
",0
"Contributed R packages are of varying quality.
","['R packages', 'quality']
","['Contributed', 'varying'] 
",1
"Oracle R Enterprise integrates R with Oracle Database and maps R functions to equivalent SQL and Oracle Data
","['Oracle R Enterprise', 'R Oracle Database', 'R functions', 'equivalent SQL Oracle Data']
","['integrates', 'maps'] 
",1
"Mining SQL functions and is designed for problems involving large amounts of data.
","['SQL functions', 'problems', 'large amounts data']
","['Mining', 'designed', 'involving'] 
",1
"It is a set of R packages (ORE)
","['R packages', 'ORE']
","['set'] 
",0
"and Oracle Database features that enable an R user to operate on database-resident data without using SQL and to
","['Oracle Database', 'enable R user operate', 'database-resident data', 'SQL']
","['features', 'using'] 
",1
"execute R scripts in one or more embedded R engines that run on the database server.
","['execute R', 'R engines', 'database server']
","['scripts', 'embedded', 'run'] 
",1
"Data analysts and data
","['Data analysts data']
","[] 
",0
"scientists can develop, refine, and deploy R scripts that leverage the parallelism and scalability of the database and
","['scientists', 'refine', 'deploy R', 'leverage parallelism scalability database']
","['develop', 'scripts'] 
",1
"the SQL data mining functions to automate data analysis in one step—without having to learn SQL
","['SQL data mining functions', 'data analysis', 'step—without learn SQL']
","['automate'] 
",0
"Oracle R Enterprise has overloaded open source R methods and functions that transparently convert standard R
","['Oracle R Enterprise', 'open source R methods functions', 'standard R']
","['overloaded', 'transparently convert'] 
",1
"syntax into SQL.
","['syntax SQL']
","[] 
",0
"These methods and functions are in ORE packages that implement the Oracle R Enterprise
","['These methods functions ORE packages', 'Oracle R Enterprise']
","['implement'] 
",0
"transparency layer.
","['transparency layer']
","[] 
",0
"With these functions and methods, R programmers can create R objects that access, analyze,
","['functions methods', 'R programmers', 'R objects access', 'analyze']
","['create'] 
",0
"10  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"and manipulate data that resides in the database.
","['manipulate data resides database']
","[] 
",0
"The database automatically optimizes the SQL code to improve
","['The database', 'SQL code']
","['automatically optimizes', 'improve'] 
",1
"the efficiency of the query.
","['efficiency query']
","[] 
",0
"Oracle R Enterprise performs function pushdown for in-database execution of base R,
","['Oracle R Enterprise', 'function', 'in-database execution base R']
","['performs'] 
",0
"Oracle SQL statistical functions, Oracle Data Mining SQL functions and selected popular R packages.
","['Oracle SQL', 'statistical functions', 'Oracle Data Mining SQL functions', 'popular R packages']
","['selected'] 
",0
"Because it
","[]
","[] 
",0
"runs as an embedded component of Oracle Database, Oracle R Enterprise can run any R package either by
","['runs', 'component Oracle Database', 'Oracle R Enterprise run R package']
","['embedded'] 
",0
"function pushdown or via “embedded R mode” while the database manages the data served to the R engines.
","['function', '“', 'R mode ” database', 'data', 'R engines']
","['embedded', 'manages', 'served'] 
",1
"This
","[]
","[] 
",0
"“embedded R mode” ability allows developers to extend Oracle Advanced Analytics’ natively supported toolkit with
","['“', 'R mode ” ability', 'developers', 'Oracle Advanced Analytics ’', 'toolkit']
","['embedded', 'allows', 'extend', 'natively supported'] 
",1
"any open source R packages and develop wide ranging and automated advanced analytics methodologies that are
","['open source R', 'advanced analytics methodologies']
","['packages develop', 'ranging automated'] 
",1
"completely managed by the database.
","['database']
","['completely managed'] 
",0
"Oracle Advanced Analytics’ Oracle R Enterprise (ORE) component transparently pushes down R functions to equivalent in-
","['Oracle Advanced Analytics ’ Oracle R Enterprise', 'ORE', 'component', 'R functions']
","['transparently pushes'] 
",0
"database SQL functions for scalability and parallelism.
","['database SQL functions scalability parallelism']
","[] 
",0
"ORE users can also leverage any R packages via “embedded R mode”.
","['ORE users', 'R packages', '“', 'R mode ”']
","['also leverage', 'embedded'] 
",1
"Users, who prefer to work in R to access and analyze their data, may use RStudio, or any R GUI, to connect to an
","['Users', 'work R access analyze data', 'RStudio', 'R GUI', 'connect']
","['prefer', 'use'] 
",1
"Oracle Database and access Oracle Advanced Analytic’s R integration (Oracle R Enterprise).
","['Oracle Database access Oracle Advanced Analytic ’ R integration', 'Oracle R Enterprise']
","[] 
",0
"Once a connection is
","['connection']
","[] 
",0
"made, the OAA/ORE session synchs the user’s metadata so they see all their tables and views inside the database.
","['OAA/ORE session', 'user ’ metadata see tables views', 'database']
","['made', 'synchs'] 
",1
"When they run any base R language function it gets transparently mapped to equivalent SQL functions.
","['base R language function', 'equivalent SQL functions']
","['run', 'gets transparently mapped'] 
",1
"R users
","['R users']
","[] 
",0
"using the OAA/ODM algorithms and OAA/ORE algorithms can perform scalable data mining in the database.
","['OAA/ODM algorithms OAA/ORE algorithms perform', 'scalable data mining database']
","['using'] 
",0
"11  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Oracle Advanced Analytics’ Oracle R Enterprise component invoking in-database ODM algorithms (e.g.-, Support Vector Machine)
","['Oracle Advanced Analytics ’ Oracle R Enterprise component', 'in-database ODM algorithms', 'Support Vector Machine']
","['invoking'] 
",0
"from an RStudio console.
","['RStudio console']
","[] 
",0
"Hadoop, Oracle Big Data Appliance and Big Data SQL
","['Hadoop', 'Oracle Big Data Appliance Big Data SQL']
","[] 
",0
"Big data is now often stored in Hadoop servers.
","['Big data', 'Hadoop servers']
","['often stored'] 
",0
"The separate data environment outside the database introduces
","['The separate data environment', 'database introduces']
","[] 
",0
"new data management and data analysis challenges.
","['new data management data analysis challenges']
","[] 
",0
"Big Data SQL addresses this challenge by extending SQL
","['Big Data SQL', 'SQL']
","['addresses challenge extending'] 
",0
"processing to Hadoop via the Oracle Big Data Appliance.
","['Hadoop', 'Oracle Big Data Appliance']
","['processing'] 
",0
"Using “smart scan” technology developed for Exadata,
","['“', 'smart scan ” technology', 'Exadata']
","['Using', 'developed'] 
",1
"Big Data SQL pushes down SQL logic to operate on Hive tables.
","['Big Data SQL', 'SQL', 'Hive tables']
","['pushes', 'operate'] 
",1
"Data analysts can now more easily take
","['Data analysts']
","['easily take'] 
",0
"advantage of new big data sources of data of possibly unknown value stored in big data reservoirs and combine that
","['advantage', 'new big data sources data', 'value', 'big data reservoirs combine']
","['stored'] 
",0
"data with data of known value managed inside a database and/or data warehouse.
","['data data', 'value', 'database and/or data warehouse']
","['known', 'managed'] 
",1
"However, the data stored in Hadoop may be voluminous and sparse representation (transactional format) and
","['data', 'Hadoop', 'representation', 'transactional format']
","['stored', 'voluminous'] 
",1
"lacking in information density.
","['information density']
","['lacking'] 
",0
"Given that much of the data may come from sensors, Internet of Things, “tweets” and
","['much data', 'sensors', 'Internet Things', '“']
","['Given', 'come', 'tweets ”'] 
",1
"other high volume sources, users can leverage Big Data SQL to collect counts, maximum values, minimum values,
","['high volume sources', 'users', 'Big Data SQL collect counts', 'maximum values', 'minimum values']
","['leverage'] 
",0
"thresholds counts above or below user defined values, averages, shorter term averages and counts and longer time
","['thresholds counts', 'values', 'averages', 'term averages', 'time']
","['user defined', 'counts'] 
",1
"averages and counts, sliding SQL window averages and counts and comparisons of each to the other.
","['averages counts', 'SQL window averages', 'comparisons']
","['sliding', 'counts'] 
",1
"So, filter “big
","[]
","[] 
",0
"data”, reduce it, join it to other database data using Oracle Big Data SQL and then mine *everything* inside the
","['data ”', 'database data', 'Oracle Big Data SQL mine * everything *']
","['reduce', 'join', 'using'] 
",1
"Oracle Database using Oracle Advanced Analytics Option.
","['Oracle Database', 'Oracle Advanced Analytics Option']
","['using'] 
",0
"12  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"SQL and Big Data SQL enable data analysts to access, summarize, filter and aggregate data from both Hadoop servers and the
","['SQL Big Data SQL', 'enable data analysts access', 'aggregate data Hadoop servers']
","['summarize'] 
",0
"Database and combine them for a more complete 360 degree customer view and build predictive models using Oracle Advanced
","['Database', 'degree customer view', 'predictive models', 'Oracle Advanced']
","['combine', 'build', 'using'] 
",1
"Analytics.
","['Analytics']
","[] 
",0
"A Platform for Developing Enterprise-wide Predictive Analytics Applications
","['A Platform Developing Enterprise-wide Predictive Analytics Applications']
","[] 
",0
"Oracle’s strategy of making big data and big data analytics simple makes it easier to develop, refine and deploy
","['Oracle ’ strategy', 'big data', 'big data analytics', 'deploy']
","['making', 'makes', 'develop', 'refine'] 
",1
"predictive analytics applications—all is part of the database’s functions.
","['predictive analytics', 'applications—all part database ’ functions']
","[] 
",0
"All the data, user access, security and
","['All data', 'user access', 'security']
","[] 
",0
"encryption, scalability, applications development environment and powerful advanced analytics are available in the
","['encryption', 'scalability', 'applications development environment', 'analytics']
","['advanced'] 
",0
"data management and data analytics platform—the Oracle Database.
","['data management data analytics', 'platform—the Oracle Database']
","[] 
",0
"Now, it is easy to add predictive insights and
","['predictive insights']
","['add'] 
",0
"real-time actionable insights into any enterprise application, BI dashboard or tool that can speak SQL to the Oracle
","['real-time actionable insights enterprise application', 'BI dashboard tool speak SQL Oracle']
","[] 
",0
"Database.
","['Database']
","[] 
",0
"Oracle Advanced Analytics, a separately licensed feature of the Oracle Database, extends the database into a powerful analytical
","['Oracle Advanced Analytics', 'licensed feature Oracle Database', 'database']
","['extends'] 
",0
"platform for both big data and big data analytics which is ideal for developing and deploying predictive analytics applications.
","['platform', 'big data', 'big data analytics', 'predictive analytics applications']
","['developing deploying'] 
",0
"Oracle has been developing predictive analytics applications and provides next-generation predictive applications on
","['Oracle', 'predictive analytics applications', 'next-generation predictive applications']
","['developing', 'provides'] 
",1
"premise and in the cloud including:
","['premise cloud']
","['including'] 
",0
" Oracle Human Capital Management Predictive Workforce
","['\uf0b7 Oracle Human Capital Management Predictive Workforce']
","[] 
",0
" Oracle Customer Relationship Management Sales Prediction Engine
","['\uf0b7 Oracle Customer Relationship Management Sales Prediction Engine']
","[] 
",0
" Oracle Adaptive Access Management’s Identity Management
","['\uf0b7 Oracle Adaptive Access Management ’ Identity Management']
","[] 
",0
" Oracle Retail Customer Analytics
","['\uf0b7 Oracle Retail Customer Analytics']
","[] 
",0
"13  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
" Oracle Predictive Incident Monitoring Premium Service
","['\uf0b7 Oracle Predictive Incident Monitoring Premium Service']
","[] 
",0
" Oracle Communications Industry Data Model
","['\uf0b7 Oracle', 'Industry Data Model']
","[] 
",0
" Oracle Retail Industry Data Model
","['\uf0b7 Oracle Retail Industry Data Model']
","[] 
",0
" Oracle Airlines Industry Data Model
","['\uf0b7 Oracle', 'Industry Data Model']
","[] 
",0
" Oracle Utilities Industry Data Model
","['\uf0b7 Oracle', 'Industry Data Model']
","[] 
",0
"Oracle HCM Predictive Workforce application delivers pre-built OAA predictive analytics for employee attrition, employee
","['Oracle HCM Predictive Workforce application delivers', 'pre-built OAA predictive analytics employee attrition', 'employee']
","[] 
",0
"performance and “What if?” analysis.
","['performance', '” analysis']
","['“'] 
",0
"14  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"Oracle Communications Data Model embeds OAA pre-built predictive models for churn prediction, customer profiling, identifying
","['Oracle Communications Data Model', 'OAA', 'pre-built predictive models', 'prediction', 'customer profiling']
","['embeds', 'churn', 'identifying'] 
",1
"churn factors, cross-sell, customer life time value (LTV) and customer sentiment.
","['churn factors', 'cross-sell', 'customer life time value', 'LTV', 'customer sentiment']
","[] 
",0
"Conclusion
","['Conclusion']
","[] 
",0
"Traditional BI and analytic approaches simply can’t keep pace with requirements era of “big data” and “cloud”.
","['Traditional BI', 'analytic approaches', 'pace requirements', '“ big data ” “ cloud ”']
","['keep', 'era'] 
",1
"For
","[]
","[] 
",0
"organizations who strive to be leaders in their areas leveraging these new technologies, the prompt capture and
","['organizations', 'strive leaders areas', 'new technologies', 'prompt capture']
","['leveraging'] 
",0
"collection of data of known and unknown value, the proper data management, assembly of relevant data and facile
","['collection data', 'unknown value', 'data management', 'assembly', 'relevant data facile']
","['known'] 
",0
"deep analysis and automation and deployment of the actionable insights is the key to success.
","['deep analysis automation deployment', 'actionable insights', 'key success']
","[] 
",0
"Oracle Advanced Analytics, a priced option to the Oracle Database 12c, collapses the traditional extract, move,
","['Oracle Advanced Analytics', 'option Oracle Database', 'traditional extract', 'move']
","['priced', 'collapses'] 
",1
"load, analyze, export, move, load/import paradigm all too common today.
","['load', 'analyze', 'export', 'move', 'load/import paradigm', 'common today']
","[] 
",0
"Oracle Advanced Analytics delivers
","['Oracle Advanced Analytics delivers']
","[] 
",0
"scalable, parallelized, in-database implementations of a wide library of workhorse predictive analytics algorithms
","['in-database implementations', 'wide library workhorse', 'predictive analytics']
","['algorithms'] 
",0
"(e.g.- clustering, regression, prediction, associations, text mining, associations analysis, anomaly detection, etc.)
","['e.g.- clustering', 'regression', 'prediction', 'associations', 'text mining', 'associations analysis', 'anomaly detection']
","[] 
",0
"as
","[]
","[] 
",0
"SQL functions within the Oracle Database 12c.
","['SQL functions', 'Oracle Database']
","[] 
",0
"Oracle Advanced Analytics exposes these predictive algorithms as
","['Oracle Advanced Analytics', 'predictive algorithms']
","['exposes'] 
",0
"SQL functions accessible via SQL (Oracle Data Mining OAA SQL API component), the Oracle Data Miner “drag and
","['SQL functions', 'SQL', 'Oracle Data Mining OAA SQL API component', 'Oracle Data Miner “ drag']
","[] 
",0
"drop” workflow GUI, an extension to Oracle SQL Developer 4.1 and through tight integration w/ open source R
","['drop', 'workflow GUI', 'extension Oracle SQL Developer', 'tight integration w/', 'open source R']
","['”'] 
",0
"(Oracle R Enterprise R integration component).
","['Oracle R Enterprise R integration component']
","[] 
",0
"Because Oracle Advanced Analytics’ in-database data mining machine learning/predictive analytics algorithms are
","['Oracle Advanced Analytics', 'in-database data mining machine', 'learning/predictive analytics']
","['algorithms'] 
",0
"built from the inside out of the Oracle Database and take full advantage of the Oracle Database’s scalability,
","['Oracle Database', 'full advantage Oracle Database ’ scalability']
","['built', 'take'] 
",1
"security, integration, cloud, structured and unstructured data mining capabilities, it make Oracle the ideal platform for
","['security', 'integration', 'cloud', 'unstructured data mining capabilities', 'Oracle ideal platform']
","['structured', 'make'] 
",1
"big data + analytics solutions and applications either on-premise or on the Oracle Cloud.
","['big data + analytics solutions applications', 'on-premise Oracle Cloud']
","[] 
",0
"15  |   BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS
","['| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS']
","[] 
",0
"With Oracle, data management and descriptive, predictive and prescriptive big data analytics are designed into the
","['Oracle', 'data management descriptive', 'predictive prescriptive', 'big data analytics']
","['designed'] 
",0
"platform from the beginning.
","['platform beginning']
","[] 
",0
"All of Oracle’s multiple decades of leading edge data management and SQL and Big
","['All Oracle ’ multiple decades', 'edge data management SQL Big']
","['leading'] 
",0
"Data SQL is harnesses and combined with Oracle’s design and development approach of “moving the algorithms to
","['Data SQL harnesses', 'Oracle ’ design development approach “', 'algorithms']
","['combined', 'moving'] 
",1
"the data” vs. “moving the data to the algorithms”.
","['data ”', '“', 'data', '”']
","['moving'] 
",0
"Oracle’s vision is to create a big data and analytic platform for the
","['Oracle ’ vision create', 'big data', 'analytic platform']
","[] 
",0
"era of big data and the cloud to:
","['era', 'big data cloud']
","[] 
",0
"Make big data + analytics simple:
","['Make', 'big data + analytics simple']
","[] 
",0
" Any data size, on any computer infrastructure
","['\uf0b7 Any data size', 'computer infrastructure']
","[] 
",0
" Any variety of data, in any combination
","['Any variety data', 'combination']
","['\uf0b7'] 
",0
"Make big data and analytics deployment simple
","['Make', 'big data analytics', 'deployment simple']
","[] 
",0
" As a service, as a platform, as an application
","['service', 'platform', 'application']
","[] 
",0
"By integrating both big data management and big data analytics into a single unified Oracle Database platform,
","['big data management', 'big data analytics', 'single unified Oracle Database platform']
","['integrating'] 
",0
"Oracle reduces total cost of ownership,  eliminates data movement, and delivers the fastest way to deliver
","['Oracle reduces', 'total cost ownership', 'data movement', 'delivers', 'way deliver']
","['eliminates', 'fastest'] 
",1
"enterprise-wide predictive analytics solutions and applications.
","['enterprise-wide predictive analytics solutions applications']
","[] 
",0
"Oracle Corporation, World Headquarters
","['Oracle Corporation', 'World Headquarters']
","[] 
",0
"500 Oracle Parkway
","['Oracle Parkway']
","[] 
",0
"Redwood Shores, CA 94065, USA
","['Redwood Shores', 'CA', 'USA']
","[] 
",0
"Worldwide Inquiries
","['Worldwide Inquiries']
","[] 
",0
"Phone: +1.650.506.7000
","['Phone', '+1.650.506.7000']
","[] 
",0
"Fax: +1.650.506.7200
","['Fax', '+1.650.506.7200']
","[] 
",0
"    Copyright © 2015, Oracle and/or its affiliates.
","['Copyright ©', 'Oracle and/or affiliates']
","[] 
",0
"All rights reserved.
","['All rights']
","['reserved'] 
",0
"This document is provided for information purposes only, and the  contents hereof are subject to change without notice.
","['This document', 'information purposes', 'contents', 'subject change', 'notice']
","['provided', 'hereof'] 
",1
"This document is not warranted to be error-free, nor subject to any other  warranties or conditions, whether expressed orally or implied in law, including implied warranties and conditions of merchantability or  fitness for a particular purpose.
","['This document', 'subject warranties conditions', 'implied law', 'implied warranties conditions merchantability fitness', 'particular purpose']
","['warranted', 'expressed', 'including'] 
",1
"We specifically disclaim any liability with respect to this document, and no contractual obligations are  formed either directly or indirectly by this document.
","['liability respect document', 'contractual obligations', 'document']
","['specifically disclaim', 'formed'] 
",1
"This document may not be reproduced or transmitted in any form or by any  means, electronic or mechanical, for any purpose, without our prior written permission.
","['This document', 'transmitted form means', 'electronic mechanical', 'purpose', 'permission']
","['reproduced', 'written'] 
",1
"Oracle and Java are registered trademarks of Oracle and/or its affiliates.
","['Oracle Java', 'trademarks Oracle and/or affiliates']
","['registered'] 
",0
"Other names may be trademarks of their respective owners.
","['Other names', 'respective owners']
","['trademarks'] 
",0
"Intel and Intel Xeon are trademarks or registered trademarks of Intel Corporation.
","['Intel Intel Xeon trademarks', 'trademarks Intel Corporation']
","['registered'] 
",0
"All SPARC trademarks are used under license and  are trademarks or registered trademarks of SPARC International, Inc. AMD, Opteron, the AMD logo, and the AMD Opteron logo are  trademarks or registered trademarks of Advanced Micro Devices.
","['All SPARC trademarks', 'license trademarks', 'trademarks SPARC International', 'Inc. AMD', 'Opteron', 'AMD logo', 'AMD Opteron logo trademarks', 'trademarks Advanced Micro']
","['used', 'registered', 'registered'] 
",1
"UNIX is a registered trademark of The Open Group.0115    White Paper Title  January 2015  Author: Charlie Berger, Sr. Dir.
","['UNIX', 'The Open Group.0115 White Paper Title January', 'Author', 'Charlie Berger', 'Sr. Dir']
","['registered'] 
",0
"of Product Management, Oracle Advanced Analytics and Data Mining (charlie.berger@oracle.com)  Contributing Authors: [OPTIONAL]
","['Product Management', 'Oracle Advanced Analytics Data Mining', 'charlie.berger @ oracle.com', 'Authors', '[ OPTIONAL ]']
","['Contributing'] 
",0
"C O N N E C T  W I T H  U S
","['C O N N E C T W', 'H U S']
","['T'] 
",0
"  blogs.oracle.com/oracle
","['blogs.oracle.com/oracle']
","[] 
",0
"  facebook.com/oracle
","['facebook.com/oracle']
","[] 
",0
"  twitter.com/oracle
","['twitter.com/oracle']
","[] 
",0
"  oracle.com
","['oracle.com']
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 70
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"A REVIEW OF STUDIES ON MACHINE LEARNING TECHNIQUES
","['A REVIEW OF STUDIES ON MACHINE LEARNING TECHNIQUES']
","[] 
",0
"Yogesh Singh              ys66@rediffmail.com  Prof & Dean  Guru Gobind Singh IP University  Delhi, 110006, India    Pradeep Kumar Bhatia            pk_bhatia2002@yahoo.com  Reader, Department of Computer Science & Engineering  Guru Jambsheshwar University of Science & Technology  Hisar, Haryana, 125001,India
","['Yogesh Singh ys66 @ rediffmail.com Prof', 'Dean Guru Gobind Singh IP University Delhi', 'India Pradeep Kumar Bhatia pk_bhatia2002 @ yahoo.com Reader', 'Department Computer Science', 'Engineering Guru Jambsheshwar University Science', 'Technology Hisar', 'Haryana', 'India']
","[] 
",0
"Omprakash Sangwan            sangwan_op@aiit.amity.edu  Head, CISCO Regional Networking Academy  Amity Institute of Information Technology   Amity University, Uttarpradesh, 201303,India
","['Omprakash Sangwan', '@', 'aiit.amity.edu Head', 'CISCO Regional Networking Academy Amity Institute Information Technology Amity University', 'Uttarpradesh', 'India']
","['sangwan_op'] 
",0
"  Abstract
","['Abstract']
","[] 
",0
"  This paper provides an extensive review of studies related to expert estimation of  software development using Machine-Learning Techniques (MLT).
","['This paper', 'extensive review studies', 'expert estimation software development', 'Machine-Learning Techniques', 'MLT']
","['provides', 'related', 'using'] 
",1
"Machine  learning in this new era, is demonstrating the promise of producing consistently  accurate estimates.
","['Machine', 'new era', 'promise', 'accurate estimates']
","['learning', 'demonstrating', 'producing'] 
",1
"Machine learning system effectively “learns” how to estimate  from training set of completed projects.
","['Machine', 'system', '“ learns', '” estimate training', 'projects']
","['learning', 'set completed'] 
",1
"The main goal and contribution of the  review is to support the research on expert estimation, i.e.- to ease other  researchers for relevant expert estimation studies using machine-learning  techniques.
","['The main goal contribution review support research expert estimation', 'i.e.- ease researchers', 'expert estimation studies', 'machine-learning techniques']
","['relevant', 'using'] 
",1
"This paper presents the most commonly used machine learning  techniques such as neural networks, case based reasoning, classification and  regression trees, rule induction, genetic algorithm & genetic programming for  expert estimation in the field of software development.
","['This paper', 'machine', 'techniques', 'neural networks', 'case', 'reasoning', 'classification regression trees', 'rule induction', 'genetic algorithm', 'genetic programming', 'expert estimation field software development']
","['presents commonly used', 'learning', 'based'] 
",1
"In each of our study we  found that the results of various machine-learning techniques depends on  application areas on which they are applied.
","['study', 'results', 'various machine-learning techniques', 'application areas']
","['found', 'depends', 'applied'] 
",1
"Our review of study not only  suggests that these techniques are competitive with traditional estimators on one  data set, but also illustrate that these methods are sensitive to the data on which  they are trained.
","['review study', 'techniques', 'competitive traditional estimators', 'data set', 'methods', 'sensitive data']
","['suggests', 'also illustrate', 'trained'] 
",1
"Keywords: Machine Learning Techniques (MLT), Neural Networks (NN), Case Based Reasoning (CBR),  Classification and Regression Trees (CART), Rule Induction, Genetic Algorithms and Genetic Programming.
","['Keywords', 'Machine Learning Techniques', 'MLT', 'Neural Networks', 'NN', 'Case', 'Reasoning', 'CBR', 'Classification Regression Trees', 'CART', 'Rule Induction', 'Genetic Algorithms Genetic Programming']
","['Based'] 
",0
".
","[]
","[] 
",0
"  1.
","[]
","[] 
",0
"INTRODUCTION  The poor performance results produced by statistical estimation models have flooded the  estimation area for over the last decade.
","['INTRODUCTION', 'The poor performance results', 'statistical estimation models', 'estimation area', 'last decade']
","['produced', 'flooded'] 
",1
"Their inability to handle categorical data, cope with  missing data points, spread of data points and most importantly lack of reasoning capabilities has  triggered an increase in the number of studies using non-traditional methods like machine  learning techniques.
","['inability', 'categorical data', 'cope', 'data points', 'spread data points', 'capabilities', 'increase number studies', 'non-traditional methods', 'machine', 'techniques']
","['handle', 'missing', 'importantly lack reasoning', 'triggered', 'using', 'learning'] 
",1
"Machine Learning is the study of computational methods for improving performance by  mechanizing the acquisition of knowledge from experience [18].
","['Machine Learning study', 'computational methods', 'performance', 'acquisition knowledge experience', ']']
","['improving', 'mechanizing', '['] 
",1
"Expert performance requires
","['Expert performance']
","['requires'] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 71
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"much domain specific knowledge, and knowledge engineering has produced hundreds of AI  expert systems that are now used regularly in industry.
","['much domain', 'specific knowledge', 'knowledge engineering', 'hundreds AI expert systems', 'industry']
","['produced', 'used'] 
",1
"Machine Learning aims to provide  increasing levels of automation in the knowledge engineering process, replacing much time- consuming human activity with automatic techniques that improve accuracy or efficiency by  discovering and exploiting regularities in training data.
","['Machine Learning aims', 'levels automation knowledge engineering process', 'human activity automatic techniques', 'accuracy efficiency', 'regularities', 'data']
","['provide increasing', 'replacing', 'consuming', 'improve', 'discovering exploiting', 'training'] 
",1
"The ultimate test of machine learning is its  ability to produce systems that are used regularly in industry, education, and elsewhere.
","['The ultimate test machine', 'ability', 'systems', 'industry', 'education']
","['learning', 'produce', 'used'] 
",1
"Most  evaluation in machine learning is experimental in nature, aimed at showing that the learning  method leads to performance on a separate test set, in one or more realistic domains, that is  better than performance on that test set without learning.
","['evaluation machine', 'experimental nature', 'method leads performance', 'separate test set', 'realistic domains', 'performance test']
","['learning', 'aimed showing learning', 'set', 'learning'] 
",1
"At a general level, there are two types of machine learning: inductive, and deductive.
","['general level', 'types machine learning']
","[] 
",0
"Deductive  learning works on existing facts and knowledge and deduces new knowledge from the old.
","['Deductive learning', 'facts', 'deduces', 'new knowledge']
","['works existing', 'knowledge'] 
",1
"Inductive machine learning methods create computer programs by extracting rules and patterns  out of massive data sets.
","['Inductive machine', 'methods', 'computer programs', 'rules patterns', 'massive data sets']
","['learning', 'create', 'extracting'] 
",1
"Inductive learning takes examples and generalizes rather than starting  with existing knowledge one major subclass of inductive learning is concept learning.
","['Inductive learning', 'examples', 'knowledge', 'major subclass inductive', 'concept learning']
","['takes', 'generalizes rather starting existing', 'learning'] 
",1
"This takes  examples of a concept and tries to build a general description of the concept.
","['examples concept', 'general description concept']
","['takes', 'tries build'] 
",1
"Very often, the  examples are described using attribute-value pairs.
","['examples', 'attribute-value pairs']
","['described using'] 
",0
"Machine learning overlaps heavily with statistics.
","['Machine', 'overlaps', 'statistics']
","['learning'] 
",0
"In fact, many machine-learning algorithms have  been found to have direct counterparts with statistics.
","['fact', 'many machine-learning algorithms', 'direct counterparts statistics']
","['found'] 
",0
"For example, boosting is now widely  thought to be a form of stage wise regression using a specific type of loss function.
","['example', 'form stage wise regression', 'specific type loss function']
","['boosting widely thought', 'using'] 
",1
"Machine  learning has a wide spectrum of applications including natural language processing, search  engines, medical diagnosis, bioinformatics and cheminformatics, detecting credit card fraud,  stock market analysis, classifying DNA sequences, speech and handwriting recognition, object  recognition in computer vision, game playing and robot locomotion.
","['Machine', 'wide spectrum applications', 'natural language processing', 'search engines', 'medical diagnosis', 'bioinformatics cheminformatics', 'credit card fraud', 'stock market analysis', 'DNA sequences', 'speech', 'recognition', 'object recognition computer vision', 'game', 'robot locomotion']
","['learning', 'including', 'detecting', 'classifying', 'handwriting', 'playing'] 
",1
"In our study we concentrate on the various paradigms, which are used in machine learning.
","['study', 'various paradigms', 'machine learning']
","['concentrate', 'used'] 
",1
"Our  review also examines the comparative study of machine learning technique with suitable  application area.
","['review', 'comparative study machine', 'technique', 'suitable application area']
","['also examines', 'learning'] 
",1
"This paper is organized as follows: In section 2 we discuss about the use of Neural Network in  machine learning.
","['This paper', 'section', 'discuss use Neural Network machine learning']
","['organized follows'] 
",0
"CBR with application area is presented in section 3.
","['CBR application area', 'section']
","['presented'] 
",0
"CART is another efficient  learning method described in section 4.
","['CART', 'method', 'section']
","['learning', 'described'] 
",1
"Another paradigm rule induction is highlighted in section  5.
","['Another paradigm rule induction', 'section']
","['highlighted'] 
",0
"In section 6 the impact of genetic algorithm and programming are discussed.
","['section', 'impact', 'genetic algorithm programming']
","['discussed'] 
",0
"Section 7  presents the discussion on various machine-learning techniques and conclusions and future  direction are presented in section 8.
","['Section', 'presents discussion', 'various machine-learning techniques conclusions', 'future direction', 'section']
","['presented'] 
",0
"2.
","[]
","[] 
",0
"NEURAL NETWORKS  Neural networks have been established to be an effective tool for pattern classification and  clustering [8, 15].
","['NEURAL NETWORKS Neural networks', 'effective tool pattern classification', ']']
","['established', 'clustering'] 
",1
"There are broadly two paradigms of neural learning algorithms namely  supervised and unsupervised.
","['algorithms']
","['learning', 'namely supervised'] 
",1
"Unsupervised neural algorithms are best suited for clustering  patterns on the basis of their inherent characteristics [8, 14].
","['neural algorithms', 'patterns basis', 'inherent characteristics', ']']
","['Unsupervised', 'best suited clustering', '['] 
",1
"There are three major approaches  for unsupervised learning:  -   (a) Competitive Learning   (b) Self Organizing feature Maps   (c) ART Networks
","['major approaches', 'learning', 'Competitive Learning', 'b', 'Self Organizing feature Maps', 'c', 'ART Networks']
","['unsupervised'] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 72
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"  The other paradigm of neural learning is the so-called supervised learning paradigm.
","['so-called supervised learning paradigm']
","['learning'] 
",0
"These  networks have been established to be universal approximators of continuous/discontinuous  functions and therefore they are suitable for usage where we have some information about the  input-output map to be approximated.
","['These networks', 'universal approximators', 'continuous/discontinuous functions', 'suitable usage information input-output map']
","['established', 'approximated'] 
",1
"A set of data (Input-Output information) is used for training  the network.
","['A set data', 'Input-Output information', 'training network']
","['used'] 
",0
"Once the network has been trained it can be given any input (from the input space of  the map to be approximated) and it will produce an output, which would correspond to the  expected output from the approximated mapping.
","['network', 'input', 'input space map', 'output', 'output', 'mapping']
","['trained given', 'approximated', 'produce', 'correspond expected', 'approximated'] 
",1
"The quality of this output has been established  to correspond arbitrarily close to the actual output desired owing to the generalization capabilities  of these networks.
","['The quality output', 'correspond', 'actual output', 'generalization capabilities networks']
","['established', 'desired owing'] 
",1
"The activation function used is the log-sigmoid function as given in [9] can be expressed as: -
","['The activation function', 'log-sigmoid function', ']']
","['used', 'given', 'expressed'] 
",1
"  Where
","[]
","[] 
",0
"  w’s are the synaptic coefficients and x’s are the outputs of the previous layer.
","['w ’', 'synaptic coefficients', '’', 'previous layer']
","['x', 'outputs'] 
",1
"For the hidden layer  x’s correspond to the input of the network while for the output layer x’s correspond to the output of  the hidden layer.
","['hidden layer x ’ correspond input network output layer x ’ correspond output', 'layer']
","['hidden'] 
",0
"The network is trained using the error back propagation algorithm [9] .The  weight update rule as given in [9] can be expressed as: -
","['The network', 'error', 'propagation algorithm', '] .The weight update rule', ']']
","['trained using', '[', 'given', 'expressed'] 
",1
"  where α is usually a positive number called the momentum constant , η is the learning rate, ∆wji  (n) is the correction applied to the synaptic weight connecting the output of neuron i to the input of  neuron j at iteration n, δj (n) is the local gradient at nth iteration, yi (n) is the function signal  appearing at the output of neuron i at iteration n.    From experimental results we conclude that neural network can be used as test oracle, effort  estimation, cost estimation, size estimation & other application areas of software engineering [1,7,
","['α', 'positive number', 'momentum constant', 'rate', '∆wji', 'n', 'correction', 'synaptic weight', 'output', 'j iteration n', 'δj', 'local gradient', 'nth iteration', 'yi', 'function', 'output', 'neuron iteration n.', 'experimental results', 'neural network', 'test oracle', 'effort estimation', 'cost estimation', 'size estimation', 'application areas software engineering [']
","['called', 'learning', 'applied', 'connecting', 'appearing', 'conclude', 'used'] 
",1
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 73
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"12, 13].
","[']']
","[] 
",0
"However the percentage error that can be tolerated will depend on the specific  application for which test case is being design.
","['percentage error', 'depend specific application test case design']
","['tolerated'] 
",0
"The architecture and training algorithm will  depend upon the space spanned by the test case parameters.
","['The architecture training', 'space', 'test case parameters']
","['depend', 'spanned'] 
",1
"There are some other systems like  complex simulation in mechanical design, weather and economic forecasting and geological  exploration that are built to solve unsolved problems using neural network for which there is no  analytical solution.
","['systems', 'complex simulation', 'mechanical design', 'economic forecasting', 'geological exploration', 'unsolved problems', 'neural network', 'analytical solution']
","['built solve', 'using'] 
",1
"The primary advantage of using neural network approach is that they are adaptable and  nonparametric; predictive models can be tailored to the data at a particular site.
","['The primary advantage', 'neural network approach', 'predictive models', 'data', 'particular site']
","['using', 'tailored'] 
",1
"3.
","[]
","[] 
",0
"CASE BASED REASONING (CBR)  Case Based Reasoning is a technique by which we solve new problems by adapting the solutions  from similarly solved problems.
","['CASE BASED REASONING', 'CBR', 'Case', 'Reasoning technique', 'new problems', 'solutions', 'problems']
","['Based', 'solve', 'adapting', 'similarly solved'] 
",1
"We take the instances of solutions from problems that have  happened in the past and try to solve new problems by using these cases.
","['instances solutions problems', 'past try', 'new problems', 'cases']
","['take', 'happened', 'solve', 'using'] 
",1
"Each such solution  available to us can be termed as a case [11].
","['Each solution', 'case', ']']
","['termed'] 
",0
"  3.1   CBR Process  A general CBR process includes the following four processes.
","['CBR Process A', 'general CBR process', 'processes']
","['includes following'] 
",0
"    A new case is defined by the initial description of any problem.
","['A new case', 'initial description problem']
","['defined'] 
",0
"This new case is retrieved from a  collection of previous cases and this retrieved case is then combined with the new case through  reuse into a solved case.
","['This new case', 'collection', 'previous cases', 'case', 'new case reuse', 'case']
","['retrieved', 'retrieved', 'combined', 'solved'] 
",1
"This solved case is nothing but a proposed solution to the defined  problem.
","['case nothing', 'solution', 'problem']
","['solved', 'proposed', 'defined'] 
",1
"Once this solution is identified, applying it practically to the real world tests it.
","['solution', 'real world tests']
","['identified', 'applying'] 
",1
"This  process of testing is termed as revision of the problem.
","['This process', 'revision problem']
","['testing termed'] 
",0
"Then comes the process of retain where  useful experience is retained for future reuse and the case base is updated by a new learned  case or by modification of some existing cases.
","['process retain', 'useful experience', 'future reuse case base', 'new learned case modification', 'cases']
","['Then comes', 'retained', 'updated', 'existing'] 
",1
"Thus we can say that CBR is a four-step process:  1.
","['CBR', 'four-step process']
","['Thus say'] 
",0
"RETRIEVE    2.
","['RETRIEVE']
","[] 
",0
"REUSE
","['REUSE']
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 74
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"3.
","[]
","[] 
",0
"REVISE  4.
","['REVISE']
","[] 
",0
"RETAIN
","['RETAIN']
","[] 
",0
"  The figure: 4 give a brief illustration of the CBR Cycle:
","['The figure', 'give brief illustration CBR Cycle']
","[] 
",0
"It is clear from the figure that general knowledge plays a crucial in CBR.
","['clear figure general knowledge', 'crucial CBR']
","['plays'] 
",0
"It supports all the CBR  processes.
","['CBR processes']
","['supports'] 
",0
"General knowledge here implies domain dependent knowledge as opposed to specific  knowledge embodied by cases.
","['General knowledge implies', 'dependent knowledge', 'specific knowledge', 'cases']
","['domain', 'opposed', 'embodied'] 
",1
"For instance in diagnosing a patient by retrieving and reusing the  case of a previous patient, a model of anatomy together with casual relationships between  pathological states may constitute the general knowledge used by a CBR system.
","['instance', 'case', 'previous patient', 'model anatomy', 'casual relationships', 'pathological states', 'general knowledge', 'CBR system']
","['diagnosing', 'retrieving reusing', 'constitute', 'used'] 
",1
"  3.2   Fundamentals of Case Based Reasoning
","['Fundamentals Case']
","['Based Reasoning'] 
",0
"  3.2.1   Case Retrieval   The process of retrieval in CBR cycle begins with the problem description and ends when the  best possible case from the set of previous cases has been obtained.
","['Case Retrieval', 'The process retrieval CBR cycle', 'problem description', 'possible case', 'previous cases']
","['begins', 'ends', 'set', 'obtained'] 
",1
"The subtasks involved in  this particular step include identifying features, matching, searching and selecting the appropriate  ones executed in that order.
","['The subtasks', 'particular step', 'features', 'appropriate ones', 'order']
","['involved', 'include identifying', 'matching', 'searching selecting', 'executed'] 
",1
"The identification task finds a set of relevant problem descriptors,  then the matching task returns those cases that are similar to the new case and finally the  selection task chooses the best possible match.
","['The identification task', 'relevant problem descriptors', 'task returns cases', 'similar new case', 'selection task', 'possible match']
","['finds set', 'matching', 'chooses'] 
",1
"Among well-known methods for case retrieval  are: nearest neighbor, induction, knowledge guided induction and template retrieval.
","['well-known methods case retrieval', 'neighbor', 'induction', 'knowledge', 'induction template retrieval']
","['guided'] 
",0
"These
","[]
","[] 
",0
"methods can be used alone or combined into hybrid retrieval strategies.
","['methods', 'combined hybrid retrieval strategies']
","['used'] 
",0
"1) Nearest Neighbour  (NN)                                                                                                        NN approach involves the assessment of similarity between stored cases and the new input case,  based on matching a weighted sum of features.
","['Neighbour', 'NN', 'NN approach', 'assessment similarity', 'cases', 'new input case', 'matching', 'sum features']
","['involves', 'stored', 'based', 'weighted'] 
",1
"2) Induction                                                                                                                             This involves generating a decision tree structure to organize the cases in memory by  determining which features do the best job in discriminating cases.
","['Induction', 'decision tree structure', 'cases memory', 'features', 'job', 'cases']
","['involves generating', 'organize', 'determining', 'discriminating'] 
",1
"3) Knowledge guided induction                                                                                                 By applying knowledge to the induction process by manually identifying case features that are  known or thought to affect the primary case feature we perform case retrieval.
","['Knowledge', 'induction', 'knowledge induction process', 'case features', 'thought affect', 'primary case feature perform case retrieval']
","['guided', 'applying', 'manually identifying', 'known'] 
",1
"This approach is  frequently used in conjunction with other techniques, because the explanatory knowledge is not  always readily available for large case bases.
","['This approach', 'conjunction techniques', 'explanatory knowledge', 'available large case bases']
","['frequently used'] 
",0
"4) Template retrieval
","['Template retrieval']
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 75
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"Template retrieval returns all cases that fit within certain criteria often used before other  techniques, such as nearest neighbour, to limit the search space to a relevant section of the  case-base.
","['Template retrieval returns cases', 'certain criteria', 'techniques', 'neighbour', 'search space', 'relevant section case-base']
","['fit', 'often used', 'limit'] 
",1
"  3.2.2  Case Reuse  This involves obtaining the solved case from a retrieved case.
","['Case Reuse', 'case', 'case']
","['involves obtaining solved', 'retrieved'] 
",1
"It analyses the differences  between the new case and the past cases and then determines what part of the retrieved case  can be transferred to the new case.
","['differences', 'new case', 'past cases determines part', 'case', 'new case']
","['analyses', 'retrieved', 'transferred'] 
",1
"CBR is essentially based on the concept of analogy wherein  by analyzing the previous cases we formulate a solution for the new cases [5].
","['CBR', 'concept analogy', 'previous cases', 'solution', 'new cases', ']']
","['essentially based', 'analyzing', 'formulate', '['] 
",1
"  3.2.3  Copy  In the trivial cases of reuse we generally copy the solution of the previous cases and make it the  solution for the new cases.
","['Copy', 'trivial cases', 'copy solution', 'previous cases', 'solution', 'new cases']
","['reuse', 'make'] 
",1
"But many systems take into consideration the differences between the  two cases and use the adaptation process to formulate a new solution based on these  differences.
","['many systems', 'consideration differences', 'cases', 'adaptation process', 'new solution', 'differences']
","['take', 'use', 'formulate', 'based'] 
",1
"  3.2.4  Adaptation  The adaptation process is of two kinds:  Structural adaptation- Adaptation rules are applied directly to the solution stored in cases i.e.-  reuse past case solution.
","['Adaptation', 'The adaptation process', 'kinds', 'Structural adaptation- Adaptation rules', 'solution', 'cases', 'i.e.- reuse', 'case solution']
","['applied', 'stored'] 
",1
"Derivational adaptation- Reuse the method that constructed the solution to a past problem.
","['Derivational adaptation- Reuse method', 'solution past problem']
","['constructed'] 
",0
"In structural adaptation we do not use the past solution directly but apply some transformation  parameters to construct the solution for the new case.
","['structural adaptation use', 'past solution', 'transformation parameters', 'solution', 'new case']
","['directly apply', 'construct'] 
",1
"Thus this kind of adaptation is also referred  to as transformational adaptation.
","['kind adaptation', 'transformational adaptation']
","['also referred'] 
",0
"In derivational adaptation we use the method or algorithm  applied previously to solve the new problem [17].
","['derivational adaptation use method algorithm', 'new problem', ']']
","['applied previously solve', '['] 
",1
"  3.2.5  Case Revision  After reusing the past cases to obtain a solution for the new case we need to test that solution.
","['Case Revision', 'past cases', 'solution', 'new case', 'test solution']
","['reusing', 'obtain', 'need'] 
",1
"We must check or test to see if the solution is correct.
","['test see solution correct']
","['check'] 
",0
"If the testing is successful then we retain  the solution, otherwise we must revise the case solution using domain specific knowledge.
","['successful retain solution', 'case solution', 'domain', 'specific knowledge']
","['testing', 'revise', 'using'] 
",1
"  3.2.6  Case Retainment- Learning (CRL)  The solution of the new problem after being tested and repaired may be retained into the existing  domain specific knowledge.
","['Case Retainment- Learning', 'CRL', 'The solution', 'new problem', 'domain', 'specific knowledge']
","['tested repaired', 'retained existing'] 
",1
"This process is called Case Retainment Learning or CRL.
","['This process', 'Case Retainment Learning CRL']
","['called'] 
",0
"Retaining  information involves selecting what information to retain, in what form to retain it, how to index the  case for later retrieval from similar problems, and how to integrate the new case in the memory  structure.
","['information', 'information retain', 'form retain', 'index case', 'similar problems', 'new case memory structure']
","['Retaining', 'involves selecting', 'later retrieval', 'integrate'] 
",1
"  3.2.7  Case Based Learning  An important feature of CBR is its coupling to learning [2].
","['Case', 'An important feature CBR', ']']
","['Based Learning', 'coupling learning'] 
",1
"Case-based reasoning is also regarded  a sub-field of machine learning.
","['Case-based reasoning', 'sub-field machine learning']
","['also regarded'] 
",0
"Thus, the notion of case-based reasoning does not only denote a  particular reasoning method, irrespective of how the cases are acquired, it also denotes a  machine learning paradigm that enables sustained learning by updating the case base after a  problem has been solved.
","['denote', 'particular reasoning method', 'irrespective cases', 'machine', 'paradigm enables', 'case base problem']
","['reasoning', 'acquired', 'also denotes', 'learning', 'sustained learning updating', 'solved'] 
",1
"Learning in CBR occurs as a natural by-product of problem solving.
","['CBR', 'natural by-product problem solving']
","['Learning', 'occurs'] 
",1
"When a problem is successfully solved, the experience is retained in order to solve similar  problems in the future.
","['problem', 'experience', 'order solve', 'similar problems']
","['successfully solved', 'retained'] 
",1
"When an attempt to solve a problem fails, the reason for the failure is  identified and remembered in order to avoid the same mistake in the future.
","['attempt solve problem', 'reason failure', 'order avoid']
","['fails', 'identified remembered', 'mistake'] 
",1
"CBR can be applied  to solve real world problems for instance handling of multiple disorders [16] or for engineering  sales support [23].
","['CBR', 'real world problems instance', 'multiple disorders', '] engineering sales support', ']']
","['applied solve', 'handling', '[', '['] 
",1
"4.
","[]
","[] 
",0
"CLASSIFICATION AND REGRESSION TREES (CART)    CART is a very efficient machine learning technique.
","['CLASSIFICATION AND REGRESSION TREES', 'CART', 'CART', 'efficient machine learning technique']
","[] 
",0
"The difference between this technique and  other machine learning technique is that CART requires very little input from the analyst.
","['The difference technique machine', 'technique CART', 'little input analyst']
","['learning', 'requires'] 
",1
"This is in
","[]
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 76
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"contrast to other technique where extensive input from the analyst, the analysis of interim results  and modification of method used is needed.
","['contrast technique', 'extensive input analyst', 'analysis', 'interim results modification method']
","['used needed'] 
",0
"Before going into the details of CART we identify the  three classes and two kinds of variables, which are important while defining classification and  regression problems.
","['details CART', 'classes', 'kinds variables', 'classification regression problems']
","['going', 'identify', 'defining'] 
",1
"There are three main classes of variables:  1) Target variable -- The “target variable” is the variable whose values are to be modeled and  predicted by other variables.
","['main classes variables', 'Target', 'The “ target', 'values', 'predicted variables']
","['modeled'] 
",0
"It is analogous to the dependent variable in linear regression.
","['analogous dependent variable linear regression']
","[] 
",0
"There  must be one and only one target variable in a decision tree analysis.
","['target', 'variable decision tree analysis']
","[] 
",0
"2) Predictor variable -- A “predictor variable” is a variable whose values will be used to predict the  value of the target variable.
","['Predictor', 'A “ predictor', 'variable ”', 'values', 'value target']
","['used predict'] 
",0
"It is analogous to the independent in linear regression.
","['analogous independent linear regression']
","[] 
",0
"There must be  at least one predictor variable specified for decision tree analysis; there may be many predictor  variables.
","['predictor', 'decision tree analysis', 'many predictor variables']
","['least', 'specified'] 
",1
"3) Weight variable -- You can specify a “weight variable”.
","['Weight variable', '“ weight', 'variable ”']
","['specify'] 
",0
"If a weight variable is specified, it must  a numeric (continuous) variable whose values are greater than or equal to 0 (zero).
","['values', 'zero']
","['weight', 'specified', 'numeric'] 
",1
"The value of  the weight variable specifies the weight given to a row in the dataset.
","['The value', 'variable specifies', 'row dataset']
","['weight', 'weight given'] 
",1
"There are 2 main kinds of variables:  1) Continuous variables -- A continuous variable has numeric values such as 1, 2, 3.14, -5, etc.
","['main kinds variables', 'Continuous variables', 'A continuous variable numeric values', '-5', 'etc']
","[] 
",0
"The relative magnitude of the values is significant (e.g.-, a value of 2 indicates twice the  magnitude of 1).
","['The relative magnitude values', 'value']
","['indicates'] 
",0
"Examples of continuous variables are blood pressure, height, weight, income,  age, and probability of illness.
","['Examples', 'continuous variables blood pressure', 'height', 'weight', 'income', 'age', 'probability illness']
","[] 
",0
"Some programs call continuous variables “ordered” or “monotonic”  variables.
","['Some programs', 'continuous variables', '” “', 'monotonic ” variables']
","['call', '“ ordered'] 
",1
"2) Categorical variables -- A categorical variable has values that function as labels rather than as  numbers.
","['Categorical variables', 'A categorical variable values', 'labels', 'numbers']
","['function'] 
",0
"Some programs call categorical variables “nominal” variables.
","['Some programs', 'categorical variables', 'nominal ” variables']
","['call', '“'] 
",1
"For example, a  categorical variable for gender might use the value 1 for male and 2 for female.
","['example', 'categorical variable gender', 'value', 'male', 'female']
","['use'] 
",0
"The actual  magnitude of the value is not significant; coding male as 7 and female as 3 would work just as  well   CART builds classification and regression trees for predicting continuous dependent variables  (regression) and categorical predictor variables (classification).
","['The actual magnitude value', 'male', 'CART', 'classification regression trees', 'continuous dependent variables', 'regression', 'categorical predictor variables', 'classification']
","['coding', 'work', 'builds', 'predicting'] 
",1
"Regression-type problems: These are generally those where one attempts to predict the values of  a continuous variable from one or more continuous and/or categorical predictor variables.
","['Regression-type problems', 'attempts', 'values', 'categorical predictor variables']
","['predict'] 
",0
"Classification-type problems: These are generally those where one attempts to predict values of a  categorical dependent variable from one or more continuous and/or categorical predictor  variables.
","['Classification-type problems', 'attempts', 'values', 'categorical dependent', 'categorical predictor variables']
","['predict'] 
",0
"CART is a non-parametric statistical methodology developed for analyzing classification issues  either from categorical or continuous dependent variables [24, 25].
","['CART', 'non-parametric statistical methodology', 'classification issues', 'categorical continuous dependent variables', ']']
","['developed analyzing', '['] 
",1
"If the dependent variable is  categorical, CART produces a classification tree.
","['dependent variable categorical', 'CART', 'classification tree']
","['produces'] 
",0
"When the dependent variable is continuous, it  produces a regression tree.
","['dependent', 'regression tree']
","['produces'] 
",0
"4.2  Binary Recursive Partitioning  Consider the problem of selecting the best size and type of laryngoscope blade for pediatric  patients undergoing intubations [20].
","['Binary Recursive Partitioning Consider problem', 'size type laryngoscope', 'pediatric patients', 'undergoing intubations', ']']
","['selecting', 'blade', '['] 
",1
"The outcome variable, the best blade for each patient (as  determined by a consulting pediatric airway specialist), has three possible values: Miller 0, Wis- Hipple 1.5, and Mac 2.
","['The outcome', 'blade patient', 'specialist', 'possible values', 'Miller', 'Wis- Hipple', 'Mac']
","['consulting'] 
",0
"The two-predictor variables are measurements of neck length and or  pharyngeal height.
","['The two-predictor variables measurements', 'length pharyngeal height']
","['neck'] 
",0
"The smallest patients are best incubated with the Miller 0, medium sized  patients with the Wis-Hipple 1.5, and the largest patients with the Mac 2.
","['patients', 'Miller', 'medium', 'patients', 'patients Mac']
","['best incubated', 'sized'] 
",1
"CART is basically used to avoid the disadvantage of the regression techniques.
","['CART', 'avoid disadvantage regression techniques']
","['basically used'] 
",0
"CART analysis  is a form of binary recursive partitioning [20].
","['CART analysis form', 'binary recursive partitioning', ']']
","[] 
",0
"The term “binary” implies that each node in a  decision tree can only be split into two groups.
","['The term “', 'binary ” implies', 'decision', 'tree split', 'groups']
","['node'] 
",0
"Thus, each node can be split into two child nodes,  in which case the original node is called a parent node.
","['node split', 'child nodes', 'case', 'original node', 'parent node']
","['called'] 
",0
"The term “recursive” refers to the fact that  the binary partitioning process can be applied over and over again.
","['The term “', 'recursive ” refers fact', 'binary partitioning process']
","['applied'] 
",0
"Thus, each parent node can  give rise to two child nodes and, in turn, each of these child nodes may themselves be split,  forming additional children.
","['parent', 'rise', 'child nodes', 'turn', 'child nodes', 'additional children']
","['node give', 'split', 'forming'] 
",1
"The term “partitioning” refers to the fact that the dataset is split into  sections or partitioned.
","['The term “', '” refers fact', 'split sections']
","['partitioning', 'dataset', 'partitioned'] 
",1
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 77
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"The figure:5 illustrates this kind of a partitioning.
","['The figure:5', 'kind partitioning']
","['illustrates'] 
",0
"This tree consists of a root node (Node 1),  containing all patients.
","['This tree', 'node', 'Node', 'patients']
","['consists root', 'containing'] 
",1
"This node is split based on the value of the neck length variable.
","['This node split', 'value neck length variable']
","['based'] 
",0
"If the  neck length is < 2.45 centimeters, then those patients are put in the first terminal node, denoted  Node -1, and the best blade is predicted to be a Miller 0.
","['neck length', 'centimeters', 'patients', 'first terminal node', 'Node -1', 'blade', 'Miller']
","['<', 'put', 'denoted', 'predicted'] 
",1
"All other patients are placed in Node 2.
","['All patients', 'Node']
","['placed'] 
",0
"The group of patients in Node 2 is initially assigned a Wis-Hipple 1.5 blade but they are also split  based on there or pharyngeal height.
","['The group patients Node', 'blade', 'pharyngeal height']
","['initially assigned', 'also split based'] 
",1
"Those patients with an or pharyngeal height less than 1.75  are placed in terminal Node -2, and assigned a Wis-Hipple 1.5 blade, while those with an or  pharyngeal height �1.75 are placed in terminal Node –3 and assigned a Mac 2 blade.
","['Those patients', 'terminal Node -2', 'blade', 'pharyngeal height �1.75', 'terminal Node –3', 'Mac', 'blade']
","['pharyngeal', 'placed', 'assigned', 'placed', 'assigned'] 
",1
"    4.3    CART Analysis   CART analysis is a tree-building technique, which is unlike traditional data analysis methods.
","['CART Analysis CART analysis tree-building technique', 'traditional data analysis methods']
","[] 
",0
"It is  ideally suited to the generation of clinical decision rules.
","['generation', 'clinical decision rules']
","['ideally suited'] 
",0
"CART Analysis consists of four basic steps: -    1.
","['CART Analysis', 'basic steps']
","['consists'] 
",0
"It consists of tree building, during which a tree is built using recursive splitting of nodes.
","['tree building', 'tree', 'recursive splitting nodes']
","['consists', 'built using'] 
",1
"Each  resulting node is assigned a predicted class, based on the distribution of classes in the learning  dataset, which would occur in that node and the decision cost matrix.
","['node', 'predicted class', 'distribution classes', 'dataset', 'node decision cost matrix']
","['resulting', 'assigned', 'based', 'learning', 'occur'] 
",1
"The assignment of a  predicted class to each node occurs whether or not that node is  remove space  subsequently  split into child nodes.
","['The assignment', 'class node', 'space', 'child nodes']
","['predicted', 'occurs', 'remove', 'subsequently split'] 
",1
"2.
","[]
","[] 
",0
"CART Analysis consists of stopping the tree building process.
","['CART Analysis', 'tree building process']
","['consists stopping'] 
",0
"At this point a “maximal” tree  has been produced, which probably greatly over fits the information contained within the learning  dataset.
","['point “', 'maximal ” tree', 'information', 'dataset']
","['produced', 'probably greatly fits', 'contained', 'learning'] 
",1
"3.
","[]
","[] 
",0
"It consists of tree “pruning,” which results in the creation of a sequence of                                    simpler and simpler trees, through the cutting off increasingly important nodes.
","['tree “ pruning', '” results creation sequence simpler simpler trees', 'important nodes']
","['consists', 'cutting'] 
",1
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 78
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"4.
","[]
","[] 
",0
"This step consists of optimal tree selection, during which the tree that fits the information in the  learning dataset, but does not over fit the information, is selected from among the sequence of  pruned trees.
","['This step', 'optimal tree selection', 'tree fits information learning dataset', 'fit information', 'sequence', 'trees']
","['consists', 'selected', 'pruned'] 
",1
"5.
","[]
","[] 
",0
"RULE INDUCTION    Rule Induction is another very important machine learning method and it is easier because the  rules in rule induction are transparent and easy to interpret than a regression model or a trained  neural network.
","['RULE INDUCTION Rule Induction', 'another important machine', 'method', 'rules', 'induction transparent', 'easy interpret regression model', 'neural network']
","['learning', 'rule', 'trained'] 
",1
"This paradigm employs condition-action rules, decision trees, or similar  knowledge structures.
","['condition-action rules', 'decision trees', 'similar knowledge structures']
","['employs'] 
",0
"Here the performance element sorts instances down the branches of the  decision tree or finds the first rule whose conditions match the instance, typically using an all-or- none match process [19].
","['performance element sorts instances branches decision tree', 'first rule', 'conditions', 'instance', 'all-or- none match process', ']']
","['finds', 'match', 'typically using', '['] 
",1
"Information about classes or predictions is stored in the action sides of  the rules or the leaves of the tree.
","['Information classes predictions', 'action sides rules leaves']
","['stored', 'tree'] 
",1
"Learning algorithms in the rule induction framework usually  carry out a greedy search through the space of decision trees or rule sets, typically using a  statistical evaluation function to select attributes for incorporation into the knowledge structure.
","['algorithms rule induction framework', 'greedy search space decision trees', 'sets', 'statistical evaluation function select', 'incorporation knowledge structure']
","['Learning', 'usually carry', 'rule', 'typically using', 'attributes'] 
",1
"Most methods partition the training data recursively into disjoint sets, attempting to summarize  each set as a conjunction of logical conditions.
","['methods partition training data', 'disjoint sets', 'summarize', 'conjunction', 'logical conditions']
","['attempting', 'set'] 
",1
"Rule Learning process     If we are given a set of training examples i.e.- instances for which classification is known we find a  set of classification rules which are used to predict new cases that haven't been presented to the  learner before.
","['Rule Learning process', 'examples', 'i.e.- instances classification', 'set classification rules', 'new cases', 'learner']
","['given set training', 'known find', 'used predict', ""n't presented""] 
",1
"While deriving these instances the bias imposed by languages must be taken into  account such as restrictions imposed while describing data and we must also consider the  language used to describe the induced set of rules.
","['instances', 'languages', 'account restrictions', 'data', 'language', 'induced set rules']
","['deriving', 'bias imposed', 'taken', 'imposed describing', 'also consider', 'used'] 
",1
"Consider a binary classification problem of classifying instances into classes positive and  negative.
","['binary classification problem', 'instances classes']
","['Consider', 'classifying'] 
",1
"We are given a data description language, which impose a bias on the data, training  examples, a hypothesis language imposing a bias on the induction rules and a coverage function  defining when an instance is covered by a rule.
","['data description language', 'bias data', 'training examples', 'hypothesis language', 'bias induction rules coverage function', 'instance', 'rule']
","['given', 'impose', 'imposing', 'defining', 'covered'] 
",1
"Given the above data we need to find a  hypothesis defined by a set of rules in a language, which is consistent that it does not cover any  negative examples and is complete that it covers all positive examples.
","['data', 'hypothesis', 'rules language', 'consistent cover', 'negative examples', 'complete covers', 'positive examples']
","['Given', 'need find', 'defined set'] 
",1
"Thus in this manner,  given the required data and the problem we can determine a set of rules, which classify the  instances in that problem.
","['manner', 'data problem determine set rules', 'instances problem']
","['given required', 'classify'] 
",1
"This forms the basis of rule induction.
","['basis rule induction']
","['forms'] 
",0
"There are two main approaches to rule induction namely propositional learning and relational rule  learning.
","['main approaches rule induction', 'relational rule learning']
","['learning'] 
",0
"Propositional Rule Learning     Propositional rule learning systems are suited for problems in which no substantial relationship  between the values of the different attributes needs to be represented.
","['Propositional Rule Learning Propositional rule', 'systems', 'problems', 'substantial relationship values', 'different attributes needs']
","['learning', 'suited', 'represented'] 
",1
"A set of instances with  known classifications where each instance is described by values of a fixed collection of attributes  is given.
","['A set instances', 'classifications instance', 'values', 'collection']
","['known', 'described', 'fixed', 'attributes given'] 
",1
"The attributes can have either a fixed set of values or take real numbers as values.
","['The attributes', 'fixed set values', 'real numbers values']
","['take'] 
",0
"Given these instances we then construct a set of IF-THEN rules.
","['instances construct', 'IF-THEN rules']
","['Given', 'set'] 
",1
"The output of learning is a  hypothesis represented by a set of rules.
","['The output', 'hypothesis', 'set rules']
","['learning', 'represented'] 
",1
"After the rules have been defined determining the  accuracy of such rules and then applying these rules to practical problems analyze their quality.
","['rules', 'accuracy rules', 'rules', 'practical problems', 'quality']
","['defined determining', 'applying', 'analyze'] 
",1
"In propositional learning the available data has a standard form with rows being individual records  or training examples and columns being properties or attributes to describe the data.
","['propositional learning', 'available data', 'standard form', 'individual records', 'examples columns properties', 'describe data']
","['rows', 'training', 'attributes'] 
",1
"Relational Rule Learning/ Inductive logic Programming (ILP)    When data is stored in several tables then it has a relational database form.
","['Relational Rule Learning/ Inductive logic Programming', 'ILP', 'data', 'several tables', 'relational database form']
","['stored'] 
",0
"In such cases the  data has to be transformed into a single table in order to use standard data mining techniques.
","['cases data', 'single table order', 'standard data mining techniques']
","['transformed', 'use'] 
",1
"The most common data transformation approach is to select one table as the main table to be  used for learning, and try to incorporate the contents of other tables by summarizing the  information contained in the table into some summary attributes, added to the main table.
","['The common data transformation approach', 'table', 'main table', 'learning', 'incorporate contents', 'information', 'table summary attributes', 'main table']
","['select', 'used', 'try', 'tables summarizing', 'contained', 'added'] 
",1
"The
","[]
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 79
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"problem with such single-table transformations is that some information may be lost while the  summarization may also introduce artifacts, possibly leading to inappropriate data mining results.
","['problem', 'single-table transformations information', 'summarization', 'artifacts', 'inappropriate data mining results']
","['lost', 'also introduce', 'possibly leading'] 
",1
"What one would like to do is to leave data conceptually unchanged and rather use data mining  tools that can deal with multi-relational data.
","['data', 'use data mining tools', 'multi-relational data']
","['like leave', 'deal'] 
",1
"ILP is intended at solving multi-relational data mining  tasks.
","['ILP', 'multi-relational data mining tasks']
","['intended solving'] 
",0
"Thus ILP is to be used for data mining in multi-relational data mining tasks with data stored in  relational databases and tasks with abundant expert knowledge of a relational nature.
","['ILP', 'data', 'multi-relational data mining tasks data', 'relational databases tasks', 'abundant expert knowledge', 'relational nature']
","['used', 'mining', 'stored'] 
",1
"Another  important concept within the realm of relational rule learning is that of boosting.
","['Another important concept', 'realm relational rule', 'boosting']
","['learning'] 
",0
"Boosting is a  particularly robust and powerful technique to enhance the prediction accuracy of systems that  learn from examples [22].
","['robust powerful technique enhance prediction accuracy systems', 'examples', ']']
","['Boosting', 'learn'] 
",1
"Thus boosting helps to improve the overall efficiency of the results  obtained.
","['overall efficiency results']
","['Thus boosting helps improve', 'obtained'] 
",1
"An example to illustrate Rule Induction    Case Study (Making Credit Decisions)  Loan companies regularly use questionnaires to collect information about people applying for  credit, which they then use in deciding whether to make loans.
","['An example illustrate Rule Induction Case Study', 'Credit Decisions', 'Loan companies', 'questionnaires', 'collect information people', 'credit', 'make loans']
","['Making', 'regularly use', 'applying', 'use deciding'] 
",1
"This process has long been  partially automated.
","['This process']
","['long partially automated'] 
",0
"For example, American Express UK used a statistical decision process  based on discriminated analysis to reject applicants falling below a certain threshold and to  accept those exceeding another.
","['example', 'American Express UK', 'statistical decision process', 'analysis reject applicants', 'certain threshold accept']
","['used', 'based discriminated', 'falling', 'exceeding'] 
",1
"The remaining 10 to 15 percent of the applicants fell into a  borderline region and were referred to higher authorities giving loan for a decision.
","['percent applicants', 'borderline region', 'authorities', 'loan decision']
","['remaining', 'fell', 'referred', 'giving'] 
",1
"However,  records showed that these authorities were no more than 50% accurate in predicting whether  these borderline applicants would default on their loans.
","['records', 'authorities', '% accurate', 'borderline applicants', 'loans']
","['showed', 'predicting', 'default'] 
",1
"These observations motivated American  Express UK to try methods from machine learning to improve the decision process.
","['These observations', 'American Express UK', 'methods machine', 'improve decision process']
","['motivated', 'try', 'learning'] 
",1
"Starting with  1014 training cases and 18 descriptive attributes (such as age and years with an employer),  Michie and his colleagues used an induction method to produce a decision tree, containing  around 20 nodes and ten of the original features, that made correct predictions on 70% of the  borderline applicants.
","['training cases', 'descriptive attributes', 'age years employer', 'Michie colleagues', 'induction method', 'decision tree', 'nodes', 'original features', 'correct predictions', '% borderline applicants']
","['Starting', 'used', 'produce', 'containing', 'ten', 'made'] 
",1
"In addition to achieving improved accuracy, the company found the rules  attractive because they could be used to explain the reasons for decisions to applicants.
","['addition', 'improved accuracy', 'company', 'rules', 'reasons decisions applicants']
","['achieving', 'found', 'used explain'] 
",1
"American Express UK was so impressed that they put the resulting knowledge base into use  without further development.
","['American Express UK', 'knowledge base use', 'development']
","['impressed put resulting'] 
",0
"6.
","[]
","[] 
",0
"GENETIC ALGORITHMS AND GENETIC PROGRAMMING  The genetic approach to machine learning is a relatively new concept.
","['GENETIC ALGORITHMS AND GENETIC PROGRAMMING', 'The genetic approach machine', 'new concept']
","['learning'] 
",0
"Both genetic algorithms  and Genetic Programming (GP) are a form of evolutionary computing which is a collective name  for problem solving techniques based on the principles of biological evolution like natural  selection.
","['Both genetic algorithms Genetic Programming', 'GP', 'form', 'collective name problem', 'techniques', 'principles', 'biological evolution', 'natural selection']
","['computing', 'solving', 'based'] 
",1
"Genetic algorithms use a vocabulary borrowed from natural genetics in that they talk  about genes (or bits), chromosomes (individuals or bit strings), and population (of individuals)  [10].
","['Genetic algorithms use', 'natural genetics talk genes', 'bits', 'chromosomes', 'individuals', 'strings', 'population', 'individuals', ']']
","['borrowed', 'bit', '['] 
",1
"Genetic algorithm approach is centered around three main processes- crossovers, mutation  and selection of individuals.
","['Genetic algorithm approach', 'main processes- crossovers', 'mutation selection individuals']
","['centered'] 
",0
"Initially many individual solutions are gathered together to make a  randomly generated population.
","['many individual solutions', 'population']
","['gathered together make', 'randomly generated'] 
",1
"Genetic algorithms are based upon the Darwin theory of  "" The  survival of the Fittest"" depending upon the fitness function the best possible solutions are  selected from the pool of individuals.
","['Genetic algorithms', 'Darwin theory', 'The survival Fittest', 'fitness function', 'possible solutions', 'pool individuals']
","['based', 'depending', 'selected'] 
",1
"The fitter individuals have greater chances of its selection  and higher the probability that its genetic information will be passed over to future generations.
","['The fitter individuals', 'chances selection', 'probability', 'genetic information', 'future generations']
","['passed'] 
",0
"Once selection is over new individuals have to be formed.
","['selection new individuals']
","['formed'] 
",0
"These new individuals are formed  either through crossover or mutation.
","['These new individuals', 'crossover mutation']
","['formed'] 
",0
"In the process of crossover, combining the genetic make up  of two solution candidates (producing a child out of two parents) creates new individuals.
","['process crossover', 'genetic make', 'solution candidates', 'child', 'parents', 'new individuals']
","['combining', 'producing', 'creates'] 
",1
"Whereas in mutation, we alter some individuals, which means that some randomly chosen parts  of genetic information is changed to obtain a new individual.
","['Whereas mutation', 'alter individuals', 'parts', 'genetic information', 'new individual']
","['means randomly chosen', 'changed obtain'] 
",1
"The process of generation doesn't  stop until one of the conditions like minimum criteria is met or the desired fitness level is attained  or a specified number of generations are reached or any combination of the above [21].
","['The process generation', 'conditions', 'minimum criteria', 'desired fitness level', 'specified number generations', 'combination', ']']
","[""n't stop"", 'met', 'attained', 'reached'] 
",1
"John Koza popularized GP, an offset of Genetic Algorithm in 1992.
","['John Koza', 'GP', 'Genetic Algorithm']
","['popularized', 'offset'] 
",1
"It aims at optimizing computer  programs rather than function parameters.
","['computer programs', 'function parameters']
","['aims optimizing'] 
",0
"GP is a supervised machine learning technique where algorithms are modeled after natural  selection.
","['GP', 'machine learning technique algorithms', 'natural selection']
","['supervised', 'modeled'] 
",1
"These algorithms are represented as function trees where these trees are intended to
","['These algorithms', 'function trees trees']
","['represented', 'intended'] 
",1
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 80
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"perform a given task [6].
","['task', ']']
","['perform given'] 
",0
"In GP the fitter individuals are retained and allowed to develop whereas  others are discarded [4].
","['GP fitter individuals', 'whereas others', ']']
","['retained allowed develop', 'discarded'] 
",1
"GP works in a manner similar to genetic algorithm.
","['GP', 'similar genetic algorithm']
","['works'] 
",0
"It also follows the principles of natural  evolution to generate a solution that maximizes (or minimizes) some fitness function [3].
","['principles', 'natural evolution generate solution maximizes', 'minimizes', 'fitness function', ']']
","['also follows', '['] 
",1
"GP  differs from GA in the sense that GP tends to find the solution of a given problem by representing  it as a array of integers while the goal of a GP process is to produce a computer program to solve  the optimization problem at hand.
","['GP differs GA sense GP', 'find solution', 'problem', 'array integers goal GP process', 'computer program', 'optimization problem hand']
","['tends', 'given', 'representing', 'produce', 'solve'] 
",1
"GP cycle works as any evolutionary process.
","['GP cycle', 'evolutionary process']
","['works'] 
",0
"New individuals  are created; tested and fitter ones succeed in creating their own children.
","['New individuals', 'fitter ones', 'children']
","['created', 'tested', 'succeed creating'] 
",1
"The unfit individuals are  removed from the population.
","['The unfit individuals', 'population']
","['removed'] 
",0
"The figure:6  illustrates how GP cycle works.
","['The figure:6', 'GP cycle works']
","['illustrates'] 
",0
"Population of Programs
","['Population Programs']
","[] 
",0
"Test Programs
","['Test Programs']
","[] 
",0
"Select Parents in
","['Select Parents']
","[] 
",0
"propertion to their fitness
","['propertion fitness']
","[] 
",0
"Creates New
","['New']
","['Creates'] 
",0
"Programs
","['Programs']
","[] 
",0
"Figure 6: Genetic Programming Cycle
","['Figure', 'Genetic Programming Cycle']
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 81
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"7.
","[]
","[] 
",0
"Discussion on Various Machine Learning Techniques
","['Discussion Various Machine Learning Techniques']
","[] 
",0
"Technique Application Areas Potential Benefits Limitations
","['Technique Application Areas Potential Benefits Limitations']
","[] 
",0
"Neural Networks (NN) Testing  Effort Estimation  Function Point Analysis  Risk Management  Reliability Metrics  Sales Forecasting
","['Neural Networks', 'NN', 'Effort Estimation Function Point Analysis Risk Management Reliability Metrics Sales']
","['Testing', 'Forecasting'] 
",1
"Adaptive learning: An ability to learn how to  do tasks based on the data given for  training or initial experience.
","['Adaptive learning', 'An ability learn tasks', 'data', 'initial experience']
","['based', 'given training'] 
",1
"Self-Organization: An ANN can create its  own organization or representation of the  information it receives during learning time.
","['Self-Organization', 'An ANN create organization representation information', 'learning time']
","['receives'] 
",0
"Real Time Operation: ANN computations  may be carried out in parallel, and special  hardware devices are being designed and  manufactured which take advantage of this  capability.
","['Real Time Operation', 'ANN computations', 'parallel', 'special hardware devices', 'advantage capability']
","['carried', 'designed manufactured take'] 
",1
"Fault Tolerance via Redundant Information  Coding: Partial destruction of a network  leads to the corresponding degradation of  performance.
","['Fault Tolerance', 'Redundant Information Coding', 'Partial destruction network', 'degradation performance']
","['leads corresponding'] 
",0
"However, some network  capabilities may be retained even with  major network damage.
","['network capabilities', 'major network damage']
","['retained'] 
",0
"Minimizing over fitting requires a  great deal of computational effort.
","['fitting', 'great deal computational effort']
","['Minimizing', 'requires'] 
",1
"The individual relations between  the input variables and the output  variables are not developed by  engineering judgment so that the  model tends to be a black box or  input/output table without  analytical basis.
","['The individual relations', 'variables output variables', 'engineering judgment model', 'black box input/output table', 'analytical basis']
","['input', 'developed', 'tends'] 
",1
"The sample size has to be large.
","['The sample size']
","[] 
",0
"Case Based Reasoning  (CBR)
","['Case', 'Reasoning', 'CBR']
","['Based'] 
",0
"Help-Desk Systems  Software Effort Estimation  Classification and Prediction  Knowledge Based Decision  systems.
","['Help-Desk Systems Software Effort Estimation Classification Prediction Knowledge', 'Decision systems']
","['Based'] 
",0
"No Expert is Required  The CBR Process is more akin to human  thinking.
","['No Expert', 'The CBR Process', 'akin human thinking']
","['Required'] 
",0
"CBR can handle failed cases (i.e.- those  cases for which accurate prediction cannot  be made)  No extensive maintenance is required.
","['CBR handle', 'cases', 'i.e.- cases', 'prediction', 'No extensive maintenance']
","['failed', 'accurate', 'made', 'required'] 
",1
"Case data can be hard to gather.
","['Case', 'hard gather']
","['data'] 
",0
"Predictions are limited to the  cases that have been observed.
","['Predictions', 'cases']
","['limited', 'observed'] 
",1
"Classification and  Regression Trees (CART)
","['Classification Regression Trees', 'CART']
","[] 
",0
"Financial applications like  Customer Relationship  Management (CRM)
","['Financial applications', 'Customer Relationship Management', 'CRM']
","[] 
",0
"It is inherently non-parametric in other  words no assumptions are made regarding  the underlying distribution of values of the
","['non-parametric words assumptions', 'underlying distribution values']
","['made regarding'] 
",0
"Relatively new and somewhat  unknown.
","[]
","[] 
",0
"Since CART is a new technique it is
","['CART', 'new technique']
","[] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 82
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"Effort Prediction (used in models  like COCOMO)
","['Effort Prediction', 'models', 'COCOMO']
","['used'] 
",0
"predictor variables.
","['predictor variables']
","[] 
",0
"CART identifies splitting variables based on  an exhaustive search of all possibilities.
","['CART', 'variables', 'exhaustive search possibilities']
","['identifies splitting', 'based'] 
",1
"It has methods for dealing with missing  variables.
","['variables']
","['methods dealing missing'] 
",0
"It is a relatively automatic machine learning  technique.
","['automatic machine learning technique']
","[] 
",0
"CART trees are easy to interpret even for  non-statisticians.
","['CART trees', 'non-statisticians']
","['easy'] 
",0
"difficult to find statisticians with  significant expertise in this  technique.
","['statisticians significant expertise technique']
","['find'] 
",0
"CART may have unstable decision  trees.
","['CART', 'unstable decision trees']
","[] 
",0
"CART splits only by one variable.
","['CART', 'variable']
","['splits'] 
",0
"Rule Induction  Making Credit Decisions (in  various loan companies)  Diagnosis of Mechanical Devices  Classification of Celestial Objects  Preventing breakdowns in  transformers
","['Rule Induction Making Credit Decisions', 'various loan companies', 'Diagnosis Mechanical', 'Classification Celestial Objects Preventing', 'transformers']
","['breakdowns'] 
",0
"Simplicity of input variables.
","['Simplicity input variables']
","[] 
",0
"The representation in rule-based technique  is easier to depict and understand.
","['The representation', 'rule-based technique', 'depict understand']
","[] 
",0
"No sufficient background  knowledge is available.
","['No sufficient background knowledge']
","[] 
",0
"It is  deduced from examples.
","['examples']
","['deduced'] 
",0
"Hard to maintain a complex rule- base.
","['Hard maintain', 'complex rule- base']
","[] 
",0
"Genetic Algorithms (GA)  and Genetic Programming  (GP)
","['Genetic Algorithms', 'GA', 'Genetic Programming', 'GP']
","[] 
",0
"Optimization  Simulation of economic processes  Scientific research purposes  (Biological Evolution)  Computer Games
","['Optimization Simulation', 'economic processes Scientific research purposes', 'Biological Evolution', 'Computer']
","[] 
",0
"GA and GP techniques can be applied to a  variety of problems.
","['GA GP techniques', 'variety problems']
","['applied'] 
",0
"GP is based on the 'Survival of the Fittest    Scheme' allowing fitter individuals to  develop and discarding unfit ones.
","['GP', 'Fittest Scheme', 'fitter individuals', 'unfit ones']
","['based', 'allowing', 'develop discarding'] 
",1
"GA is easy to grasp and can be easily  applied without much difficulty
","['GA', 'easy grasp', 'much difficulty']
","['easily applied'] 
",0
"Resource requirements are large.
","['Resource requirements']
","[] 
",0
"It can be a time consuming  process.
","['time', 'process']
","['consuming'] 
",0
"GA practitioners often run many  copies of the same code with the  same inputs to get statistically  reliable results.
","['GA practitioners', 'many copies', 'inputs', 'reliable results']
","['often run', 'code', 'get'] 
",1
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 83
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"8.
","[]
","[] 
",0
"Conclusions and Future Directions  The main contribution of this review is to discuss the various Machine-Learning Techniques  employed in effort estimation, cost estimation, size estimation and other field of Software  Engineering.
","['Conclusions Future', 'The main contribution review', 'various Machine-Learning Techniques', 'effort estimation', 'cost estimation', 'size estimation field Software Engineering']
","['discuss', 'employed'] 
",1
"The paper also gives a relative comparison of all the techniques based on their  applications, advantages and limitations.
","['The paper', 'relative comparison techniques', 'applications', 'advantages limitations']
","['also gives', 'based'] 
",1
"After analysis of all the techniques, we cannot state as  any one technique being the best.
","['analysis techniques', 'state', 'technique']
","[] 
",0
"Each technique has different application areas and is useful in  different domains based on its advantages.
","['Each technique', 'different application areas', 'useful different domains', 'advantages']
","['based'] 
",0
"Thus, keeping in mind the limitations of each of the  techniques and also the prime focus being the improvement in performance and efficiency we  should use that technique, which best suits a particular application.
","['mind limitations techniques', 'prime focus improvement performance efficiency use technique', 'suits', 'particular application']
","['keeping'] 
",0
"For instance GA and GP  prove to be useful in the area of scientific research involving biological evolution whereas rule  based techniques and CART analysis may be useful in many financial applications.
","['instance GA GP', 'useful area', 'scientific research', 'biological evolution whereas', 'techniques CART analysis', 'many financial applications']
","['prove', 'involving', 'rule based', 'useful'] 
",1
"Similarly CBR  is being developed for use in Help- Desk Systems, a relatively new application and NN may be  employed for Risk Management or Sales Forecasting.
","['CBR', 'Help- Desk', 'new application NN', 'Risk Management Sales']
","['developed use', 'employed', 'Forecasting'] 
",1
"Our study also encourages that no one technique can be classified as being the perfect machine  learning technique.
","['study', 'technique', 'perfect machine learning technique']
","['also encourages', 'classified'] 
",1
"For this reason there is a strong need for better insight into the validity and  generality of many of the discussed techniques.
","['reason', 'strong need', 'insight validity generality', 'techniques']
","['discussed'] 
",0
"In particular we plan to continue with research  on: -  When to use machine-learning techniques and estimation models.
","['particular plan', 'research', 'machine-learning techniques estimation models']
","['continue', 'use'] 
",1
"How to select and combine a set of test cases for effective estimation technique & to get better  results?
","['select combine', 'test cases', 'effective estimation technique', 'results']
","['set', 'get'] 
",1
"9.
","[]
","[] 
",0
"REFERENCES:  [1] Aggarwal K.K., Yogesh Singh, A.Kaur, O.P.Sangwan ""A Neural Net Based Approach to Test  Oracle""   ACM SIGSOFT Vol.
","['REFERENCES', '] Aggarwal K.K.', 'Yogesh Singh', 'A.Kaur', 'O.P.Sangwan', 'A Neural Net', 'Approach Test Oracle', 'ACM SIGSOFT Vol']
","['Based'] 
",0
"29 No.
","[]
","[] 
",0
"4, May 2004.
","['May']
","[] 
",0
"[2].
","[']']
","[] 
",0
"Agnar Aamodt, Enric Plaza.
","['Agnar Aamodt', 'Enric Plaza']
","[] 
",0
"""Foundational Issues, Methodological Variations, System  approaches.""
","['Foundational Issues', 'Methodological Variations', 'System']
","['approaches'] 
",0
"AlCom -Artificial Intelligence Communications, IOS Press Vol.
","['AlCom', '-Artificial Intelligence Communications', 'IOS Press Vol']
","[] 
",0
"7: 1, pp.
","['pp']
","[] 
",0
"39-59.
","[]
","[] 
",0
"[3]  Al Globus.
","['] Al Globus']
","[] 
",0
"""Towards 100,000 CPU Cycle-Scavenging by Genetic Algorithms.""
","['Towards', 'CPU Cycle-Scavenging Genetic Algorithms']
","[] 
",0
"CSC at NASA  Ames  Research Center, September 2001.
","['CSC NASA Ames Research Center', 'September']
","[] 
",0
"[4]  Chris Bozzuto.
","['] Chris Bozzuto']
","[] 
",0
"""Machine Learning: Genetic Programming.""
","['Machine Learning', 'Genetic Programming']
","[] 
",0
"February 2002.
","['February']
","[] 
",0
"[5] Dr. Bonnie Morris, West Virginia University ""Case Based Reasoning"" AI/ES Update vol.
","['] Dr. Bonnie Morris', 'West Virginia University', 'Case', 'AI/ES Update vol']
","['Based Reasoning'] 
",0
"5 no.
","[]
","[] 
",0
"1 Fall 1995.
","['Fall']
","[] 
",0
"[6] Eleazar Eskin and Eric Siegel.
","['] Eleazar Eskin Eric Siegel']
","[] 
",0
"""Genetic Programming Applied to Othello: Introducing Students  to Machine Learning Research"" available at http://www.cs.columbia.edu/~evs/papers/sigcse- paper.ps.
","['Genetic Programming Applied Othello', 'Introducing Students', 'Research', 'available http', '//www.cs.columbia.edu/~evs/papers/sigcse- paper.ps']
","['Machine Learning'] 
",0
"[7] Gavin R. Finnie   and Gerhard E. Wittig, “AI Tools for Software Development Effort  Estimation”, IEEE Transaction on Software Engineering, 1996.
","['] Gavin R. Finnie Gerhard E. Wittig', '“ AI Tools Software Development Effort Estimation ”', 'IEEE Transaction Software Engineering']
","[] 
",0
"[8]  Haykin S., “Neural Networks, A Comprehensive Foundation,” Prentice  Hall India, 2003.
","['] Haykin S.', '“ Neural Networks', 'A Comprehensive Foundation', '” Prentice Hall India']
","[] 
",0
"[9].
","[']']
","[] 
",0
"Howden William E. and Eichhorst Peter.
","['Howden William E. Eichhorst Peter']
","[] 
",0
"Proving properties of programs from program traces.
","['properties programs program traces']
","['Proving'] 
",0
"In Tutorial: Software Testing and Validation Techniques: E Miller and W.E.howden(eds.0.
","['Tutorial', 'Software Testing Validation Techniques', 'E Miller W.E.howden', 'eds.0']
","[] 
",0
"new  York:IEEE Computer Society Press, 1978.
","['new York', 'IEEE Computer Society Press']
","[] 
",0
"[10] Hsinchun Chen.
","['] Hsinchun Chen']
","[] 
",0
"""Machine Learning for Information Retrieval: Neural Networks, Symbolic  Learning, and Genetic Algorithms"" available at  http://ai.bpa.arizona.edu/papers/mlir93/mlir93.html#318.
","['Machine Learning Information Retrieval', 'Neural Networks', 'Symbolic Learning', 'Genetic Algorithms', 'available http']
","[] 
",0
"[11] Ian Watson & Farhi Marir.
","['] Ian Watson', 'Farhi Marir']
","[] 
",0
"""Case-Based Reasoning: A Review "" available at http://www.ai- cbr.org/classroom/cbr-review.html.
","['Case-Based Reasoning', 'A Review', 'available http', '//www.ai- cbr.org/classroom/cbr-review.html']
","[] 
",0
"[12] Juha Hakkaarainen, Petteri Laamanen, and Raimo Rask, “ Neural Network in Specification  Level Software Size Estimation”, IEEE Transaction on Software Engineering, 1993.
","['] Juha Hakkaarainen', 'Petteri Laamanen', 'Raimo Rask', '“ Neural Network Specification Level Software Size Estimation ”', 'IEEE Transaction Software Engineering']
","[] 
",0
"[13] Krishnamoorthy Srinivasan and Douglas Fisher, “Machine Learning Approaches to  Estimating Software Development Effort”, IEEE Transaction on Software Engineering, 1995.
","['] Krishnamoorthy Srinivasan Douglas Fisher', '“ Machine Learning Approaches Estimating Software Development Effort ”', 'IEEE Transaction Software Engineering']
","[] 
",0
"[14] Kohonen T., “Self Organizing Maps”, 2nd Edition, Berlin: Springer- Verlag, 1997.
","['] Kohonen T.', '“ Self Organizing Maps ”', 'Edition', 'Berlin', 'Springer- Verlag']
","[] 
",0
"[15].
","[']']
","[] 
",0
"Mayrhauser A. von, Anderson C. and Mraz R., “Using A Neural Network to Predict Test  Case Effectiveness”’ – Procs IEEE Aerospace Applications Conference, Snowmass, CO,  Feb.1995.
","['Mayrhauser A. von', 'Anderson C. Mraz R.', '“', 'A Neural Network Predict Test Case Effectiveness ” ’ – Procs IEEE Aerospace Applications Conference', 'Snowmass', 'CO', 'Feb.1995']
","['Using'] 
",0
"Yogesh Singh, Pradeep Kumar Bhatia & Omprakash Sangwan
","['Yogesh Singh', 'Pradeep Kumar Bhatia', 'Omprakash Sangwan']
","[] 
",0
"International Journal of Computer Science and Security, Volume (1) : Issue (1) 84
","['International Journal Computer Science Security', 'Volume', 'Issue']
","[] 
",0
"[16] Martin Atzmueller, Joachim Baumeister, Frank Puppe, Wenqi Shi, and John A. Barnden ""  Case Based Approaches for handling multiple disorders"" Proceedings of the Seventeenth  International Florida Artificial Intelligence Research Society, 2004.
","['] Martin Atzmueller', 'Joachim Baumeister', 'Frank Puppe', 'Wenqi Shi', 'John A. Barnden', 'Case', 'Approaches', 'multiple disorders', 'Proceedings Seventeenth International Florida Artificial Intelligence Research Society']
","['Based', 'handling'] 
",1
"[17] Nahid Amani, Mahmood Fathi and Mahdi Rehghan.
","['] Nahid Amani', 'Mahmood Fathi Mahdi Rehghan']
","[] 
",0
"""A Case-Based Reasoning Method for  Alarm  Filtering and Correlation in Telecommunication Networks"" available at   http://ieeexplore.ieee.org/iel5/10384/33117/01557421.pdf?arnumber=1557421.
","['A Case-Based Reasoning Method Alarm Filtering Correlation Telecommunication Networks', 'available http', '//ieeexplore.ieee.org/iel5/10384/33117/01557421.pdf', 'arnumber=1557421']
","[] 
",0
"[18] Pat Langley, Stanford and Herbert A. Simon, Pittsburgh.
","['] Pat Langley', 'Stanford Herbert A. Simon', 'Pittsburgh']
","[] 
",0
"""Application of Machine Learning  and Rule Induction.""
","['Application Machine Learning Rule Induction']
","[] 
",0
"available at http://cll.stanford.edu/~langley/papers/app.cacm.ps.
","['available http', '//cll.stanford.edu/~langley/papers/app.cacm.ps']
","[] 
",0
"[19]Peter Flach and Nada Lavrac.
","['] Peter Flach Nada Lavrac']
","[] 
",0
"""Rule Induction"" available at   www.cs.bris.ac.uk/Teaching/Resources/COMSM0301/materials/RuleInductionSection.pdf.
","['Rule Induction', 'available www.cs.bris.ac.uk/Teaching/Resources/COMSM0301/materials/RuleInductionSection.pdf']
","[] 
",0
"[20] Roger J. Lewis.
","['] Roger J. Lewis']
","[] 
",0
"""An Introduction to Classification and Regression Tree (CART) Analysis""  Presented at the 2000 Annual Meeting of the Society for Academic Emergency Medicine in San   Francisco, California.
","['An Introduction Classification Regression Tree', 'CART', 'Analysis', 'Annual Meeting Society Academic Emergency Medicine San Francisco', 'California']
","['Presented'] 
",0
"[21]  Stephen M Winkler, Michael Aenzeller and Stefan Wagner.
","['] Stephen M Winkler', 'Michael Aenzeller Stefan Wagner']
","[] 
",0
"""Advances in Applying Genetic  Programming to Machine Learning, Focusing on Classification Problems"" available at   http://www.heuristiclab.com/publications/papers/winkler06c.ps.
","['Advances Applying Genetic Programming Machine Learning', 'Classification', 'available http', '//www.heuristiclab.com/publications/papers/winkler06c.ps']
","['Focusing'] 
",0
"[22] Susanne Hoche.
","['] Susanne Hoche']
","[] 
",0
"""Active Relational Rule Learning in a Constrained Confidence-Rated  Boosting Framework"" PhD Thesis, Rheinische Friedrich-Wilhelms-Universitaet Bonn, Germany,  December 2004.
","['Active Relational Rule Learning', 'Confidence-Rated Boosting Framework', 'PhD Thesis', 'Rheinische Friedrich-Wilhelms-Universitaet Bonn', 'Germany', 'December']
","['Constrained'] 
",0
"[23] Watson, I.
","['] Watson']
","[] 
",0
"& Gardingen, D. "" A Distributed Case-Based Reasoning Application for  Engineering Sales Support"".
","['Gardingen', 'D.', 'A Distributed', 'Case-Based Reasoning Application Engineering Sales Support']
","[] 
",0
"In, Proc.
","['Proc']
","[] 
",0
"16th Int.
","['Int']
","[] 
",0
"Joint Conf.
","['Joint Conf']
","[] 
",0
"on Artificial Intelligence (IJCAI-99), Vol.
","['Artificial Intelligence', 'IJCAI-99', 'Vol']
","[] 
",0
"1: pp.
","['pp']
","[] 
",0
"600-605, 1999.
","[]
","[] 
",0
"[24] Yisehac Yohannes, John Hoddinott "" Classification and Regression Trees- An Introduction""  International Food Policy Research Institute, 1999.
","['] Yisehac Yohannes', 'John Hoddinott', 'Classification Regression Trees-', 'An Introduction', 'International Food Policy Research Institute']
","[] 
",0
"[25] Yisehac Yohannes, Patrick Webb "" Classification and Regression Trees"" International Food  Policy Research Institute, 1999.
","['] Yisehac Yohannes', 'Patrick Webb', 'Classification Regression Trees', 'International Food Policy Research Institute']
","[] 
",0
"A Very Brief Introduction to Machine Learning With Applications to Communication Systems
","['A Very', 'Brief Introduction Machine Learning', 'Applications Communication Systems']
","[] 
",0
"Osvaldo Simeone, Fellow, IEEE
","['Osvaldo Simeone', 'Fellow', 'IEEE']
","[] 
",0
"Abstract—Given the unprecedented availability of data and computing resources, there is widespread renewed interest in applying data-driven machine learning methods to problems for which the development of conventional engineering solutions is challenged by modelling or al- gorithmic deficiencies.
","['unprecedented availability data', 'resources', 'interest', 'data-driven machine', 'methods problems development', 'conventional engineering solutions', 'al- gorithmic deficiencies']
","['computing', 'renewed', 'applying', 'learning', 'challenged modelling'] 
",1
"This tutorial-style paper starts by addressing the questions of why and when such techniques can be useful.
","['This tutorial-style paper', 'questions techniques']
","['starts addressing'] 
",0
"It then provides a high-level introduction to the basics of supervised and unsupervised learning.
","['high-level introduction basics', 'unsupervised learning']
","['provides', 'supervised'] 
",1
"For both supervised and unsupervised learning, exemplifying applications to communication networks are discussed by distinguishing tasks carried out at the edge and at the cloud segments of the network at different layers of the protocol stack, with an emphasis on the physical layer.
","['unsupervised learning', 'applications communication networks', 'tasks', 'edge cloud segments network', 'different layers', 'stack', 'emphasis', 'physical layer']
","['supervised', 'exemplifying', 'discussed distinguishing', 'carried', 'protocol'] 
",1
"I.
","[]
","[] 
",0
"INTRODUCTION
","['INTRODUCTION']
","[] 
",0
"After the “AI winter” of the 80s and the 90s, interest in the application of data-driven Artificial Intelligence (AI) techniques has been steadily increasing in a number of engineering fields, including speech and image analysis [1] and communications [2].
","['“ AI winter', 'interest application', 'Artificial Intelligence', 'AI', 'techniques', 'number engineering fields', 'speech image analysis', '] communications', ']']
","['”', 'steadily increasing', 'including', '[', '['] 
",1
"Unlike the logic-based expert systems that were dominant in the earlier work on AI (see, e.g.-, [3]), the renewed confidence in data- driven methods is motivated by the successes of pattern recognition tools based on machine learning.
","['logic-based expert systems', 'work AI', ']', 'confidence', 'data- driven methods', 'successes', 'pattern recognition tools', 'machine learning']
","['see', 'renewed', 'motivated', 'based'] 
",1
"These tools rely on decades-old algorithms, such as backpropagation [4], the Expectation Maximization (EM) algorithm [5], and Q-learning [6], with a number of modern algorithmic advances, including novel regularization techniques and adaptive learning rate schedules (see review in [7]).
","['These tools', 'decades-old algorithms', 'backpropagation', ']', 'Expectation Maximization', 'EM', ']', 'Q-learning [', ']', 'number', 'modern algorithmic advances', 'novel regularization techniques', 'rate schedules', 'review', ']']
","['[', 'algorithm', 'including', 'adaptive learning', 'see'] 
",1
"Their success is built on the unprecedented availability of data and computing resources in many engineering domains.
","['success', 'unprecedented availability data', 'resources', 'many engineering domains']
","['built', 'computing'] 
",1
"While the new wave of promises and breakthroughs around machine learning arguably falls short, at least for now, of the requirements that drove early AI research [3], [8], learning algorithms have proven to be useful in a number of important applications – and more is certainly on the way.
","['promises', 'machine learning', 'requirements', 'early AI research', ']', ']', 'useful number', 'important applications', 'way']
","['wave', 'breakthroughs', 'arguably falls', 'drove', '[', '[', 'learning', '–'] 
",1
"King’s College London, United Kingdom (email: osvaldo.simeone@kcl.ac.uk).
","['’ College London', 'United Kingdom', 'email', 'osvaldo.simeone @ kcl.ac.uk']
","['King'] 
",0
"This work has received funding from the European Research Council (ERC) under the European Union Horizon 2020 research and innovation program (grant agreement 725731).
","['This work', 'funding European Research Council', 'ERC', 'European Union Horizon', 'research innovation program', 'grant agreement']
","['received'] 
",0
"This paper provides a very brief introduction to key concepts in machine learning and to the literature on machine learning for communication systems.
","['This paper', 'brief introduction', 'key concepts machine', 'literature machine', 'communication systems']
","['provides', 'learning', 'learning'] 
",1
"Unlike other review papers such as [9]–[11], the presentation aims at highlighting conditions under which the use of machine learning is justified in engineering problems, as well as specific classes of learning algorithms that are suitable for their solution.
","['review papers', '] – [', ']', 'presentation aims', 'conditions', 'machine learning', 'engineering problems', 'specific classes', 'algorithms', 'suitable solution']
","['[', 'highlighting', 'use', 'justified', 'learning'] 
",1
"The presentation is organized around the description of general technical concepts, for which an overview of applications to communication networks is subsequently provided.
","['The presentation', 'description', 'general technical concepts', 'overview applications communication networks']
","['organized', 'subsequently provided'] 
",1
"These applications are chosen to exemplify general design criteria and tools and not to offer a comprehensive review of the state of the art and of the historical progression of advances on the topic.
","['These applications', 'general design criteria tools', 'comprehensive review state', 'art historical progression advances topic']
","['chosen exemplify', 'offer'] 
",1
"We proceed in this section by addressing the question “What is machine learning?”, by providing a taxonomy of machine learning methods, and by finally considering the question “When to use machine learning?”.
","['section', 'question', 'machine', '”', 'taxonomy machine', 'methods', 'question “', 'use machine learning', '”']
","['proceed', 'addressing', '“', 'learning', 'providing', 'learning', 'finally considering'] 
",1
"A.
","[]
","[] 
",0
"What is Machine Learning?
","['Machine Learning']
","[] 
",0
"In order to fix the ideas, it is useful to introduce the machine learning methodology as an alternative to the conventional engineering approach for the design of an algorithmic solution.
","['order fix ideas', 'useful introduce machine', 'methodology', 'alternative conventional engineering approach design', 'algorithmic solution']
","['learning'] 
",0
"As illustrated in Fig.
","['illustrated Fig']
","[] 
",0
"1(a), the conventional engineering design flow starts with the ac- quisition of domain knowledge: The problem of interest is studied in detail, producing a mathematical model that capture the physics of the set-up under study.
","['conventional engineering design flow', 'ac- quisition domain knowledge', 'The problem interest', 'detail', 'mathematical model capture physics', 'set-up study']
","['starts', 'studied', 'producing'] 
",1
"Based on the model, an optimized algorithm is produced that offers performance guarantees under the assumption that the given physics-based model is an accurate representation of reality.
","['model', 'algorithm', 'offers performance guarantees assumption', 'physics-based model accurate representation reality']
","['Based', 'optimized', 'produced', 'given'] 
",1
"As an example, designing a decoding algorithm for a wireless fading channel under the conventional engi- neering approach would require the development, or the selection, of a physical model for the channel connecting transmitter and receiver.
","['example', 'algorithm wireless', 'channel conventional engi- neering approach', 'development', 'selection', 'physical model channel', 'transmitter receiver']
","['designing decoding', 'fading', 'require', 'connecting'] 
",1
"The solution would be obtained by tackling an optimization problem, and it would yield optimality guarantees under the given channel model.
","['The solution', 'optimization problem', 'optimality guarantees', 'channel model']
","['obtained tackling', 'yield', 'given'] 
",1
"Typical example of channel models include Gaussian and fading channels (see, e.g.-, [12]).
","['Typical example channel models', 'Gaussian fading channels', ']']
","['include', 'see'] 
",1
"1
","[]
","[] 
",0
"ar X
","['ar X']
","[] 
",0
"iv :1
","['iv :1']
","[] 
",0
"80 8.
","[]
","[] 
",0
"02 34
","[]
","[] 
",0
"2v 4
","[]
","[] 
",0
" [ cs
","['[ cs']
","[] 
",0
".I T
","['.I']
","['T'] 
",0
"]   5
","[]
","[] 
",0
" N ov
","['N ov']
","[] 
",0
" 2 01
","[]
","[] 
",0
"8
","[]
","[] 
",0
"acquisition
","['acquisition']
","[] 
",0
"of domain
","['domain']
","[] 
",0
"knowledge
","['knowledge']
","[] 
",0
"algorithm
","['algorithm']
","[] 
",0
"development
","['development']
","[] 
",0
"physics-based
","[]
","[] 
",0
"mathematical model
","['mathematical model']
","[] 
",0
"algorithm with
","['algorithm']
","[] 
",0
"performance
","['performance']
","[] 
",0
"guarantees
","['guarantees']
","[] 
",0
"acquisition
","['acquisition']
","[] 
",0
"of data
","['data']
","[] 
",0
"learning
","[]
","['learning'] 
",0
"training set
","['training set']
","[] 
",0
"black-box
","['black-box']
","[] 
",0
"machine
","['machine']
","[] 
",0
"hypothesis
","['hypothesis']
","[] 
",0
"class
","['class']
","[] 
",0
"(a)
","[]
","[] 
",0
"(b)
","['b']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"1.
","[]
","[] 
",0
"(a) Conventional engineering design flow; and (b) baseline machine learning methodology.
","['Conventional engineering design flow', 'b', 'baseline machine', 'methodology']
","['learning'] 
",0
"In contrast, in its most basic form, the machine learning approach substitutes the step of acquiring do- main knowledge with the potentially easier task of collecting a sufficiently large number of examples of desired behaviour for the algorithm of interest.
","['contrast', 'basic form', 'machine', 'approach substitutes', 'do- main knowledge', 'task', 'large number examples', 'behaviour algorithm interest']
","['learning', 'step acquiring', 'collecting', 'desired'] 
",1
"These examples constitute the training set.
","['These examples', 'training set']
","['constitute'] 
",0
"As seen in Fig.
","['Fig']
","['seen'] 
",0
"1(b), the examples in the training set are fed to a learning algorithm to produce a trained “machine” that carries out the desired task.
","['b', 'fed', 'algorithm produce', '“ machine ”', 'task']
","['examples training set', 'learning', 'trained', 'carries desired'] 
",1
"Learning is made possible by the choice of a set of possible “machines”, also known as the hypothesis class, from which the learning algorithm makes a selection during training.
","['possible choice', 'possible “ machines ”', 'hypothesis class', 'selection training']
","['Learning made', 'set', 'also known', 'learning', 'makes'] 
",1
"An example of an hypothesis class is given by a neural network architecture with learnable synaptic weights.
","['An example hypothesis class', 'neural network architecture', 'learnable synaptic weights']
","['given'] 
",0
"Learning algorithms are generally based on the optimization of a performance criterion that measures how well the selected “machine” matches the available data.
","['algorithms', 'optimization performance criterion measures', 'machine ” matches', 'available data']
","['Learning', 'generally based', 'well selected'] 
",1
"For the problem of designing a channel decoder, a machine learning approach can hence operate even in the absence of a well-established channel model.
","['problem', 'channel decoder', 'machine', 'approach hence', 'well-established channel model']
","['designing', 'learning', 'operate even absence'] 
",1
"It is in fact enough to have a sufficiently large number of examples of received signals – the inputs to the decoding machine – and transmitted messages – the desired outputs of the decoding machine – to be used for the training of a given class of decoding functions [13].
","['fact', 'large number examples', 'signals', 'inputs', 'machine –', 'messages', 'outputs', 'machine –', 'class', 'functions', ']']
","['received', '–', 'decoding', 'transmitted', '– desired', 'decoding', 'used training given', 'decoding'] 
",1
"acquisition
","['acquisition']
","[] 
",0
"of domain
","['domain']
","[] 
",0
"knowledge
","['knowledge']
","[] 
",0
"acquisition
","['acquisition']
","[] 
",0
"of data
","['data']
","[] 
",0
"learning
","[]
","['learning'] 
",0
"training set
","['training set']
","[] 
",0
" machine
","['machine']
","[] 
",0
"hypothesis
","['hypothesis']
","[] 
",0
"class
","['class']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"2.
","[]
","[] 
",0
"Machine learning methodology that integrates domain knowl- edge during model selection.
","['Machine', 'methodology integrates', 'knowl- edge model selection']
","['learning', 'domain'] 
",1
"Moving beyond the basic formulation described above, machine learning tools can integrate available domain knowledge in the learning process.
","['basic formulation', 'machine learning tools', 'available domain knowledge', 'process']
","['Moving', 'described', 'integrate', 'learning'] 
",1
"This is indeed the key to the success of machine learning tools in a number of applications.
","['key success machine learning tools number applications']
","[] 
",0
"A notable example is image processing, whereby knowledge of the translational invariance of vi- sual features is reflected in the adoption of convolutional neural networks as the hypothesis class to be trained.
","['A notable example image processing', 'translational invariance', 'vi- sual features', 'adoption convolutional neural networks hypothesis class']
","['knowledge', 'reflected', 'trained'] 
",1
"More generally, as illustrated in Fig.
","['Fig']
","['illustrated'] 
",0
"2, domain knowl- edge can dictate the choice of a specific hypothesis class for use in the training process.
","['knowl- edge dictate choice', 'specific hypothesis class use training process']
","['domain'] 
",0
"Examples of applications of this idea to communication systems, including to the problem of decoding, will be discussed later in the paper.
","['Examples applications idea communication systems', 'problem decoding', 'paper']
","['including', 'discussed'] 
",1
"B. Taxonomy of Machine Learning Methods
","['B. Taxonomy Machine Learning Methods']
","[] 
",0
"There are three main classes of machine learning techniques, as discussed next.
","['main classes machine', 'techniques']
","['learning', 'discussed'] 
",1
"• Supervised learning: In supervised learning, the
","['•', 'learning', 'supervised learning']
","['Supervised'] 
",0
"training set consists of pairs of input and desired output, and the goal is that of learning a mapping between input and output spaces.
","['training set', 'pairs input', 'output', 'goal', 'input output spaces']
","['consists', 'desired', 'learning mapping'] 
",1
"As an illustration, in Fig.
","['illustration', 'Fig']
","[] 
",0
"3(a), the inputs are points in the two- dimensional plane, the outputs are the labels as- signed to each input (circles or crosses), and the goal is to learn a binary classifier.
","['inputs points', 'two- dimensional plane', 'outputs labels', 'input', 'circles crosses', 'goal learn', 'binary classifier']
","['as- signed'] 
",0
"Applications include the channel decoder discussed above, as well as email spam classification on the basis of examples of spam/ non-spam emails.
","['Applications', 'channel decoder', 'email spam classification basis', 'non-spam emails']
","['include', 'discussed', 'examples'] 
",1
"• Unsupervised learning: In unsupervised learning, the training set consists of unlabelled inputs, that is, of inputs without any assigned desired output.
","['•', 'learning', 'unsupervised learning', 'set', 'unlabelled inputs', 'inputs', 'output']
","['Unsupervised', 'training', 'consists', 'assigned desired'] 
",1
"For instance, in Fig.
","['instance', 'Fig']
","[] 
",0
"3(b), the inputs are again points in the two-dimensional plane, but no indication is provided by the data about the corresponding de- sired output.
","['b', 'inputs points', 'two-dimensional plane', 'indication', 'data', 'de-', 'output']
","['provided', 'corresponding', 'sired'] 
",1
"Unsupervised learning generally aims at discovering properties of the mechanism gen- erating the data.
","['properties', 'gen- erating data']
","['Unsupervised learning', 'generally aims discovering', 'mechanism'] 
",1
"In the example of Fig.
","['example Fig']
","[] 
",0
"3(b), the goal of unsupervised learning is to cluster together
","['b', 'goal', 'cluster']
","['unsupervised learning'] 
",0
"2
","[]
","[] 
",0
"input points that are close to each other, hence assigning a label – the cluster index – to each input point (clusters are delimited by dashed lines).
","['input points', 'hence', 'label – cluster index – input point', 'clusters', 'dashed lines']
","['assigning', 'delimited'] 
",1
"Applications include clustering of documents with similar topics.
","['Applications', 'documents', 'similar topics']
","['include clustering'] 
",0
"It is emphasized that clustering is only one of the learning tasks that fall under the category of unsupervised learning (see Sec.
","['learning tasks', 'category', 'unsupervised learning', 'Sec']
","['emphasized clustering', 'fall', 'see'] 
",1
"V).
","['V']
","[] 
",0
"• Reinforcement learning: Reinforcement learning lies, in a sense, between supervised and unsuper- vised learning.
","['• Reinforcement learning', 'Reinforcement', 'lies', 'sense', 'unsuper- vised learning']
","['learning', 'supervised'] 
",1
"Unlike unsupervised learning, some form of supervision exists, but this does not come in the form of the specification of a desired output for every input in the data.
","['unsupervised learning', 'form supervision exists', 'form specification', 'output', 'every input data']
","['come', 'desired'] 
",1
"Instead, a reinforcement learning algorithm receives feedback from the envi- ronment only after selecting an output for a given input or observation.
","['algorithm receives', 'envi- ronment', 'output', 'input observation']
","['learning', 'feedback', 'selecting', 'given'] 
",1
"The feedback indicates the degree to which the output, known as action in re- inforcement learning, fulfils the goals of the learner.
","['The feedback', 'degree output', 'action', 're- inforcement learning', 'fulfils goals learner']
","['indicates', 'known'] 
",1
"Reinforcement learning applies to sequential deci- sion making problems in which the learner interacts with an environment by sequentially taking actions – the outputs – on the basis of its observations – its inputs – while receiving feedback regarding each selected action.
","['Reinforcement', 'applies', 'sequential deci- sion', 'problems', 'learner interacts environment', 'actions', 'outputs', '– basis observations', 'inputs', 'feedback', 'action']
","['learning', 'making', 'sequentially taking', '–', '–', '– receiving', 'regarding selected'] 
",1
"Most current machine learning applications fall in the supervised learning category, and hence aim at learning an existing pattern between inputs and outputs.
","['current machine learning applications', 'learning category', 'aim', 'pattern inputs outputs']
","['fall supervised', 'learning existing'] 
",1
"Supervised learning is relatively well-understood at a theoretical level [14], [15], and it benefits from well- established algorithmic tools.
","['well-understood theoretical level', ']', ']', 'benefits', 'algorithmic tools']
","['Supervised learning', '[', '[', 'well- established'] 
",1
"Unsupervised learning has so far defied a unified theoretical treatment [16].
","['unified theoretical treatment', ']']
","['Unsupervised learning', 'far defied', '['] 
",1
"Never- theless, it arguably poses a more fundamental practical problem in that it directly tackles the challenge of learn- ing by direct observation without any form of explicit feedback.
","['Never- theless', 'fundamental practical problem', 'direct observation', 'form explicit feedback']
","['arguably poses', 'directly tackles challenge', 'ing'] 
",1
"Reinforcement learning has found extensive applications in problems that are characterized by clear feedback signals, such as win/lose outcomes in games, and that entail searches over large trees of possible action-observation histories [17], [18].
","['Reinforcement', 'extensive applications problems', 'clear feedback signals', 'win/lose outcomes games', 'entail searches', 'large trees', 'possible action-observation histories', ']', ']']
","['learning found', 'characterized', '[', '['] 
",1
"This paper only covers supervised and unsupervised learning.
","['This paper', 'unsupervised learning']
","['covers supervised'] 
",0
"Reinforcement learning requires a different analytical framework grounded in Markov Decision Pro- cesses and will not be discussed here (see [17]).
","['Reinforcement', 'different analytical framework', 'Markov Decision Pro- cesses', ']']
","['learning requires', 'grounded', 'discussed', 'see'] 
",1
"For a broader discussion on the technical aspects of supervised and unsupervised learning, we point to [19] and refer- ences therein.
","['discussion', 'technical aspects', 'unsupervised learning', 'point', '] refer- ences']
","['supervised', '['] 
",1
"C. When to Use Machine Learning?
","['C.', 'Use Machine Learning']
","[] 
",0
"Based on the discussion in Sec.
","['discussion Sec']
","['Based'] 
",0
"I-A, the use of a
","['I-A', 'use']
","[] 
",0
"machine learning approach in lieu of a more conventional engineering design should be justified on a case-by- case basis on the basis of its suitability and potential
","['machine', 'approach', 'lieu conventional engineering design', 'case-by- case basis basis suitability potential']
","['learning', 'justified'] 
",1
"advantages.
","['advantages']
","[] 
",0
"The following criteria, inspired by [20], offer useful guidelines on the type of engineering tasks that can benefit from the use of machine learning tools.
","['The following criteria', ']', 'useful guidelines', 'engineering tasks', 'use machine learning tools']
","['inspired', 'offer', 'benefit'] 
",1
"1.
","[]
","[] 
",0
"The traditional engineering flow is not applicable or is undesirable due to a model deficit or to an algorithm deficit [21].
","['The traditional engineering flow', 'applicable undesirable due model deficit algorithm deficit', ']']
","['['] 
",0
"• With a model deficit, no physics-based mathematical models exist for the problem due to insufficient domain knowledge.
","['•', 'model deficit', 'physics-based mathematical models', 'problem', 'due insufficient domain knowledge']
","['exist'] 
",0
"As a result, a conventional model-based design is inapplicable.
","['result', 'conventional model-based design']
","[] 
",0
"• With an algorithm deficit, a well-established math- ematical model is available, but existing algorithms optimized on the basis of such model are too com- plex to be implemented for the given application.
","['•', 'algorithm deficit', 'well-established math- ematical model', 'algorithms', 'basis model', 'com- plex', 'application']
","['existing', 'optimized', 'implemented given'] 
",1
"In this case, the use of hypothesis classes including efficient “machines”, such as neural network of lim- ited size or with tailored hardware implementations (see, e.g.-, [22], [23] and references therein), can yield lower-complexity solutions.
","['case', 'hypothesis classes', 'efficient “ machines ”', 'neural network', 'lim- ited size', 'hardware implementations', ']', '] references', 'yield lower-complexity solutions']
","['use', 'including', 'tailored', 'see', '['] 
",1
"2.
","[]
","[] 
",0
"A sufficiently large training data sets exist or can be created.
","['data sets']
","['training', 'exist created'] 
",1
"3.
","[]
","[] 
",0
"The task does not require the application of logic, common sense, or explicit reasoning based on back- ground knowledge.
","['The task require application logic', 'common sense', 'back- ground knowledge']
","['explicit reasoning based'] 
",0
"4.
","[]
","[] 
",0
"The task does not require detailed explanations for how the decision was made.
","['The task require', 'detailed explanations decision']
","['made'] 
",0
"The trained machine is by and large a black box that maps inputs to outputs.
","['The trained machine', 'large black box maps', 'outputs']
","['inputs'] 
",0
"As such, it does not provide direct means to ascertain why a given output has been produced in response to an input, although recent research has made some progress on this front [24].
","['ascertain', 'output', 'response input', 'recent research', 'progress front', ']']
","['means', 'given', 'produced', 'made', '['] 
",1
"This contrasts with engineered optimal solutions, which can be typically interpreted on the basis of physical performance criteria.
","['optimal solutions', 'interpreted basis', 'physical performance criteria']
","['contrasts engineered'] 
",0
"For instance, a maximum likelihood decoder chooses a given output because it minimizes the probability of error under the assumed model.
","['instance', 'maximum likelihood decoder', 'output minimizes probability error', 'model']
","['chooses given', 'assumed'] 
",1
"5.
","[]
","[] 
",0
"The phenomenon or function being learned is station- ary for a sufficiently long period of time.
","['The phenomenon function', 'period time']
","['learned'] 
",0
"This is in order to enable data collection and learning.
","['This order', 'enable data collection learning']
","[] 
",0
"6.
","[]
","[] 
",0
"The task has either loose requirement constraints, or, in the case of an algorithm deficit, the required performance guarantees can be provided via numeri- cal simulations.
","['The task', 'loose requirement constraints', 'case algorithm deficit', 'performance guarantees', 'numeri- cal simulations']
","['required', 'provided'] 
",1
"With the conventional engineering ap- proach, theoretical performance guarantees can be ob- tained that are backed by a physics-based mathematical model.
","['conventional engineering', 'ap- proach', 'theoretical performance guarantees', 'backed physics-based mathematical model']
","['ob- tained'] 
",0
"These guarantees can be relied upon insofar as the model is trusted to be an accurate representation of reality.
","['These guarantees', 'insofar model', 'accurate representation reality']
","['relied', 'trusted'] 
",1
"If a machine learning approach is used to address an algorithm deficit and a physics-based model is available, then numerical results may be sufficient in order to compute satisfactory performance measures.
","['machine learning approach', 'address algorithm deficit', 'physics-based model', 'numerical results', 'order compute', 'satisfactory performance measures']
","['used', 'sufficient'] 
",1
"In
","[]
","[] 
",0
"3
","[]
","[] 
",0
"4 5 6 7 8 9 0
","[]
","[] 
",0
"1
","[]
","[] 
",0
"2
","[]
","[] 
",0
"3
","[]
","[] 
",0
"4
","[]
","[] 
",0
"5
","[]
","[] 
",0
"4 5 6 7 8 0
","[]
","[] 
",0
"1
","[]
","[] 
",0
"2
","[]
","[] 
",0
"3
","[]
","[] 
",0
"4
","[]
","[] 
",0
"5
","[]
","[] 
",0
"(a)
","[]
","[] 
",0
"(b)
","['b']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"3.
","[]
","[] 
",0
"Illustration of (a) supervised learning and (b) unsupervised learning.
","['Illustration', 'learning', 'b', 'learning']
","['supervised', 'unsupervised'] 
",1
"contrast, weaker guarantees can be offered by machine learning in the absence of a physics-based model.
","['contrast', 'guarantees', 'machine', 'absence physics-based model']
","['offered', 'learning'] 
",1
"In this case, one can provide performance bounds only under the assumptions that the hypothesis class is sufficiently general to include “machines” that can perform well on the problem and that the data is representative of the actual data distribution to be encountered at runtime (see, e.g.-, [19][Ch.
","['case', 'provide performance', 'assumptions hypothesis class', '“ machines', 'problem data', 'actual data distribution', 'runtime', '] [ Ch']
","['bounds', 'include', 'perform', 'representative', 'encountered', 'see'] 
",1
"5]).
","[']']
","[] 
",0
"The selection of a biased hypothesis class or the use of an unrepresentative data set may hence yield strongly suboptimal performance.
","['The selection', 'hypothesis class use', 'unrepresentative data set', 'yield', 'suboptimal performance']
","['biased', 'hence'] 
",1
"We will return to these criteria when discussing ap- plications to communication systems.
","['criteria', 'ap- plications communication systems']
","['return', 'discussing'] 
",1
"II.
","['II']
","[] 
",0
"MACHINE LEARNING FOR COMMUNICATION NETWORKS
","['MACHINE LEARNING FOR COMMUNICATION NETWORKS']
","[] 
",0
"In order to exemplify applications of supervised and unsupervised learning, we will offer annotated pointers to the literature on machine learning for communication systems.
","['order exemplify applications', 'unsupervised learning', 'offer', 'pointers', 'machine', 'communication systems']
","['supervised', 'annotated', 'literature', 'learning'] 
",1
"Rather than striving for a comprehensive, and historically minded, review, the applications and refer- ences have been selected with the goal of illustrating key aspects regarding the use of machine learning in engineering problems.
","['review', 'applications', 'refer- ences', 'goal', 'key aspects', 'use machine', 'engineering problems']
","['Rather striving', 'historically minded', 'selected', 'illustrating', 'regarding', 'learning'] 
",1
"Core
","['Core']
","[] 
",0
"Network
","['Network']
","[] 
",0
"Edge
","['Edge']
","[] 
",0
"Cloud
","['Cloud']
","[] 
",0
"Wireless
","['Wireless']
","[] 
",0
"Edge
","['Edge']
","[] 
",0
"Access
","['Access']
","[] 
",0
"Network
","['Network']
","[] 
",0
"Core
","['Core']
","[] 
",0
"Cloud
","['Cloud']
","[] 
",0
"Cloud
","['Cloud']
","[] 
",0
"Edge
","['Edge']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"4.
","[]
","[] 
",0
"A generic cellular wireless network architecture that dis- tinguishes between edge segment, with base stations, access points, and associated computing resources, and cloud segment, consisting of core network and associated cloud computing platforms.
","['A generic cellular wireless network architecture', 'dis- tinguishes', 'segment', 'base stations', 'access points', 'computing resources', 'cloud segment', 'core network', 'cloud', 'platforms']
","['edge', 'associated', 'consisting', 'associated', 'computing'] 
",1
"Throughout, we focus on tasks carried out at the network side, rather than at the users, and organize the applications along two axes.
","['Throughout', 'focus tasks', 'network side', 'users', 'applications', 'axes']
","['carried', 'organize'] 
",1
"On one, with reference to Fig.
","['reference Fig']
","[] 
",0
"4, we distinguish tasks that are carried out at the edge of the network, that is, at the base stations or access points and at the associated computing platforms, from tasks that are instead responsibility of a centralized cloud processor connected to the core network (see, e.g.-, [25]).
","['distinguish tasks', 'edge network', 'base stations access points', 'platforms', 'tasks', 'responsibility', 'centralized cloud processor', 'core network', ']']
","['carried', 'associated computing', 'connected', 'see'] 
",1
"The edge operates on the basis of timely local information collected at different layers of the protocol stack, which may include all layers from the physical up to the application layer.
","['The edge', 'basis', 'local information', 'different layers', 'stack', 'layers', 'physical application layer']
","['operates', 'collected', 'protocol', 'include'] 
",1
"In contrast, the centralized cloud processes longer-term and global information collected from multiple nodes in the edge network, which typically encompasses only the higher layers of the protocol stack, namely networking and application layers.
","['contrast', 'cloud', 'longer-term global information', 'multiple nodes edge network', 'layers', 'stack', 'application layers']
","['centralized', 'processes', 'collected', 'typically encompasses', 'protocol', 'namely networking'] 
",1
"Examples of data that may be available at the cloud and at the edge can be found in Table I and Table II, respectively.
","['Examples data', 'available cloud edge', 'Table', 'Table II']
","['found'] 
",0
"As a preliminary discussion, it is useful to ask which tasks of a communication network, if any, may benefit from machine learning through the lens of the criteria re- viewed in Sec.
","['preliminary discussion', 'useful ask tasks communication network', 'machine', 'lens criteria', 'Sec']
","['benefit', 'learning', 'viewed'] 
",1
"I-C. First, as seen, there should be either a model deficit or an algorithm deficit that prevents the use of a conventional model-based engineering design.
","['I-C. First', 'either model deficit algorithm deficit prevents', 'conventional model-based engineering design']
","['seen', 'use'] 
",1
"As an example of model deficit, proactive resource allocation that is based on predictions of human behaviour, e.g.-, for caching popular contents, may not benefit from well- established and reliable models, making a data-driven approach desirable (see, e.g.-, [26], [27]).
","['example model deficit', 'proactive resource allocation', 'predictions', 'human behaviour', 'popular contents', 'reliable models', 'data-driven approach', ']', ']']
","['based', 'caching', 'benefit', 'established', 'making', 'see', '['] 
",1
"For an instance of algorithm deficit, consider the problem of channel decoding for channels with known and accurate models based on which the maximum likelihood decoder entails an excessive complexity.
","['instance algorithm deficit', 'problem channel decoding channels', 'accurate models', 'maximum likelihood decoder', 'excessive complexity']
","['consider', 'known', 'based', 'entails'] 
",1
"Assuming that the problem at hand is characterized by model or algorithm deficits, one should then consider the rest of the criteria discussed in Sec.
","['problem hand', 'model algorithm deficits', 'consider rest criteria', 'Sec']
","['Assuming', 'characterized', 'discussed'] 
",1
"I-C.
","['I-C']
","[] 
",0
"Most are
","[]
","[] 
",0
"4
","[]
","[] 
",0
"TABLE I EXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT OF A COMMUNICATION NETWORK
","['TABLE', 'EXAMPLES OF DATA AVAILABLE AT THE EDGE SEGMENT', 'A COMMUNICATION NETWORK']
","[] 
",0
"Layer Data Physical Baseband signals, channel state information
","['Layer Data Physical Baseband signals', 'channel state information']
","[] 
",0
"Medium Access Control/ Link Throughput, FER, random access load and latency Network Location, traffic loads across services, users’ device types, battery levels
","['Medium Access Control/ Link Throughput', 'FER', 'random access load latency Network Location', 'traffic loads', 'services', 'users', 'device types', 'battery levels']
","['’'] 
",0
"Application Users’ preferences, content demands, computing loads, QoS metrics
","['Application Users', 'preferences', 'content demands', 'loads', 'QoS metrics']
","['’', 'computing'] 
",1
"TABLE II EXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT OF A COMMUNICATION NETWORK
","['TABLE II EXAMPLES OF DATA AVAILABLE AT THE CLOUD SEGMENT', 'A COMMUNICATION NETWORK']
","[] 
",0
"Layer Data Network Mobility patterns, network-wide traffic statistics, outage rates
","['Layer Data Network Mobility patterns', 'network-wide traffic statistics', 'outage rates']
","[] 
",0
"Application User’s behaviour patterns, subscription information, service usage statistics, TCP/IP traffic statistics
","['Application User ’ behaviour patterns', 'subscription information', 'service usage statistics', 'TCP/IP traffic statistics']
","[] 
",0
"typically satisfied by communication problems.
","['satisfied communication problems']
","[] 
",0
"Indeed, for most tasks in communication networks, it is possible to collect or generate training data sets and there is no need to apply common sense or to provide detailed explanations for how a decision was made.
","['tasks communication networks', 'possible collect generate training data sets', 'common sense provide', 'explanations decision']
","['need', 'detailed', 'made'] 
",1
"The remaining two criteria need to be checked on a case-by-case basis.
","['criteria', 'case-by-case basis']
","['remaining', 'need checked'] 
",1
"First, the phenomenon or function being learned should not change too rapidly over time.
","['phenomenon function', 'change', 'time']
","['learned'] 
",0
"For example, designing a channel decoder based on samples obtained from a limited number of realizations of a given propagation channel requires the channel is stationary over a sufficiently long period of time (see [28]).
","['example', 'channel decoder', 'samples', 'limited number realizations', 'propagation channel', 'channel', 'period time', ']']
","['designing', 'based', 'obtained', 'given', 'requires', 'see'] 
",1
"Second, in the case of a model deficit, the task should have some tolerance for error in the sense of not requir- ing provable performance guarantees.
","['Second', 'case model deficit', 'task tolerance error sense', 'requir- ing', 'provable performance guarantees']
","[] 
",0
"For instance, the performance of a decoder trained on a channel lacking a well-established channel model, such as a biological communication link, can only be relied upon insofar as one trusts the available data to be representative of the complete set of possible realizations of the problem under study.
","['instance', 'performance decoder', 'channel', 'well-established channel model', 'biological communication link', 'trusts', 'available data', 'possible realizations problem study']
","['trained', 'lacking', 'relied', 'set'] 
",1
"Alternatively, under an algorithm deficit, a physics-based model, if available, can be possibly used to carry out computer simulations and obtain numerical performance guarantees.
","['algorithm deficit', 'physics-based model', 'carry computer simulations', 'numerical performance guarantees']
","['possibly used', 'obtain'] 
",1
"In Sec.
","['Sec']
","[] 
",0
"IV and Sec.
","['IV Sec']
","[] 
",0
"VI, we will provide some pointers to specific applications to supervised and unsupervised learning, respectively.
","['VI', 'provide pointers', 'specific applications', 'unsupervised learning']
","['supervised'] 
",0
"III.
","['III']
","[] 
",0
"SUPERVISED LEARNING
","['SUPERVISED LEARNING']
","[] 
",0
"As introduced in Sec.
","['Sec']
","['introduced'] 
",0
"I, supervised learning aims at discovering patterns that relate inputs to outputs on the basis of a training set of input-output examples.
","['aims', 'patterns', 'inputs', 'outputs basis training', 'input-output examples']
","['supervised learning', 'discovering', 'relate', 'set'] 
",1
"We can distinguish two classes of supervised learning problems depending on whether the outputs are continuous or dis- crete variables.
","['classes', 'problems', 'outputs', 'continuous dis- crete variables']
","['distinguish', 'supervised learning', 'depending'] 
",1
"In the former case, we have a regression problem, while in the latter we have a classification
","['former case', 'regression problem', 'classification']
","[] 
",0
"0 0.2 0.4 0.6 0.8 1 -1.5
","['-1.5']
","[] 
",0
"-1
","['-1']
","[] 
",0
"-0.5
","['-0.5']
","[] 
",0
"0
","[]
","[] 
",0
"0.5
","[]
","[] 
",0
"1
","[]
","[] 
",0
"1.5
","[]
","[] 
",0
"?
","[]
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"5.
","[]
","[] 
",0
"Illustration of the supervised learning problem of regression: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x?
","['Illustration', 'problem regression', 'input-output training examples', 'xn', 'tn', 'n =', 'N', 'predict output', 'value input x']
","['supervised learning', 'Given', 'unobserved'] 
",1
"problem.
","['problem']
","[] 
",0
"We discuss the respective goals of the two problems next.
","['respective goals', 'problems']
","['discuss'] 
",0
"This is followed by a formal definition of classification and regression, and by a discussion of the methodology and of the main steps involved in tackling the two classes of problems.
","['formal definition classification regression', 'discussion methodology', 'main steps', 'classes problems']
","['followed', 'involved tackling'] 
",1
"A.
","[]
","[] 
",0
"Goals
","['Goals']
","[] 
",0
"As illustrated in Fig.
","['illustrated Fig']
","[] 
",0
"5, in a regression problem, we are given a training set D of N training points (xn, tn), with n = 1, ..., N , where the variables xn are the inputs, also known as covariates, domain points, or explanatory variables; while the variables tn are the outputs, also known as dependent variables, labels, or responses.
","['regression problem', 'training', 'D N training points', 'xn', 'tn', 'n =', 'N', 'xn inputs', 'covariates', 'domain points', 'explanatory variables', 'variables', 'outputs', 'dependent variables', 'labels', 'responses']
","['given', 'set', 'variables', 'also known', 'tn', 'also known'] 
",1
"In regression, the outputs are continuous variables.
","['regression', 'continuous variables']
","['outputs'] 
",0
"The problem is to predict the output t for a new, that is, as of yet unobserved, input x.
","['The problem predict output', 'x']
","['yet unobserved', 'input'] 
",1
"As illustrated in Fig.
","['illustrated Fig']
","[] 
",0
"6, classification is similarly defined with the only caveat that the outputs t are discrete
","['classification', 'caveat outputs']
","['similarly defined', 'discrete'] 
",1
"5
","[]
","[] 
",0
"4 5 6 7 8 9 0.5
","[]
","[] 
",0
"1
","[]
","[] 
",0
"1.5
","[]
","[] 
",0
"2
","[]
","[] 
",0
"2.5
","[]
","[] 
",0
"3
","[]
","[] 
",0
"3.5
","[]
","[] 
",0
"4
","[]
","[] 
",0
"4.5
","[]
","[] 
",0
"?
","[]
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"6.
","[]
","[] 
",0
"Illustration of the supervised learning problem of classi- fication: Given input-output training examples (xn, tn), with n = 1, ..., N , how should we predict the output t for an unobserved value of the input x?
","['Illustration', 'problem', 'classi- fication', 'input-output training examples', 'xn', 'tn', 'n =', 'N', 'predict output', 'value input x']
","['supervised learning', 'Given', 'unobserved'] 
",1
"variables that take a finite number of possible values.
","['variables', 'finite number', 'possible values']
","['take'] 
",0
"The value of the output t for a given input x indicates the class to which x belongs.
","['The value output', 'input x', 'class', 'x belongs']
","['given', 'indicates'] 
",1
"For instance, the label t is a binary variable as in Fig.
","['instance', 'label binary', 'variable Fig']
","[] 
",0
"6 for a binary classification problem.
","['binary classification problem']
","[] 
",0
"Based on the training set D, the goal is to predict the label, or the class, t for a new, as of yet unobserved, input x.
","['Based training', 'D', 'goal predict label', 'class', 'x']
","['set', 'yet unobserved', 'input'] 
",1
"To sum up, the goal of both regression and clas- sification is to derive from the training data set D a predictor t̂(x) that generalizes the input-output mapping in D to inputs x that are not present in D. As such, learning is markedly distinct from memorizing: while memorizing would require producing a value tn for some recorded input xn in the training set, learning is about generalization from the data set to the rest of the relevant input space.
","['goal regression', 'clas- sification', 'derive training data', 'D predictor t̂', 'x', 'input-output mapping D', 'x present D. As', 'distinct memorizing', 'memorizing', 'value tn', 'input', 'training set', 'generalization data', 'rest relevant', 'space']
","['sum', 'set', 'generalizes', 'inputs', 'learning', 'require producing', 'recorded', 'learning', 'set', 'input'] 
",1
"The problem of extrapolating a predictor from the training set is evidently impossible unless one is willing to make some assumption about the underlying input- output mapping.
","['The problem', 'predictor training', 'assumption', 'input- output mapping']
","['extrapolating', 'set', 'make', 'underlying'] 
",1
"In fact, the output t may well equal any value for an unobserved x if nothing else is specified about the problem.
","['fact', 'output', 'value', 'unobserved x nothing', 'problem']
","['well equal', 'else specified'] 
",1
"This impossibility is formalized by the no free-lunch theorem: without making assumptions about the relationship between input and output, it is not possible to generalize the available observations outside the training set [14].
","['This impossibility', 'free-lunch theorem', 'assumptions relationship input output', 'possible generalize', 'available observations', 'training', ']']
","['formalized', 'making', 'set'] 
",1
"The set of assumptions made in order to enable learning are known as inductive bias.
","['The set assumptions', 'order', 'inductive bias']
","['made', 'learning known'] 
",1
"As an example, for the regression problem in Fig.
","['example', 'regression problem Fig']
","[] 
",0
"5, a possible inductive bias is to postulate that the input- output mapping is a polynomial function of some order.
","['possible inductive bias', 'input- output', 'polynomial function order']
","['postulate', 'mapping'] 
",1
"B.
","['B']
","[] 
",0
"Defining Supervised Learning
","[]
","['Defining Supervised Learning'] 
",0
"Having introduced the goal of supervised learning, we now provide a more formal definition of the problem.
","['goal', 'learning', 'formal definition problem']
","['Having introduced', 'supervised', 'provide'] 
",1
"Throughout, we use Roman font to denote random variables and the corresponding letter in regular font for realizations.
","['Throughout', 'use Roman', 'denote random variables', 'letter', 'regular font realizations']
","['font', 'corresponding'] 
",1
"As a starting point, we assume that the training set D is generated as
","['point', 'D']
","['starting', 'assume training set', 'generated'] 
",1
"(xn, tn) ∼ i.i.d.
","['xn', 'tn', '∼ i.i.d']
","[] 
",0
"p(x, t), n = 1, ..., N, (1)
","['p', 'x', 'n =', 'N']
","[] 
",0
"that is, each training sample pair (xn, tn) is generated from the same true joint distribution p(x, t) and the sam- ple pairs are independent identically distributed (i.i.d.).
","['sample pair', 'tn', 'true joint distribution p', 'x', 'sam- ple pairs']
","['training', 'generated', 'identically distributed'] 
",1
"As discussed, based on the training set D, we wish to obtain a predictor t̂(x) that performs well on any possible relevant input x.
","['training', 'D', 'predictor t̂', 'x', 'possible relevant input x']
","['discussed', 'based', 'set', 'obtain', 'performs'] 
",1
"This requirement is formalized by imposing that the predictor is accurate for any test pair (x, t) ∼ p(x, t), which is generated independently of all the pairs in the training set D.
","['This requirement', 'predictor', 'accurate test pair', 'x', 'p', 'x', 'pairs training', 'D']
","['formalized imposing', 'generated', 'set'] 
",1
"The quality of the prediction t̂(x) for a test pair (x, t) is measured by a given loss function `(t, t̂) as `(t, t̂(x)).
","['The quality prediction t̂', 'x', 'test pair', 'x', 'loss function', 't̂', 't̂', 'x']
","['measured given'] 
",0
"Typical examples of loss functions include the quadratic loss `(t, t̂) = (t − t̂)2 for regression problems; and the error rate `(t, t̂) = 1(t 6= t̂), which equals 1 when the prediction is incorrect, i.e.-, t 6= t̂, and 0 otherwise, for classification problems.
","['Typical examples loss functions', 'quadratic loss', 't̂', '=', '− t̂', 'regression problems', 'rate', 't̂', 't̂', 'prediction incorrect', 't̂', 'classification problems']
","['include', 'error', '=', 'equals'] 
",1
"The formal goal of learning is that of minimizing the average loss on the test pair, which is referred to as the generalization loss.
","['The formal goal', 'minimizing average loss test pair', 'generalization loss']
","['learning', 'referred'] 
",1
"For a given predictor t̂, this is defined as
","['predictor t̂']
","['given', 'defined'] 
",1
"Lp(t̂) = E(x,t)∼p(x,t)[`(t, t̂(x))].
","['Lp', 't̂', '= E', 'x', '∼p', 'x', 't̂', 'x', ']']
","[] 
",0
"(2)
","[]
","[] 
",0
"The generalization loss (2) is averaged over the distribu- tion of the test pair (x, t).
","['The generalization loss', 'distribu- tion test pair', 'x']
","['averaged'] 
",0
"Before moving on to the solution of the problem of minimizing the generalization loss, we mention that the formulation provided here is only one, albeit arguably the most popular, of a number of alternative formula- tions of supervised learning.
","['solution problem', 'generalization loss', 'mention formulation', 'number', 'alternative formula- tions', 'learning']
","['moving', 'minimizing', 'provided', 'albeit', 'supervised'] 
",1
"The frequentist framework described above is in fact complemented by other view- points, including Bayesian and Minimum Description Length (MDL) (see [19] and references therein).
","['The frequentist framework', 'fact', 'view- points', 'Bayesian Minimum Description Length', 'MDL', '] references']
","['described', 'complemented', 'including', 'see'] 
",1
"C. When The True Distribution p(x, t) is Known: Infer- ence
","['C.', 'The True Distribution p', 'x', 'Infer- ence']
","['Known'] 
",0
"Consider first the case in which the true joint dis- tribution p(x, t) relating input and output is known.
","['first case', 'true joint dis- tribution p', 'x', 'input output']
","['Consider', 'relating', 'known'] 
",1
"This scenario can be considered as an idealization of the situation resulting from the conventional engineering design flow when the available physics-based model is accurate (see Sec.
","['This scenario', 'idealization situation', 'conventional engineering design flow', 'available physics-based model accurate', 'Sec']
","['considered', 'resulting', 'see'] 
",1
"I).
","[]
","[] 
",0
"Under this assumption, the data set
","['assumption', 'data']
","['set'] 
",0
"6
","[]
","[] 
",0
"D is not necessary, since the mapping between input and output is fully described by the distribution p(x, t).
","['D', 'input output', 'distribution p', 'x']
","['mapping', 'fully described'] 
",1
"If the true distribution p(x, t) is known, the problem of minimizing the generalization loss reduces to a stan- dard inference problem, i.e.-, an estimation problem in a regression set-up, in which the outputs are continuous variables, or a detection problem in a classification set- up, in which the outputs are finite discrete variables.
","['true distribution p', 'x', 'problem', 'generalization loss', 'stan- dard inference problem', 'estimation problem regression set-up', 'continuous variables', 'detection problem classification set-', 'finite discrete variables']
","['known', 'minimizing', 'reduces', 'outputs', 'outputs'] 
",1
"In an inference problem, the optimal predictor t̂ can be directly computed from the posterior distribution
","['inference problem', 'optimal predictor t̂', 'posterior distribution']
","['directly computed'] 
",0
"p(t|x) = p(x, t)
","['p', 't|x', '= p', 'x']
","[] 
",0
"p(x) , (3)
","['p', 'x']
","[] 
",0
"where p(x) is the marginal distribution of the input x.
","['p', 'x', 'marginal distribution input x']
","[] 
",0
"The latter can be computed from the joint distribution p(x, t) by summing or integrating out all the values of t. In fact, given a loss function `(t, t̂), the optimal predictor for any input x is obtained as
","['joint distribution p', 'x', 'values', 'fact', 'loss function', 't̂', 'optimal predictor input x']
","['computed', 'summing integrating', 't.', 'given', 'obtained'] 
",1
"t̂∗(x) = argmin t̂
","['t̂∗', 'x', 'argmin t̂']
","['='] 
",0
"Et∼p(t|x)[`(t, t̂)|x].
","['Et∼p', 't|x', '[', 't̂', '|x ]']
","[] 
",0
"(4)
","[]
","[] 
",0
"In words, the optimal predictor t̂∗(x) is obtained by identifying the value (or values) of t that minimizes the average loss, where the average is taken with respect to the posterior distribution p(t|x) of the output given the input.
","['words', 'optimal predictor t̂∗', 'x', 'value', 'values', 'average loss', 'respect', 'posterior distribution p', 't|x', 'output', 'input']
","['obtained identifying', 'minimizes', 'taken', 'given'] 
",1
"Given that the posterior p(t|x) yields the optimal predictor, it is also known as the true predictive distribution.
","['posterior p', 't|x', 'optimal predictor', 'true predictive distribution']
","['Given', 'yields', 'also known'] 
",1
"The optimal predictor (4) can be explicitly evaluated for given loss functions.
","['The optimal predictor', 'loss functions']
","['explicitly evaluated given'] 
",0
"For instance, for the quadratic loss, which is typical for regression, the optimal predictor is given by the mean of the predictive distribution, or the posterior mean, i.e.-,
","['instance', 'quadratic loss', 'typical regression', 'optimal predictor', 'mean predictive distribution', 'posterior mean', 'i.e.-']
","['given'] 
",0
"t̂∗(x) = Et∼p(t|x)[t|x], (5)
","['t̂∗', 'x', 'Et∼p', 't|x', 't|x ]']
","['=', '['] 
",1
"while, with the error rate loss, which is typical for classification, problems, the optimal predictor is given by the maximum of the predictive distribution, or the maximum a posteriori (MAP) estimate, i.e.-,
","['error rate loss', 'typical classification', 'problems', 'optimal predictor', 'maximum predictive distribution', 'maximum posteriori', 'MAP', 'estimate', 'i.e.-']
","['given'] 
",0
"t̂∗(x) = argmax t p(t|x).
","['t̂∗', 'x', 'argmax p', 't|x']
","['='] 
",0
"(6)
","[]
","[] 
",0
"For a numerical example, consider binary inputs and outputs and the joint distribution p(x, t) such that p(0, 0) = 0.05, p(0, 1) = 0.45, p(1, 0) = 0.4 and p(1, 1) = 0.1.
","['numerical example', 'binary inputs outputs', 'joint distribution p', 'x', 'p', '=', 'p', '=', 'p', 'p', '=']
","['consider', '='] 
",1
"The predictive distribution for input x = 0 is then given as p(t = 1|x = 0) = 0.9, and hence we have the optimal predictor given by the average t̂∗(x = 0) = 0.9 × 1 + 0.1 × 0 = 0.9 for the quadratic loss, and by the MAP solution t̂∗(x = 0) = 1 for the error rate loss.
","['The predictive distribution input x', 'p', '=', 'optimal predictor', 'average t̂∗', 'x =', 'quadratic loss', 'MAP solution t̂∗', 'x =', 'error rate loss']
","['=', 'given', 'given', '=', '='] 
",1
"D. When the True Distribution p(x, t) is Not Known: Machine Learning
","['D.', 'True Distribution p', 'x', 'Machine']
","['Not Known', 'Learning'] 
",1
"Consider now the case of interest in which domain knowledge is not available and hence the true joint distribution is unknown.
","['case interest domain knowledge', 'available hence', 'true joint distribution unknown']
","['Consider'] 
",0
"In such a scenario, we have a learning problem and we need to use the examples in the training set D in order to obtain a meaningful predictor that approximately minimizes the generalization loss.
","['scenario', 'problem need use', 'D order', 'meaningful predictor', 'minimizes generalization loss']
","['learning', 'examples training set', 'obtain'] 
",1
"At a high level, the methodology applied by machine learning follows three main steps, which are described next.
","['high level', 'methodology', 'machine learning', 'main steps']
","['applied', 'follows', 'described'] 
",1
"1.
","[]
","[] 
",0
"Model selection (inductive bias): As a first step, one needs to commit to a specific class of hypotheses that the learning algorithm may choose from.
","['Model selection', 'inductive bias', 'first step', 'commit', 'specific class hypotheses', 'algorithm']
","['needs', 'learning', 'choose'] 
",1
"The hypothesis class is also referred to as model.
","['The hypothesis class', 'model']
","['also referred'] 
",0
"The selection of the hy- pothesis class characterizes the inductive bias mentioned above as a pre-requisite for learning.
","['The selection', 'hy- pothesis class', 'inductive bias', 'pre-requisite learning']
","['characterizes', 'mentioned'] 
",1
"In a probabilistic framework, the hypothesis class, or model, is defined by a family of probability distributions parameterized by a vector θ.
","['probabilistic framework', 'hypothesis class', 'model', 'family probability distributions', 'vector θ']
","['defined', 'parameterized'] 
",1
"Specifically, there are two main ways of specifying a parametric family of distributions as a model for supervised learning: • Generative model: Generative models specify a
","['main ways', 'parametric family distributions model', 'learning', '• Generative model', 'Generative models']
","['specifying', 'supervised', 'specify'] 
",1
"family of joint distributions p(x, t|θ); • Discriminative model: Discriminative models pa-
","['family', 'joint distributions', 'Discriminative model', 'Discriminative models pa-']
","['p'] 
",0
"rameterize directly the predictive distribution as p(t|x, θ).
","['predictive distribution p', 't|x', 'θ']
","['rameterize'] 
",0
"Broadly speaking, discriminative models do not make any assumptions about the distribution of the inputs x and hence may be less prone to bias caused by a misspecification of the hypothesis class.
","['speaking', 'discriminative models', 'assumptions distribution inputs', 'hence', 'prone bias', 'misspecification hypothesis class']
","['make', 'x', 'less', 'caused'] 
",1
"On the flip side, generative models may be able to capture more of the structure present in the data and consequently improve the performance of the predictor [29].
","['flip side', 'generative models', 'able capture structure', 'present data', 'performance predictor', ']']
","['consequently improve', '['] 
",1
"For both types of models, the hypothesis class is typically selected from a common set of probability distributions that lead to efficient learning algorithms in Step 2.
","['types models', 'hypothesis class', 'probability distributions', 'algorithms Step']
","['typically selected', 'set', 'lead', 'learning'] 
",1
"Furthermore, any available basic domain knowledge can be in principle incorporated in the selection of the model (see also Sec.
","['available basic domain knowledge principle', 'selection model', 'Sec']
","['incorporated', 'see'] 
",1
"VII).
","['VII']
","[] 
",0
"2.
","[]
","[] 
",0
"Learning: Given data D, in the learning step, a learning criterion is optimized in order to obtain the parameter vector θ and identify a distribution p(x, t|θ) or p(t|x, θ), depending on whether a generative or dis- criminative model was selected at Step 1.
","['data D', 'step', 'criterion', 'order', 'parameter vector θ', 'distribution p', 'p', 't|x', 'θ', 'generative dis- criminative model', 'Step']
","['Learning', 'Given', 'learning', 'learning', 'optimized', 'obtain', 'identify', 'depending', 'selected'] 
",1
"3.
","[]
","[] 
",0
"Inference: In the inference step, the learned model is used to obtain the predictor t̂(x) by using (4) with the learned model in lieu of the true distribution.
","['Inference', 'inference step', 'model', 'predictor t̂', 'x', 'model lieu', 'true distribution']
","['learned', 'used obtain', 'using', 'learned'] 
",1
"Note that generative models require the calculation of the predictive distribution p(t|x) via marginalization, while discriminative models provide directly the predictive
","['Note', 'generative models', 'calculation', 'predictive distribution p', 't|x', 'marginalization', 'discriminative models']
","['require', 'provide'] 
",1
"7
","[]
","[] 
",0
"distribution.
","['distribution']
","[] 
",0
"As mentioned, the predictor should be eval- uated on test data that is different from the training set D. As we will discuss, the design cycle typically entails a loop between validation of the predictor at Step 3 and model selection at Step 1.
","['predictor eval- uated test data', 'different training', 'D.', 'discuss', 'design cycle', 'loop validation predictor Step', 'model selection Step']
","['mentioned', 'set', 'typically entails'] 
",1
"The next examples illustrate the three steps introduced above for a binary classification problem.
","['The next examples', 'steps', 'binary classification problem']
","['illustrate', 'introduced'] 
",1
"Example 1: Consider a binary classification problem in which the input is a generic D-dimensional vector x = [x1, ..., xD]
","['binary classification problem input', 'generic D-dimensional vector x = [ x1', ']']
","['Consider'] 
",0
"T and the output is binary, i.e.-, t ∈ {0, 1}.
","['T output binary', '∈']
","[] 
",0
"The superscript “T ” represents transposition.
","['The superscript “ T ”', 'transposition']
","['represents'] 
",0
"In Step 1, we select a model, that is, a parameterized family of distributions.
","['Step', 'select model', 'family distributions']
","['parameterized'] 
",0
"A common choice is given by logistic regression1, which is a discriminative model whereby the predictive distribution p(t|x, θ) is parameterized as illustrated in Fig.
","['A common choice', 'logistic regression1', 'discriminative model', 'predictive distribution p', 't|x', 'θ', 'illustrated Fig']
","['given', 'parameterized'] 
",1
"7.
","[]
","[] 
",0
"The model first computes D′ fixed features φ(x) = [φ1(x) · · ·φD′(x)]T of the input, where a feature is a function of the data.
","['The model', 'D′', 'fixed features', 'x', '[ φ1', 'x', '· ·φD′', 'x', 'T input', 'feature function data']
","['first computes', 'φ', '=', '·', ']'] 
",1
"Then, it computes the predictive probability as
","['computes', 'probability']
","['predictive'] 
",0
"p(t = 1|x,w) = σ(wTφ(x)), (7)
","['p', 'w', '= σ', 'wTφ', 'x']
","[] 
",0
"where w is the set of learnable weights – i.e.-, the pa- rameter θ defined above – and σ(a) = (1+exp(−a))−1 is the sigmoid function.
","['w', 'learnable weights', 'i.e.-', 'pa- rameter θ', '– σ', '=', '−a', 'sigmoid function']
","['set', 'defined', '−1'] 
",1
"Under logistic regression, the probability that the label is t = 1 increases as the linear combination of features becomes more positive, and we have p(t = 1|x,w) > 0.5 for wTφ(x) > 0.
","['logistic regression', 'probability label', 'increases', 'linear combination features', 'p', 'w', 'wTφ', 'x']
","['=', 'becomes', '>', '>'] 
",1
"Conversely, the probability that the label is t = 0 increases as the linear combination of features becomes more negative, with p(t = 0|x,w) > 0.5 for wTφ(x) < 0.
","['probability label', 'increases', 'linear combination features', 'p', 'w', 'wTφ', 'x']
","['=', 'becomes', '>', '<'] 
",1
"As a specific instance of this problem, if we wish to classify emails between spam and non-spam ones, possible useful features may count the number of times that certain suspicious words appear in the text.
","['specific instance problem', 'wish classify emails', 'non-spam ones', 'possible useful features', 'number times', 'certain suspicious words', 'text']
","['spam', 'count', 'appear'] 
",1
"Step 2 amounts to the identification of the weight vector w on the basis of the training set D with the ideal goal of minimizing the generalization loss (2).
","['Step', 'amounts identification weight vector', 'w basis training', 'D', 'ideal goal', 'generalization loss']
","['set', 'minimizing'] 
",1
"This step will be further discussed in the next subsection.
","['This step', 'next subsection']
","['discussed'] 
",0
"Finally, in Step 3, the optimal predictor is obtained by assuming that the learned model p(t|x,w) is the true predictive distribution.
","['Step', 'optimal predictor', 'model p', 't|x', 'w', 'true predictive distribution']
","['obtained assuming learned'] 
",0
"Assuming an error rate loss function, following the discussion in Sec.
","['error rate loss function', 'discussion Sec']
","['Assuming', 'following'] 
",1
"III-C, the optimal predictor is given by the MAP choice t̂∗(x) = 1 if wTφ(x) > 0 and t̂∗(x) = 0 otherwise.
","['III-C', 'optimal predictor', 'MAP choice t̂∗', 'x', 'wTφ', 'x', 't̂∗', 'x']
","['given', '=', '>', '='] 
",1
"It is noted that the linear combination wTφ(x) is also known as logit or log-likelihood ratio (LLR).
","['linear combination wTφ', 'x', 'logit log-likelihood ratio', 'LLR']
","['noted', 'also known'] 
",1
"This rule can be seen to correspond to a linear classifier [19].
","['This rule', 'correspond', 'linear classifier', ']']
","['seen'] 
",0
"The performance
","['The performance']
","[] 
",0
"1The term ”regression” may be confusing, since the model applies to classification.
","['term ” regression ”', 'model applies classification']
","['confusing'] 
",0
"Fig.
","['Fig']
","[] 
",0
"7.
","[]
","[] 
",0
"An illustration of the hypothesis class p(t|x,w) assumed by logistic regression using a neural network representation: functions φi, with i = 1, ..., D′, are fixed and compute features of the input vector x = [x1, ..., xD].
","['An illustration hypothesis class p', 't|x', 'w', 'logistic regression', 'neural network representation', 'functions', 'D′', 'compute features', 'vector x = [ x1', 'xD ]']
","['assumed', 'using', 'φi', 'fixed', 'input'] 
",1
"The learnable parameter vector θ here corresponds to the weights w used to linearly combine the features in (7).
","['The learnable parameter vector θ', 'weights w', 'combine features']
","['corresponds', 'used'] 
",1
"of the predictor should be tested on new, test, input- output pairs, e.g.-, new emails in the spam classification example.
","['predictor', 'test', 'input- output pairs', 'new emails', 'spam classification example']
","['tested'] 
",0
"�
","['�']
","[] 
",0
"Example 2: Logistic regression requires to specify a suitable vector of features φ(x).
","['Logistic regression', 'specify suitable vector features', 'x']
","['requires', 'φ'] 
",1
"As seen in the email spam classification example, this entails the availability of some domain knowledge to be able to ascertain which functions of the input x may be more relevant for the classification task at hand.
","['email spam classification example', 'availability domain knowledge', 'able ascertain functions', 'x', 'classification task hand']
","['seen', 'entails', 'input', 'relevant'] 
",1
"As discussed in Sec.
","['Sec']
","['discussed'] 
",0
"I, this knowledge may not be available due to, e.g.-, cost or time constraints.
","['knowledge', 'cost time constraints']
","[] 
",0
"Multi-layer neural networks provide an alternative model choice at Step 1 that obviates the need for hand-crafted features.
","['Multi-layer', 'neural networks', 'alternative model choice Step', 'obviates', 'hand-crafted features']
","['provide', 'need'] 
",1
"The model is illustrated in Fig.
","['The model', 'Fig']
","['illustrated'] 
",0
"8.
","[]
","[] 
",0
"Unlike linear regression, in a multi-layer neural network, the feature vector φ(x) used by the last layer to compute the logit, or LLR, that determines the predictive probability (7) is not fixed a priori.
","['linear regression', 'multi-layer neural network', 'feature vector φ', 'x', 'last layer compute logit', 'LLR', 'predictive probability', 'priori']
","['used', 'determines', 'fixed'] 
",1
"Rather, the feature vector is computed by the previous layers.
","['feature vector', 'previous layers']
","['computed'] 
",0
"To this end, each neuron, represented as a circle in Fig.
","['circle Fig']
","['end', 'represented'] 
",1
"8, computes a fixed non-linear function, e.g.-, sigmoid, of a linear combination of the values obtained from the previous layer.
","['computes', 'non-linear function', 'linear combination values', 'previous layer']
","['fixed', 'obtained'] 
",1
"The weights of these linear combinations are part of the learnable parameters θ, along with the weights of the last layer.
","['The weights', 'combinations part', 'learnable parameters', 'weights', 'last layer']
","['linear', 'θ'] 
",1
"By allowing the weights at all layers of the model to be trained simultaneously, multi-layer neural networks enable the joint learning of the last-layer linear classifier and of the features φ(x) the classifier operates on.
","['weights layers', 'multi-layer neural networks', 'last-layer linear classifier features', 'x']
","['allowing', 'model trained', 'learning', 'φ', 'operates'] 
",1
"As a notable example, deep neural networks are characterized by a large number of intermediate layers that tend to learn increasingly abstract features of the input [7].
","['notable example', 'deep neural networks', 'large number', 'intermediate layers', 'abstract features', ']']
","['characterized', 'tend', 'input'] 
",1
"�
","['�']
","[] 
",0
"In the rest of this section, we first provide some technical details about Step 2, i.e.-, learning, and then we return to Step 1, i.e.-, model selection.
","['rest section', 'technical details Step', 'i.e.-', 'learning', 'Step', 'model selection']
","['provide', 'return'] 
",1
"As it will be seen, this order is dictated by the fact that model selection requires some understanding of the learning process.
","['order', 'fact model selection', 'process']
","['seen', 'dictated', 'requires understanding learning'] 
",1
"8
","[]
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"8.
","[]
","[] 
",0
"An illustration of the hypothesis class p(t|x,w) assumed by multi-layer neural networks.
","['An illustration hypothesis class p', 't|x', 'w', 'multi-layer neural networks']
","['assumed'] 
",0
"The learnable parameter vector θ here corresponds to the weights wL used at the last layer to linearly combine the features φ(x) and the weight matrices W 1, ...,WL−1
","['The learnable parameter vector θ', 'weights wL', 'combine features', 'x', 'matrices W', 'WL−1']
","['corresponds', 'used', 'φ', 'weight'] 
",1
"used at the preceding layers in order to compute the feature vector.
","['layers order compute feature vector']
","['used preceding'] 
",0
"E. Learning
","['E. Learning']
","[] 
",0
"Ideally, a learning rule should obtain a predictor that minimizes the generalization error (2).
","['rule', 'predictor', 'minimizes generalization error']
","['learning', 'obtain'] 
",1
"However, as discussed in Sec.
","['Sec']
","['discussed'] 
",0
"III-C, this task is out of reach without knowledge of the true joint distribution p(x, t).
","['III-C', 'task reach', 'knowledge', 'true joint distribution p', 'x']
","[] 
",0
"There- fore, alternative learning criteria need to be considered that rely on the training set D rather than on the true distribution.
","['There- fore', 'alternative learning criteria', 'D', 'true distribution']
","['need considered', 'rely training set'] 
",1
"In the context of probabilistic models, the most basic learning criterion is Maximum Likelihood (ML).
","['context probabilistic models', 'criterion Maximum Likelihood', 'ML']
","['learning'] 
",0
"ML selects a value of θ in the parameterized family of models p(x, t|θ) or p(t|x, θ) that is the most likely to have generated the observed training set D. Mathematically, ML solves the problem of maximizing the log-likelihood function
","['ML', 'value θ', 'family models', 'p', 't|x', 'θ', 'observed training', 'D. Mathematically', 'ML', 'problem', 'log-likelihood function']
","['selects', 'parameterized', 'p', 'likely generated', 'set', 'solves', 'maximizing'] 
",1
"maximize ln p(D|θ) (8)
","['ln p', 'D|θ']
","['maximize'] 
",0
"over θ, where p(D|θ) is the probability of the data set D for a given value of θ.
","['θ', 'p', 'D|θ', 'probability data', 'D', 'value θ']
","['set', 'given'] 
",1
"Given the assumption of i.i.d.
","['assumption i.i.d']
","['Given'] 
",0
"data points in D (see Sec.
","['data points D', 'Sec']
","['see'] 
",0
"III-B), the log-likelihood can be written as
","['III-B']
","['written'] 
",0
"ln p(D|θ) = N∑ n=1
","['ln p', 'D|θ', 'N∑ n=1']
","['='] 
",0
"ln p(tn|xn, θ), (9)
","['ln p', 'tn|xn', 'θ']
","[] 
",0
"where we have used as an example the case of discrim- inative models.
","['example case', 'discrim- inative models']
","['used'] 
",0
"Note that most learning criteria used in practice can be interpreted as ML problems, including the least squares criterion – ML for Gaussian models – and cross-entropy – ML for categorical models.
","['Note', 'criteria', 'practice', 'ML problems', 'squares', '– ML Gaussian models', 'cross-entropy – ML', 'categorical models']
","['learning', 'used', 'interpreted', 'including', 'criterion', '–'] 
",1
"The ML problem (8) rarely has analytical solutions and is typically addressed by Stochastic Gradient De- scent (SGD).
","['The ML problem', 'analytical solutions', 'Stochastic Gradient De- scent', 'SGD']
","['typically addressed'] 
",0
"Accordingly, at each iteration, subsets of examples, also known as mini-batches, are selected from the training set, and the parameter vector is updated in the direction of gradient of the log-likelihood function as evaluated on these examples.
","['iteration', 'subsets examples', 'mini-batches', 'training set', 'parameter vector', 'updated direction gradient', 'log-likelihood function', 'examples']
","['also known', 'selected', 'evaluated'] 
",1
"The resulting learning rule can be written as
","['learning rule']
","['resulting', 'written'] 
",1
"θnew ← θold + γ∇θ ln p(tn|xn, θ)|θ=θold , (10)
","['θnew ← θold + γ∇θ ln p', 'tn|xn', 'θ', '|θ=θold']
","[] 
",0
"where we have defined as γ > 0 the learning rate, and, for simplicity of notation, we have considered a mini- batch given by a single example (xn, tn).
","['rate', 'simplicity notation', 'mini- batch', 'single example', 'tn']
","['defined', 'learning', 'considered', 'given'] 
",1
"It is noted that, with multi-layer neural networks, the computation of the gradient ∇θ ln p(tn|xn, θ) yields the standard backpropagation algorithm [7], [19].
","['multi-layer neural networks', 'computation gradient ∇θ ln p', 'tn|xn', 'θ', 'standard backpropagation algorithm', ']', ']']
","['noted', 'yields', '[', '['] 
",1
"The learning rate is an example of hyperparameters that define the learning algorithm.
","['The learning rate example hyperparameters', 'algorithm']
","['define learning'] 
",0
"Many variations of SGD have been proposed that aim at improving convergence (see, e.g.-, [7], [19]).
","['Many variations', 'aim', 'convergence', ']', ']']
","['SGD proposed', 'improving', 'see', '['] 
",1
"ML has evident drawbacks as an indirect means of minimizing the generalization error.
","['ML', 'evident drawbacks', 'generalization error']
","['indirect means minimizing'] 
",0
"In fact, ML only considers the fit of the probabilistic model on the training set without any consideration for the performance on unobserved input-output pairs.
","['fact', 'ML', 'fit probabilistic model training', 'consideration performance', 'input-output pairs']
","['considers', 'set', 'unobserved'] 
",1
"This weakness can be somewhat mitigated by regularization [7], [19] during learning and by a proper selection of the model via validation, as discussed in the next subsection.
","['This weakness', 'regularization [', ']', ']', 'proper selection model', 'validation', 'next subsection']
","['somewhat mitigated', '[', 'learning', 'discussed'] 
",1
"Regu- larization adds a penalty term to the log-likelihood that depends on the model parameters θ.
","['Regu- larization', 'penalty term', 'model parameters']
","['adds', 'depends', 'θ'] 
",1
"The goal is to prevent the learned model parameters θ to assume values that are a priori too unlikely and that are hence possible symptoms of overfitting.
","['The goal prevent', 'model parameters', 'assume values', 'unlikely hence', 'possible symptoms']
","['learned', 'θ', 'priori', 'overfitting'] 
",1
"As an example, for logistic regression, one can add a penalty that is proportional to the norm ||w||2 of the weight vector w in order to prevent the weights to assume excessively high values when fitting the data in the learning step.
","['example', 'logistic regression', 'add penalty', 'proportional norm ||w||2', 'vector w order prevent weights', 'high values', 'data', 'step']
","['weight', 'assume', 'fitting', 'learning'] 
",1
"F. Model Selection
","['F. Model Selection']
","[] 
",0
"We now discuss the first, key, step of model selection, which defines the inductive bias adopted in the learning process.
","['key', 'model selection', 'defines', 'bias', 'learning process']
","['discuss', 'step', 'inductive', 'adopted'] 
",1
"In order to illustrate the main ideas, here we study a particular aspect of model selection, namely that of model order selection.
","['order illustrate', 'main ideas', 'study', 'particular aspect model selection', 'model order selection']
","[] 
",0
"To this end, we consider a hierarchical set of models of increasing complexity and we address the problem of selecting (in Step 1) the order, or the complexity, of the specific model to be posited for learning (in Step 2).
","['hierarchical set models', 'complexity address problem selecting', 'Step', 'order', 'complexity', 'specific model', 'learning', 'Step']
","['end', 'consider', 'increasing', 'posited'] 
",1
"As an example of model order selection, one may fix a set of models including multi- layer networks of varying number of intermediate layers and focus on determining the number of layers.
","['example model order selection', 'set models', 'multi- layer networks', 'number', 'intermediate layers', 'number layers']
","['fix', 'including', 'varying', 'focus determining'] 
",1
"It is emphasized that the scope of model selection goes much beyond model order selection, including the possible incorporation of domain knowledge and the tuning of the hyperparameters of the learning algorithm.
","['scope model selection', 'model order selection', 'possible incorporation domain knowledge', 'hyperparameters', 'algorithm']
","['emphasized', 'goes', 'including', 'tuning', 'learning'] 
",1
"For concreteness, we focus on the regression problem illustrated in Fig.
","['concreteness', 'regression problem', 'Fig']
","['focus', 'illustrated'] 
",1
"5 and assume a set of discriminative models p(t|x,w) under which the output t is distributed as
","['discriminative models', 't|x', 'w', 'output']
","['set', 'p', 'distributed'] 
",1
"M∑ m=0
","['M∑ m=0']
","[] 
",0
"wmx m +N (0, 1).
","['wmx +N']
","[] 
",0
"(11)
","[]
","[] 
",0
"9
","[]
","[] 
",0
"0 0.2 0.4 0.6 0.8 1 -3
","['-3']
","[] 
",0
"-2
","['-2']
","[] 
",0
"-1
","['-1']
","[] 
",0
"0
","[]
","[] 
",0
"1
","[]
","[] 
",0
"2
","[]
","[] 
",0
"3
","[]
","[] 
",0
"= 9M
","[]
","[] 
",0
"M= 1
","['M=']
","[] 
",0
"M= 3
","['M=']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"9.
","[]
","[] 
",0
"Training set in Fig.
","['Training', 'Fig']
","['set'] 
",0
"5, along with a predictor trained by using the discriminative model (11) and ML for different values of the model order M .
","['predictor', 'discriminative model', 'ML', 'different values', 'order M']
","['trained using'] 
",0
"In words, the output t is given by a polynomial function of order M of the input x plus zero-mean Gaussian noise of power equal to one.
","['words', 'output', 'polynomial function order M input x', 'zero-mean Gaussian noise power']
","['given'] 
",0
"The learnable parameter vector θ is given by the weights w = [w0, ..., wM−1]T .
","['The learnable parameter vector θ', 'weights', '= [ w0', 'wM−1 ] T']
","['given', 'w'] 
",1
"Model selection, to be carried out in Step 1, amounts to the choice of the model order M .
","['Model selection', 'Step', 'amounts choice model order M']
","['carried'] 
",0
"Having chosen M in Step 1, the weights w can be learned in Step 2 using ML, and then the optimal pre- dictor can be obtained for inference in Step 3.
","['M Step', 'weights', 'learned Step', 'ML', 'optimal pre- dictor', 'inference Step']
","['Having chosen', 'w', 'using', 'obtained'] 
",1
"Assuming the quadratic loss, the optimal predictor is given by the posterior mean t̂(x) =
","['quadratic loss', 'optimal predictor', 'posterior mean t̂', 'x', '=']
","['Assuming', 'given'] 
",1
"∑M m=0wmx
","['∑M m=0wmx']
","[] 
",0
"m for the learned parameters w. This predictor is plotted in Fig.
","['parameters', 'This predictor', 'Fig']
","['learned', 'plotted'] 
",1
"9 for different values of M , along with the training set of Fig.
","['different values M', 'training', 'Fig']
","['set'] 
",0
"5.
","[]
","[] 
",0
"With M = 1, the predictor t̂(x) is seen to underfit the training data.
","['M =', 'predictor t̂', 'x', 'underfit training data']
","['seen'] 
",0
"This is in the sense that the model is not rich enough to capture the variations present in the training data, and, as a result, we obtain a large training loss
","['This sense model', 'capture variations', 'data', 'result', 'large training loss']
","['training', 'obtain'] 
",1
"LD(w) = 1
","['LD', 'w']
","['='] 
",0
"N
","['N']
","[] 
",0
"N∑ n=1
","['N∑ n=1']
","[] 
",0
"(tn − t̂(xn))2.
","['tn − t̂', 'xn']
","[] 
",0
"(12)
","[]
","[] 
",0
"The training loss measures the quality of the predictor defined by weights w on the points in the training set.
","['The training loss', 'quality predictor', 'weights', 'w points', 'set']
","['measures', 'defined', 'training'] 
",1
"In contrast, with M = 9, the predictor fits well the training data – so much so that it appears to overfit it.
","['contrast', 'M =', 'predictor fits', 'data', 'overfit']
","['well training', 'appears'] 
",1
"In other words, the model is too rich and, in order to account for the observations in the training set, it appears to yield inaccurate predictions outside it.
","['words', 'model', 'order account observations training', 'yield inaccurate predictions']
","['set', 'appears'] 
",1
"As a compromise between underfitting and overfitting, the selection M = 3 seems to be preferable.
","['compromise', 'overfitting', 'selection M']
","['underfitting', '=', 'seems'] 
",1
"As implied by the discussion above, underfitting can be detected by observing solely the training data D via the evaluation of the training loss (12).
","['implied discussion', 'data D', 'evaluation training loss']
","['underfitting detected observing', 'solely training'] 
",1
"In contrast, over-
","['contrast']
","[] 
",0
"fitting cannot be ascertained on the basis of the training data as it refers to the performance of the predictor out- side D. It follows that model selection cannot be carried out by observing only the training set.
","['fitting', 'basis training data refers performance predictor', 'out- side D.', 'model selection', 'training set']
","['ascertained', 'follows', 'carried observing'] 
",1
"Rather, some information must be available about the generalization performance of the predictor.
","['information', 'available generalization performance predictor']
","[] 
",0
"This is typically obtained by means of validation.
","['validation']
","['typically obtained means'] 
",0
"In its simplest instantiation, validation partitions the available data into two sets, a training set D and a validation set.
","['instantiation', 'validation partitions', 'available data', 'sets', 'D validation set']
","['training set'] 
",0
"The training set is used for learning as discussed in Sec.
","['The training set', 'learning', 'Sec']
","['used', 'discussed'] 
",1
"III-E, while the validation set is used to estimate the generalization loss.
","['III-E', 'validation set', 'estimate generalization loss']
","['used'] 
",0
"This is done by computing the average in (12) only over the validation set.
","['computing average', 'validation']
","['done', 'set'] 
",1
"More sophisticated forms of validation exist, including cross-validation [7].
","['sophisticated forms validation', 'cross-validation [', ']']
","['exist', 'including'] 
",1
"Keeping some data aside for validation, one can obtain a plot as in Fig.
","['data', 'validation', 'plot Fig']
","['Keeping', 'obtain'] 
",1
"10, where the training loss (12) is compared with the generalization loss (2) estimated via validation.
","['loss', 'generalization loss', 'validation']
","['training', 'compared', 'estimated'] 
",1
"The figure allows us to conclude that, when M is large enough, the generalization loss starts increasing, indicating overfitting.
","['The figure', 'M', 'generalization loss', 'overfitting']
","['allows', 'conclude', 'starts increasing', 'indicating'] 
",1
"Note, in contrast, that underfitting is detectable by observing the training loss.
","['Note', 'contrast', 'training loss']
","['underfitting', 'observing'] 
",1
"A figure such as Fig.
","['A figure Fig']
","[] 
",0
"10 can be used to choose a value of M that approximately minimizes the generalization loss.
","['choose value M', 'generalization loss']
","['used', 'approximately minimizes'] 
",1
"More generally, validation allows for model selection, as well as for the selection of the parameters used by learning the algorithm, such as the learning rate γ in (10).
","['validation', 'model selection', 'selection parameters', 'algorithm', 'rate γ']
","['allows', 'used learning', 'learning'] 
",1
"To this end, one compares the generalization loss, estimated via validation, for a number of models and then chooses the one with the smallest estimated generalization loss.
","['generalization loss', 'validation', 'number models', 'smallest', 'generalization loss']
","['end', 'compares', 'estimated', 'chooses', 'estimated'] 
",1
"Finally, it is important to remark that the performance of the model selected via validation should be estimated on the basis of a separate data set, typically called the test set.
","['important remark performance model', 'validation', 'basis', 'separate data set', 'test set']
","['selected', 'estimated', 'typically called'] 
",1
"This is because the generalization loss estimated using validation is a biased estimate of the true generalization loss (2) due to the process of model selection.
","['This generalization loss', 'validation', 'estimate', 'true generalization loss', 'due process model selection']
","['estimated using', 'biased'] 
",1
"In particular, the loss on the validation set will tend to be small, since the model was selected during validation with the aim of minimizing it.
","['loss validation', 'model', 'validation aim minimizing']
","['set tend', 'selected'] 
",1
"Importantly, the test set should never be used during the three steps that make up the machine learning methodology and should ideally only be used once to test the trained predictor.
","['test set', 'steps', 'machine', 'methodology', 'used test', 'predictor']
","['never used', 'make', 'learning', 'trained'] 
",1
"IV.
","['IV']
","[] 
",0
"APPLICATIONS OF SUPERVISED LEARNING TO COMMUNICATION SYSTEMS
","['APPLICATIONS OF SUPERVISED LEARNING TO COMMUNICATION SYSTEMS']
","[] 
",0
"In this section, we provide some pointers to existing applications of supervised learning to communication networks.
","['section', 'pointers', 'applications', 'communication networks']
","['provide', 'existing', 'supervised learning'] 
",1
"The discussion is organized by following the approach described in Sec.
","['The discussion', 'approach', 'Sec']
","['organized following', 'described'] 
",1
"II.
","['II']
","[] 
",0
"Accordingly, we distin- guish between tasks carried out at edge and cloud (see
","['distin- guish tasks', 'edge cloud']
","['carried', 'see'] 
",1
"10
","[]
","[] 
",0
"1 2 3 4 5 6 7 8 9 0
","[]
","[] 
",0
"0.2
","[]
","[] 
",0
"0.4
","[]
","[] 
",0
"0.6
","[]
","[] 
",0
"0.8
","[]
","[] 
",0
"1
","[]
","[] 
",0
"1.2
","[]
","[] 
",0
"1.4
","[]
","[] 
",0
"1.6 ro
","['ro']
","[] 
",0
"ot  a
","['ot']
","[] 
",0
"ve ra
","['ra']
","[] 
",0
"ge  s
","['ge']
","[] 
",0
"qu ar
","['qu ar']
","[] 
",0
"ed  l
","['ed l']
","[] 
",0
"os s
","['os']
","[] 
",0
"training
","['training']
","[] 
",0
"generalization  (via validation)
","['generalization', 'validation']
","[] 
",0
"overfittingunderfitting
","[]
","['overfittingunderfitting'] 
",0
"Fig.
","['Fig']
","[] 
",0
"10.
","[]
","[] 
",0
"Training loss and generalization loss, estimated via valida- tion, as a function of the model order M for the example in Fig.
","['loss generalization loss', 'valida- tion', 'function model order M example Fig']
","['Training', 'estimated'] 
",1
"9.
","[]
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"4), as well as at different layers of the protocol stack.
","['different layers', 'stack']
","['protocol'] 
",0
"We refer to Table I and Table II for examples of data types that may be available at the edge and cloud segments.
","['II examples data types', 'available edge cloud segments']
","['refer', 'Table'] 
",1
"A.
","[]
","[] 
",0
"At the Edge
","['Edge']
","[] 
",0
"Consider first tasks to be carried out at the edge, i.e.-, at the base stations or at the associated edge computing platform.
","['first tasks', 'edge', 'base stations', 'edge', 'platform']
","['Consider', 'carried', 'associated', 'computing'] 
",1
"1) Physical Layer: For the physical layer, we focus first on the receiver side and then on the transmitter.
","['Physical Layer', 'physical layer', 'focus', 'receiver side transmitter']
","[] 
",0
"At the receiver, a central task that can potentially ben- efit from machine learning is channel detection and decoding.
","['receiver', 'central task', 'ben- efit machine', 'channel detection decoding']
","['learning'] 
",0
"This amounts to a multi-class classification problem, in which the input x is given by the received baseband signal and the output is the label of the correct transmitted message (e.g.-, the transmitted bits) [13], [30].
","['multi-class classification problem', 'input x', 'baseband signal output label correct', 'message', 'transmitted bits', ']', ']']
","['amounts', 'given received', 'transmitted', '[', '['] 
",1
"When can machine learning help?
","['machine', 'help']
","['learning'] 
",0
"Recalling the discussion in Sec.
","['discussion Sec']
","['Recalling'] 
",0
"II, we should first ask whether a modelling or algorithmic deficit exists.
","['II', 'algorithmic deficit exists']
","['first ask', 'modelling'] 
",1
"A model deficit may occur when operating over channels that do not have well-established mathematical models, such as for molecular communications [31].
","['A model deficit', 'channels', 'well-established mathematical models', 'molecular communications', ']']
","['occur operating', '['] 
",1
"Algorithm deficit is more common, given that optimal decoders over a number of well-established channel models tend to be computationally complex.
","['Algorithm deficit', 'optimal decoders number', 'well-established channel models']
","['given', 'tend'] 
",1
"This is the case for channels with strong non-linearities, as recognized as early as the nineties in the context of satellite communication [2], [32] and more recently for optical communications [33]; or for modulation schemes such as continuous phase modulation [34] – another work from the nineties – or in multi–user networks [35].
","['This case', 'strong non-linearities', 'early nineties', 'satellite communication', ']', ']', 'optical communications', ']', 'modulation', 'continuous phase modulation', '] –', 'another work nineties', 'networks', ']']
","['channels', 'recognized', 'context', '[', '[', '[', 'schemes', '[', '–', '['] 
",1
"Assuming that the problem at hand is characterized by a modelling or algorithmic deficit, then one should also
","['problem hand', 'algorithmic deficit']
","['Assuming', 'characterized modelling'] 
",1
"check the remaining criteria listed in Sec.
","['check', 'criteria', 'Sec']
","['remaining', 'listed'] 
",1
"II, particularly those regarding the rate of change of the phenomenon under study and the requirements in terms of perfor- mance guarantees.
","['II', 'rate change phenomenon study requirements terms', 'perfor- mance guarantees']
","['particularly regarding'] 
",0
"For channel decoding, the presence of fast-varying channels may make the first criterion hard to be satisfied in practice (unless channel estimation is made part of the learning process); while stringent reliability requirements may preclude the use of machine learning in the presence of a model deficit.
","['channel decoding', 'presence', 'fast-varying channels', 'first criterion', 'satisfied practice', 'channel estimation', 'part', 'process', 'stringent reliability requirements', 'use machine', 'presence model deficit']
","['make', 'made', 'learning', 'preclude', 'learning'] 
",1
"As mentioned, a generally beneficial idea in the use of data-aided methods is that of incorporating domain knowledge in the definition of the hypothesis class.
","['beneficial idea use', 'data-aided methods', 'domain knowledge definition hypothesis class']
","['mentioned', 'incorporating'] 
",1
"As notable examples related to channel decoding, in [36], [37], knowledge of the near-optimality of message pass- ing methods for the decoding of sparse graphical codes is used to set up a parameterized model that borrows the message passing structure and that is trained to decode more general codes.
","['notable examples', 'channel', ']', ']', 'near-optimality message', 'pass- ing methods', 'sparse graphical codes', 'parameterized model', 'message passing structure', 'decode general codes']
","['related', 'decoding', '[', 'knowledge', 'decoding', 'used set', 'borrows', 'trained'] 
",1
"A related approach is investigated in [38] for polar codes.
","['A related approach', '] polar codes']
","['investigated'] 
",0
"Another useful idea is that of directly integrating algorithms designed using the standard engineering flow with trained machines.
","['Another useful idea', 'algorithms', 'standard engineering flow', 'machines']
","['directly integrating', 'designed using', 'trained'] 
",1
"Instances of this idea include [39] in which a conventional channel decoder is deployed in tandem with a channel equalizer at its input that is trained to compensate for hardware impairments.
","['Instances idea', '] conventional channel decoder', 'tandem channel equalizer input', 'compensate hardware impairments']
","['include', 'deployed', 'trained'] 
",1
"A related approach is proposed in [40], whereby a conventional decoder is implemented within a turbo-like iterative loop with a machine learning-based regressor that has the role of estimating the channel noise.
","['A related approach', ']', 'conventional decoder', 'turbo-like iterative loop machine', 'learning-based regressor role', 'channel noise']
","['proposed', 'implemented', 'estimating'] 
",1
"Other tasks that can potentially benefit from machine learning at the receiver’s side include modulation clas- sification, which is a classification problem justified by the complexity of optimal solutions (algorithm deficit) [41]; localization, which is a regression problem, typ- ically motivated by the lack of tractable channels for complex propagation environments (model deficit) [42]; and channel state information-based authentication, a classification problem made difficult by the absence of well-established models relating channel features with devices’ identities (model deficit) [43].
","['Other tasks', 'machine learning receiver ’ side', 'modulation', 'clas- sification', 'classification problem', 'complexity', 'optimal solutions', 'deficit', ']', 'localization', 'regression problem', 'lack', 'tractable channels', 'complex propagation environments', 'model deficit', ']', 'channel state', 'information-based authentication', 'classification problem', 'difficult absence well-established models', 'channel features devices', '’ identities', 'model deficit', ']']
","['potentially benefit', 'include', 'justified', '[', 'ically motivated', '[', 'made', 'relating', '['] 
",1
"Turning to the transmitter side, most emerging ap- plications tackle the algorithmic deficit related to the complexity of the non-convex programs that typically underlie power control and precoding optimization for the downlink.
","['transmitter side', 'ap- plications', 'algorithmic deficit', 'complexity', 'non-convex programs', 'underlie power control', 'optimization downlink']
","['Turning', 'emerging', 'tackle', 'related', 'precoding'] 
",1
"Notably, in [44], a training set is ob- tained by running a non-convex solver to produce an optimized output power vector for given input channels.
","[']', 'non-convex solver', 'output power vector', 'input channels']
","['[', 'training set', 'running', 'produce optimized', 'given'] 
",1
"Note that the approach does not directly optimize the performance criterion of interest, such as the sum-rate.
","['Note approach', 'optimize performance criterion interest', 'sum-rate']
","[] 
",0
"Rather, it relies on the assumption that similar inputs – the channel coefficients – generally yield similar optimal solutions – the power allocation vector.
","['relies', 'similar inputs', '– channel coefficients', 'similar optimal solutions', 'power allocation vector']
","['assumption', '– generally yield', '–'] 
",1
"if the analytical
","[]
","[] 
",0
"11
","[]
","[] 
",0
"model available based on domain knowledge is only a coarse approximation of the physical model, the resulting training set can be used to augment the data in order to carry out a preliminary training of a machine learning model [45]2.
","['model', 'domain knowledge', 'coarse approximation', 'physical model', 'training set', 'augment data order', 'preliminary training machine', 'model']
","['based', 'resulting', 'used', 'carry', 'learning'] 
",1
"For an application at a full-duplex transceiver, we refer to [47], which learns how to cancel self-interference in order to overcome the lack of well-established models for the transmitter-receiver chain of non-linearities.
","['application', 'full-duplex transceiver', ']', 'cancel self-interference order', 'overcome lack', 'well-established models', 'chain non-linearities']
","['refer', 'learns'] 
",1
"2) Link and Medium Access Control Layers: At the medium access control layer, we highlight some ap- plications of machine learning that tackle the lack of mathematical models for complex access protocols and communication environments.
","['Link Medium Access Control Layers', 'medium access control layer', 'ap- plications machine', 'tackle lack', 'mathematical models', 'complex access protocols communication environments']
","['highlight', 'learning'] 
",1
"In [48], a mechanism is proposed to predict whether a channel decoder will suc- ceed on the basis of the outputs of the first few iterations of the iterative decoding process.
","[']', 'mechanism', 'channel decoder', 'suc- ceed basis outputs', 'first iterations', 'process']
","['proposed', 'iterative decoding'] 
",1
"This binary predictor is useful in order to request an early retransmission at the link layer using Automatic Retransmission Request (ARQ) or Hybrid ARQ (HARQ) in order to reduce latency.
","['This binary predictor', 'useful order request', 'early retransmission link layer', 'Automatic Retransmission Request', 'ARQ', 'Hybrid ARQ', 'HARQ', 'order', 'latency']
","['using', 'reduce'] 
",1
"At the medium access control layer, data-aided methods can instead be used to predict the availability of spectrum in the presence of interfering incumbent devices with complex activation patterns for cognitive radio applications [49] (see also [50]).
","['medium access control layer', 'data-aided methods', 'predict availability spectrum presence', 'incumbent devices', 'complex activation patterns', 'cognitive radio applications', ']', ']']
","['instead used', 'interfering', '[', 'see'] 
",1
"An approach that leverages depth images to detect the availability of mmwave channels is proposed in [51].
","['An approach', 'depth images', 'availability', 'channels', ']']
","['leverages', 'detect', 'mmwave', 'proposed'] 
",1
"3) Network and Application Layers: A task that is particularly well-suited for machine learning is the caching of popular contents for reduced latency and network congestion [52].
","['Network Application Layers', 'A task', 'well-suited machine', 'popular contents', 'latency network congestion', ']']
","['learning caching', 'reduced', '['] 
",1
"Caching may take place at the edge and, more traditionally, within the core network segment.
","['place edge', 'core network segment']
","['Caching', 'take'] 
",1
"Caching at the edge has the advantage of catering directly to the preference of the local population of users, but it generally suffers from a reduced hit rate due to the smaller available storage capacity.
","['edge advantage', 'local population users', 'suffers', 'hit rate', 'available storage capacity']
","['Caching', 'catering', 'reduced'] 
",1
"Optimizing the selection of contents to be stored at the edge can be formulated as a classification problem that can benefit from a data-driven approach in order to adapt to the specific features of the local traffic [52].
","['selection contents', 'edge', 'classification problem benefit', 'data-driven approach order adapt', 'local traffic', ']']
","['Optimizing', 'stored', 'formulated', 'features', '['] 
",1
"B.
","['B']
","[] 
",0
"At the Cloud
","['Cloud']
","[] 
",0
"We now turn to some relevant tasks to be carried out at the cloud at both network and application layers.
","['relevant tasks', 'cloud network application layers']
","['turn', 'carried'] 
",1
"1) Network: The main task of the network layer is routing (see [53] for further discussion).
","['Network', 'The main task network layer routing', '] discussion']
","['see'] 
",0
"Considering a software-defined networking implementation, routing re- quires the availability at a network controller of informa- tion regarding the quality of individual communication
","['software-defined networking implementation', 're- quires availability network controller', 'informa- tion', 'quality', 'individual communication']
","['Considering', 'routing', 'regarding'] 
",1
"2This can be thought of as an example of experience learning as part of small-sample learning techniques [46].
","['thought example experience', 'part', 'small-sample learning techniques', ']']
","['learning', '['] 
",1
"links in the core network, as well as regarding the status of the queues at the network routers.
","['links core network', 'status queues network routers']
","['well regarding'] 
",0
"In the presence of wireless or optical communications, the quality of a link may not be available at the network controller, but it may be predicted using available historical data [33], [54] in the absence of agreed-upon dynamic availability models.
","['presence wireless', 'optical communications', 'quality link', 'available network controller', 'available historical data', ']', '] absence', 'agreed-upon dynamic availability models']
","['predicted using', '['] 
",1
"In a similar manner, predicting congestion can be framed as a data-aided classification problem [55].
","['similar manner', 'congestion', 'data-aided classification problem', ']']
","['predicting', 'framed', '['] 
",1
"2) Application: Finally, a relevant supervised learning task is that of traffic classification, whereby data streams are classified on the basis of some extracted features, such as packet sizes and inter-arrival times, in terms of their applications, e.g.-, Voice over IP.
","['Application', 'relevant', 'task traffic classification', 'data streams', 'basis', 'features', 'packet', 'inter-arrival times', 'terms applications', 'Voice IP']
","['supervised learning', 'classified', 'extracted', 'sizes'] 
",1
"[56]
","[']']
","[] 
",0
"V. UNSUPERVISED LEARNING
","['V. UNSUPERVISED LEARNING']
","[] 
",0
"As introduced in Sec.
","['Sec']
","['introduced'] 
",0
"I, unlike supervised learning, unsupervised learning tasks operate over unlabelled data sets consisting solely of the inputs xn, with n = 1, ..., N , and the general goal is that of discovering properties of the data.
","['learning', 'unsupervised learning tasks', 'unlabelled data sets', 'inputs xn', 'n =', 'N', 'general goal', 'properties data']
","['supervised', 'operate', 'consisting', 'discovering'] 
",1
"We start this section by reviewing some of the typical specific unsupervised learning tasks.
","['section', 'typical specific', 'learning tasks']
","['start', 'reviewing', 'unsupervised'] 
",1
"We then cover methodology, models, and learning, includ- ing advanced methods such as Generative Adversarial Networks (GANs) [7].
","['methodology', 'models', 'includ- ing', 'methods Generative Adversarial Networks', 'GANs', ']']
","['cover', 'learning', 'advanced', '['] 
",1
"A.
","[]
","[] 
",0
"Goals and Definitions
","['Goals Definitions']
","[] 
",0
"In unsupervised learning, taking a frequentist formu- lation (see Sec.
","['unsupervised learning', 'frequentist formu- lation', 'Sec']
","['taking', 'see'] 
",1
"III-A), we are given a training set D consisting of N i.i.d.
","['III-A', 'training', 'D', 'N i.i.d']
","['given', 'set', 'consisting'] 
",1
"samples xn ∼ p(x) with n = 1, ..., N generated from an unknown true distribution p(x).
","['samples', '∼ p', 'x', 'N', 'unknown true distribution p', 'x']
","['xn', 'n', 'generated'] 
",1
"The high-level goal is that of learning some useful properties of the distribution p(x).
","['The high-level goal', 'useful properties distribution p', 'x']
","['learning'] 
",0
"More specifically, we can identify the following tasks.
","['tasks']
","['identify following'] 
",0
"• Density estimation: Density estimation aims at es-
","['• Density estimation', 'Density estimation', 'es-']
","['aims'] 
",0
"timating directly the distribution p(x).
","['distribution p', 'x']
","['timating'] 
",0
"This may be useful, for example, for use in plug-in estimators of information-theoretic quantities, for the design of compression algorithms, or to detect outliers;
","['example', 'plug-in estimators', 'information-theoretic quantities', 'design compression algorithms', 'detect outliers']
","['useful', 'use'] 
",1
"• Clustering: Clustering aims at partitioning all points in the data set D in groups of similar objects, where the notion of similarity is domain-dependent;
","['• Clustering', 'Clustering aims', 'points data', 'D groups', 'similar objects', 'notion similarity domain-dependent']
","['partitioning', 'set'] 
",1
"• Dimensionality reduction, representation, and fea- ture extraction: These three related tasks represent each data point xn in a different space, typically of lower dimensionality, in order to highlight in- dependent explanatory factors and/or to ease visu- alization, interpretation, or the implementation of successive tasks, e.g.-, classification;
","['• Dimensionality reduction', 'representation', 'fea- ture extraction', 'tasks', 'represent data point xn', 'different space', 'dimensionality', 'order', 'in- dependent explanatory factors', 'ease visu- alization', 'interpretation', 'implementation', 'successive tasks', 'classification']
","['related', 'highlight', 'and/or'] 
",1
"• Generation of new samples: Given the data set D, we wish to learn a machine that produces sam- ples that are approximately distributed according
","['• Generation', 'new samples', 'data', 'D', 'machine', 'sam- ples']
","['Given', 'set', 'produces', 'approximately distributed according'] 
",1
"12
","[]
","[] 
",0
"to p(x).
","['p', 'x']
","[] 
",0
"As an example, if the data set contains images of celebrities, the idea is to produce plausi- ble images of non-existent celebrities.
","['example', 'data', 'contains', 'images celebrities', 'idea', 'plausi- ble images', 'non-existent celebrities']
","['set', 'produce'] 
",1
"This can be useful, e.g.-, to produce artificial scenes for video parameterizes or films.
","['artificial scenes video', 'films']
","['produce', 'parameterizes'] 
",1
"As suggested by the variety of tasks listed above, unsupervised learning does not have a formal unified formulation as supervised learning.
","['variety tasks', 'formal unified formulation', 'learning']
","['suggested', 'listed', 'learning', 'supervised'] 
",1
"Nevertheless, the general methodology follows three main steps in a manner similar to supervised learning (see Sec.
","['general methodology', 'main steps', 'learning', 'Sec']
","['follows', 'supervised', 'see'] 
",1
"III-D).
","['III-D']
","[] 
",0
"In Step 1 (model selection), a model, or a hypothesis class, is selected, defining the inductive bias of the learning process.
","['Step', 'model selection', 'model', 'hypothesis class', 'inductive bias', 'process']
","['selected', 'defining', 'learning'] 
",1
"This is done by positing a family of probability distributions p(x|θ) parameterized by a vector θ.
","['family probability distributions', 'x|θ', 'vector θ']
","['done positing', 'p', 'parameterized'] 
",1
"In Step 2 (learning), the data D is used to optimize a learning criterion with the aim of choosing a value for the parameter vector θ.
","['Step', 'data D', 'learning criterion aim', 'value parameter vector θ']
","['learning', 'used', 'choosing'] 
",1
"Finally, in Step 3, the trained model is leveraged in order to carry out the task of interest, e.g.-, clustering or sample generation.
","['Step', 'model', 'leveraged order carry task interest', 'sample generation']
","['trained', 'clustering'] 
",1
"In the following, we discuss Step 1 (model selection) and Step 2 (learning).
","['discuss Step', 'model selection', 'Step']
","['following', 'learning'] 
",1
"For the formulation of specific tasks to be carried out at Step 3, we refer to, e.g.-, [7], [19], [57].
","['formulation', 'specific tasks', 'Step', 'refer', ']', ']', ']']
","['carried', '[', '['] 
",1
"B.
","['B']
","[] 
",0
"Models
","['Models']
","[] 
",0
"Unsupervised learning models, selected at Step 1 of the machine learning process, typically involve a hidden or latent (vector of) variables zn for each data point xn.
","['learning models', 'Step', 'machine learning process', 'hidden latent', 'vector', 'zn data point xn']
","['Unsupervised', 'selected', 'typically involve', 'variables'] 
",1
"For example, in a clustering problem, the latent variable zn represents the cluster index of xn.
","['example', 'problem', 'latent', 'variable zn', 'cluster index xn']
","['clustering', 'represents'] 
",1
"Latent variables are hidden or unobserved in the sense that they do not appear for any of the data points xn in D.3 The relationship between latent variables zn and observable variables xn can be modelled in different ways, giving rise to a number of different types of models for unsupervised learning.
","['Latent variables', 'unobserved sense', 'data points', 'xn D.3', 'The relationship', 'latent variables', 'observable variables', 'different ways', 'rise number', 'different types models', 'learning']
","['hidden', 'appear', 'zn', 'xn modelled', 'giving', 'unsupervised'] 
",1
"These are illustrated in Fig.
","['Fig']
","['illustrated'] 
",0
"11 and discussed next.
","[]
","[] 
",0
"By way of a short round-up of types of models, with reference to Fig.
","['way', 'short round-up types models', 'reference Fig']
","[] 
",0
"11, directed generative models, illustrated by Fig.
","['generative models', 'Fig']
","['directed', 'illustrated'] 
",1
"11(a), posit that there exist hidden causes z yielding the observation x. Undirected genera- tive models, represented in Fig.
","['hidden causes', 'observation', 'genera- tive models', 'Fig']
","['posit exist', 'z yielding', 'x. Undirected', 'represented'] 
",1
"11(b) model the mutual correlation between x and z. Discriminative models, illustrated by Fig.
","['b', 'model', 'mutual correlation x z. Discriminative models', 'Fig']
","['illustrated'] 
",0
"11(c) model the extraction of the latent representation z from x.
","['c', 'model extraction', 'latent representation z x']
","[] 
",0
"Finally, autoencoders, represented in Fig.
","['autoencoders', 'Fig']
","['represented'] 
",0
"11(d) assume that x is encoded into a latent representation z in such as way that x can then be approximately recovered from z.
","['encoded latent representation z way x', 'z']
","['assume', 'approximately recovered'] 
",1
"In the following, we provide some additional details about directed generative
","['additional details']
","['following', 'provide', 'directed'] 
",1
"3Problems in which some of the inputs in D are labelled by a value zn are filed under the rubric of semi-supervised learning [29].
","['inputs D', 'value zn', 'rubric semi-supervised learning', ']']
","['labelled', 'filed'] 
",1
"Fig.
","['Fig']
","[] 
",0
"11.
","[]
","[] 
",0
"Illustration of typical unsupervised learning models: (a) directed generative models; (b) undirected generative models; (c) discriminative models; and (d) autoencoders.
","['Illustration', 'learning models', 'generative models', 'b', 'generative models', 'c', 'discriminative models', 'autoencoders']
","['unsupervised', 'directed', 'undirected'] 
",1
"models and autoencoders, and we point to [19] and references therein for a discussion about the remaining models.
","['models autoencoders', 'point', '] references', 'therein discussion', 'models']
","['[', 'remaining'] 
",1
"As illustrated in Fig.
","['illustrated Fig']
","[] 
",0
"11(a), directed generative models assume that each data point x is caused4 by a hidden variable z.
","['generative models', 'data point x caused4 hidden', 'variable z']
","['directed', 'assume'] 
",1
"This is in the sense that the joint distribution p(x, z|θ) is parameterized as p(x, z|θ) = p(z|θ)p(x|z, θ), where p(z|θ) is the distribution of the hidden cause and p(x|z, θ) is the conditional distribution of the data x given the cause z.
","['This sense', 'joint distribution p', 'z|θ', 'p', 'z|θ', '= p', 'z|θ', 'p', 'θ', 'z|θ', 'distribution', 'cause p', 'θ', 'conditional distribution data', 'cause z']
","['parameterized', 'hidden', 'x given'] 
",1
"As a result, under a directed generative model, the distribution of an observation x = x can be written as
","['result', 'generative model', 'distribution observation x = x']
","['directed', 'written'] 
",1
"p(x|θ) = ∑ z
","['p', 'x|θ', '∑ z']
","['='] 
",0
"p(z|θ)p(x|z, θ) = Ez∼p(z|θ)[ln p(x|z, θ)],
","['p', 'z|θ', 'p', 'θ', 'Ez∼p', 'z|θ', 'ln p', 'θ', ']']
","['=', '['] 
",1
"(13) where the sum in the second term should be replaced by an integration for continuous hidden variables, and the last equality expresses the marginalization over z as an expectation.
","['sum', 'second term', 'integration', 'continuous hidden variables', 'last equality', 'marginalization z expectation']
","['replaced', 'expresses'] 
",1
"As an example, for the problem of document clus- tering, variable x represents a document in the training set and z is interpreted as a latent topic that “causes” the generation of the document.
","['example', 'problem document clus- tering', 'variable x', 'document training', 'z', 'interpreted latent topic “', '” generation document']
","['represents', 'set', 'causes'] 
",1
"Model selection requires the specification of a parameterized distribution p(z|θ) over the topics, e.g.-, a categorical distribution with parameters equals to the probability of each possible value, and the distribution p(x|z, θ) of the document given a topic.
","['Model selection', 'distribution p', 'z|θ', 'topics', 'categorical distribution parameters', 'probability', 'possible value', 'distribution p', 'θ', 'document', 'topic']
","['requires', 'parameterized', 'equals', 'given'] 
",1
"Basic representatives of directed generative models include mixture of Gaussians and likelihood-free models [19], [58].
","['Basic representatives', 'generative models', 'likelihood-free models', ']', ']']
","['directed', 'include', '[', '['] 
",1
"4The use of the term “cause” is meant to be taken in an intuitive, rather than formal, way.
","['use term “ cause ”', 'way']
","['meant taken'] 
",0
"For a discussion on the study of causality, we refer to [8].
","['discussion study causality', ']']
","['refer'] 
",0
"13
","[]
","[] 
",0
"As represented in Fig.
","['Fig']
","['represented'] 
",0
"11(d), autoencoders model encoding from data x to hidden variables z, as well as de- coding from hidden variables back to data.
","['autoencoders', 'data x hidden variables z', 'hidden variables', 'data']
","['model encoding', 'coding'] 
",1
"Accordingly, model selection for autoencoders requires the specifica- tion of a parameterized family of encoders p(z|x, θ) and decoders p(x|z, θ).
","['model selection autoencoders', 'specifica- tion', 'family encoders', 'z|x', 'θ', 'decoders', 'θ']
","['requires', 'parameterized', 'p', 'p'] 
",1
"As an example, autoencoders can be used to learn how to compress an input signal x into a representation z in a smaller space so as to ensure that x can be recovered from z within an admissible level of distortion.
","['example', 'autoencoders', 'learn compress', 'signal x representation z', 'space', 'x', 'admissible level distortion']
","['used', 'input', 'ensure', 'recovered'] 
",1
"Representatives of autoencoders, which cor- respond to specific choices for the encoder and decoder families of distributions, include Principal Component Analysis (PCA), dictionary learning, and neural network- based autoencoders [19], [57], [58].
","['Representatives autoencoders', 'cor- respond', 'specific choices', 'decoder families distributions', 'Principal Component Analysis', 'PCA', 'dictionary learning', 'neural network-', 'autoencoders', ']', ']', ']']
","['encoder', 'include', 'based', '[', '[', '['] 
",1
"C. Learning
","['C. Learning']
","[] 
",0
"We now discuss learning, to be carried out as Step 2.
","['Step']
","['discuss learning', 'carried'] 
",1
"For brevity, we focus on directed generative models and refer to [19] and references therein for a treatment of learning for the other models in Fig.
","['brevity', 'focus', 'generative models', '] references', 'treatment learning models Fig']
","['directed', 'refer', 'therein'] 
",1
"11.
","[]
","[] 
",0
"In this regard, we note that the problem of training autoencoders is akin to supervised learning in the sense that autoencoders specify the desired output for each input in the training set.
","['regard', 'note problem training autoencoders', 'learning sense autoencoders', 'output input training set']
","['akin supervised', 'specify desired'] 
",1
"As for supervised learning, the most basic learning criterion for probabilistic models is ML.
","['learning', 'criterion', 'probabilistic models ML']
","['supervised', 'learning'] 
",1
"Following the discussion in Sec.
","['discussion Sec']
","['Following'] 
",0
"III-E, ML tackles the problem of maximizing the log-likelihood of the data, i.e.-,
","['III-E', 'ML', 'problem', 'log-likelihood data', 'i.e.-']
","['tackles', 'maximizing'] 
",1
"maximize θ
","['θ']
","['maximize'] 
",0
"ln p(x|θ) = lnEz∼p(z|θ)[ln p(x|z, θ)].
","['ln p', 'x|θ', 'lnEz∼p', 'z|θ', 'ln p', 'θ', ']']
","['=', '['] 
",1
"(14)
","[]
","[] 
",0
"Note that problem (14) considers only one data point x in the data set for the purpose of simplifying the notation, but in practice the log-likelihood needs to be summed over the N examples in D.
","['Note problem', 'considers', 'data point x data set purpose', 'notation', 'practice log-likelihood needs', 'N examples D']
","['simplifying', 'summed'] 
",1
"Unlike the corresponding problem for supervised learning (8), the likelihood in (14) requires an average over the hidden variables.
","['problem', 'learning', 'likelihood', 'average hidden variables']
","['corresponding', 'supervised', 'requires'] 
",1
"This is because the value of the hidden variables z is not known, and hence the probability of the observation x needs to account for all possible values of z weighted by their probabilities p(z|θ).
","['This value', 'variables', 'hence probability observation x', 'account', 'possible values', 'weighted probabilities', 'z|θ']
","['hidden', 'known', 'needs', 'z', 'p'] 
",1
"This creates a number of technical challenges.
","['number', 'technical challenges']
","['creates'] 
",0
"First, the objective in (14) is generally more complex to optimize, since the average over z destroys the typical structure of the model p(x|z, θ), whose logarithm is often selected as a tractable function (see, e.g.-, logistic re- gression).
","['complex optimize', 'average z', 'typical structure model p', 'θ', 'logarithm', 'tractable function', 'logistic re- gression']
","['destroys', 'often selected', 'see'] 
",1
"Second, the average in (14) cannot be directly approximated using Monte Carlo methods if the goal is to optimize over the model parameters θ, given that the distribution p(z|θ) generally depends on θ itself.
","['Monte Carlo methods goal', 'model parameters', 'distribution p', 'z|θ', 'θ']
","['directly approximated using', 'optimize', 'θ', 'given', 'generally depends'] 
",1
"To tackle these issues, a standard approach is based on the introduction of a variational distribution q(z)
","['issues', 'standard approach', 'introduction', 'variational distribution q', 'z']
","['tackle', 'based'] 
",1
"over the hidden variables and on the optimization of a tractable lower bound on the log-likelihood known as the Evidence Lower BOund (ELBO).
","['hidden variables optimization', 'Evidence Lower BOund', 'ELBO']
","['known'] 
",0
"To elaborate, for any fixed value x and any distribution q(z) on the latent variables z (possibly dependent on x), the ELBO L(q, θ) is defined as
","['value x distribution q', 'z', 'latent variables', 'x', 'ELBO L', 'q', 'θ']
","['elaborate', 'fixed', 'z', 'possibly dependent', 'defined'] 
",1
"L(q, θ) = Ez∼q(z)[ln p(x|z, θ)]−KL(q(z)||p(z|θ)), (15)
","['L', 'q', 'θ', 'Ez∼q', 'z', 'ln p', 'θ', '−KL', 'q', 'z', '||p', 'z|θ']
","['=', '[', ']'] 
",1
"where KL(q||p) = Ez∼q(z)[ln(q(z)/p(z))] is the Kullback-Leibler (KL) divergence.
","['KL', 'q||p', '= Ez∼q', 'z', '[ ln', 'q', 'z', '/p', 'z', 'Kullback-Leibler', 'KL', 'divergence']
","[] 
",0
"The latter is a mea- sure of the distance between the two distributions, as we will further discuss in Sec.
","['The latter mea- sure distance', 'distributions', 'discuss Sec']
","[] 
",0
"V-D (see [59], [60]).
","['V-D', ']', ']']
","['see', '['] 
",1
"The analytical advantages of the ELBO L(q, θ) over the original log-likelihood are that: (i) it entails an expectation of the logarithm of the model p(x|z, θ), which, as mentioned, is typically a tractable function; and (ii) the average is over a fixed distribution q(z), which does not depend on the model parameter θ.
","['The analytical advantages ELBO L', 'q', 'θ', 'original log-likelihood', 'expectation logarithm model p', 'θ', 'tractable function', 'ii', 'average', 'distribution q', 'z', 'model parameter θ']
","['entails', 'mentioned', 'fixed', 'depend'] 
",1
"Using Jensen’s inequality, it can be seen that the ELBO (15) is a global lower bound on the log-likelihood function, that is,
","['Jensen ’ inequality', 'ELBO', 'log-likelihood function']
","['Using', 'seen'] 
",1
"ln p(x|θ) ≥ L(q, θ).
","['ln p', 'x|θ', 'L', 'q', 'θ']
","['≥'] 
",0
"(16)
","[]
","[] 
",0
"An illustration of the lower bounding property of the ELBO can be found in Fig.
","['An illustration', 'property ELBO', 'Fig']
","['lower bounding', 'found'] 
",1
"12.
","[]
","[] 
",0
"An important feature of this inequality is that the ELBO “touches” the log- likelihood function at values θ0, if any, for which the distribution q(z) satisfies the equality
","['An important feature inequality ELBO “ touches', 'log- likelihood function values θ0', 'distribution q', 'z', 'equality']
","['”', 'satisfies'] 
",1
"q(z) = p(z|x, θ0).
","['q', 'z', '= p', 'z|x', 'θ0']
","[] 
",0
"(17)
","[]
","[] 
",0
"In words, the ELBO is tight if the variational distribution is selected to equal the posterior distribution of the hidden variables given the observation x under the model parameter θ0.
","['words', 'ELBO', 'variational distribution', 'equal posterior distribution hidden variables', 'observation x model parameter θ0']
","['tight', 'selected', 'given'] 
",1
"Stated less formally, in order to ensure that the ELBO is tight at a value θ0, one needs to solve the problem of inferring the distribution of the hidden variables z given the observation x under the model identified by the value θ0.
","['order', 'ELBO', 'tight value θ0', 'solve problem', 'distribution hidden variables', 'observation x model', 'value θ0']
","['Stated', 'ensure', 'needs', 'inferring', 'given', 'identified'] 
",1
"The property (16) leads to the natural idea of the Expectation-Maximization (EM) algorithm as a means to tackle the ML problem.
","['The property', 'natural idea Expectation-Maximization', 'EM', 'algorithm', 'tackle ML problem']
","['leads', 'means'] 
",1
"As illustrated in Fig.
","['illustrated Fig']
","[] 
",0
"13, EM maximizes the ELBO iteratively, where the ELBO at each iteration is computed to be tight at the current iterate for θ.
","['EM', 'ELBO', 'ELBO iteration', 'tight current iterate θ']
","['maximizes', 'computed'] 
",1
"More formally, the EM algorithm can be summarized as follows5.
","['EM', 'follows5']
","['algorithm summarized'] 
",0
"The model vector is initialized to some value θold and then for each iteration the following two steps are performed.
","['The model vector', 'initialized value', 'iteration', 'steps']
","['θold', 'following', 'performed'] 
",1
"5EM is an instance of the more general Majorization-Minimization algorithm [61].
","['instance', 'general Majorization-Minimization algorithm', ']']
","['['] 
",0
"14
","[]
","[] 
",0
"-4 -3 -2 -1 0 1 2 3 4 -5
","['-4 -3 -2', '-5']
","['-1'] 
",0
"-4.5
","['-4.5']
","[] 
",0
"-4
","['-4']
","[] 
",0
"-3.5
","['-3.5']
","[] 
",0
"-3
","['-3']
","[] 
",0
"-2.5
","['-2.5']
","[] 
",0
"-2
","['-2']
","[] 
",0
"-1.5 L
","['-1.5 L']
","[] 
",0
"o g
","['g']
","[] 
",0
"-l ik
","['-l ik']
","[] 
",0
"e lih
","['e lih']
","[] 
",0
"o o
","[]
","[] 
",0
"d
","[]
","[] 
",0
"ELBO ( 0 =  3)
","['ELBO']
","[] 
",0
"ELBO ( 0  =  2)
","['ELBO']
","[] 
",0
"LL
","['LL']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"12.
","[]
","[] 
",0
"The ELBO (15) is a global lower bound on the log-likelihood that is tight at values of the model parameters θ0 for which equality (17) holds.
","['The ELBO', 'log-likelihood tight values', 'parameters', 'equality']
","['model', 'θ0', 'holds'] 
",1
"• Expectation, or E, step: For fixed parameter vector θold, solve the problem
","['• Expectation', 'E', 'step', 'parameter vector θold', 'solve problem']
","['fixed'] 
",0
"maximize q
","['q']
","['maximize'] 
",0
"L(q, θold).
","['L', 'q', 'θold']
","[] 
",0
"(18)
","[]
","[] 
",0
"The solution of this problem is given by qnew(z) = p(z|x, θold).
","['The solution problem', 'qnew', 'z', '= p', 'z|x', 'θold']
","['given'] 
",0
"In fact, as discussed, the tightest (i.e.-, largest) value of the ELBO is obtained by choosing the variational distribution q(z) as the posterior of the latent variables under the current model θold.
","['fact', 'value ELBO', 'variational distribution q', 'z', 'latent variables', 'current model θold']
","['discussed', 'obtained choosing'] 
",1
"This step can be interpreted as estimating the latent variables z, via the predictive distribution p(z|x, θold), assuming that the current model θold is correct.
","['This step', 'latent variables', 'predictive distribution p', 'z|x', 'θold', 'current model θold correct']
","['interpreted estimating', 'z', 'assuming'] 
",1
"• Maximization, or M, step: For fixed variational distribution qnew(z), solve the problem
","['• Maximization', 'M', 'step', 'variational distribution qnew', 'z', 'problem']
","['fixed', 'solve'] 
",1
"maximize θ
","['θ']
","['maximize'] 
",0
"L(qnew, θ) = Ez∼qnew(z) [ln p(x, z|θ)] .
","['L', 'θ', 'Ez∼qnew', 'z', 'ln p', 'z|θ', ']']
","['=', '['] 
",1
"(19)
","[]
","[] 
",0
"This optimization is akin to that carried out in the corresponding supervised learning problem with known latent variables z with the difference that these are randomly selected from the fixed varia- tional distribution qnew(z) obtained in the E step.
","['This optimization', 'learning problem', 'latent variables', 'difference', 'varia- tional distribution qnew', 'z', 'E step']
","['carried corresponding supervised', 'known', 'z', 'randomly selected fixed', 'obtained'] 
",1
"Given that the EM algorithm maximizes at each step a lower bound on the log-likelihood that is tight at the current iterate θold, EM guarantees decreasing objective values along the iterations, which ensures convergence to a local optimum of the original problem.
","['EM algorithm maximizes', 'log-likelihood tight current iterate θold', 'EM', 'objective values', 'iterations', 'convergence', 'local optimum original problem']
","['Given', 'step', 'guarantees decreasing', 'ensures'] 
",1
"We refer to [57], [58] for detailed examples.
","[']', ']', 'detailed examples']
","['refer', '['] 
",1
"The EM algorithm is generally impractical for large- scale problems due to the complexity of computing the posterior of the latent variables in the E step and of averaging over such distribution in the M step.
","['The EM algorithm', 'impractical large- scale problems', 'due complexity', 'posterior latent variables E step', 'distribution M step']
","['computing', 'averaging'] 
",1
"Many state-of-the-art solutions to the problem of unsupervised
","['Many state-of-the-art solutions problem']
","['unsupervised'] 
",0
"...
","[]
","[] 
",0
"LL
","['LL']
","[] 
",0
"newold
","['newold']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"13.
","[]
","[] 
",0
"Illustration of the EM algorithm: At each iteration, a tight ELBO is evaluated in the E step by solving the problem of estimating the latent variables (via the posterior distribution p(z|x, θ)), and then the ELBO is maximized in the M step by solving a problem akin to supervised learning with the estimated latent variables.
","['Illustration EM algorithm', 'iteration', 'tight ELBO', 'E step', 'problem', 'latent variables', 'posterior distribution p', 'z|x', 'θ', 'ELBO', 'M step', 'problem akin', 'latent variables']
","['evaluated', 'solving', 'estimating', 'maximized', 'solving', 'supervised learning estimated'] 
",1
"learning with probabilistic models entail some approxi- mation of the EM algorithm.
","['probabilistic models', 'approxi- mation EM algorithm']
","['learning', 'entail'] 
",1
"Notably, the E step can be approximated by parametrizing the variational distribu- tion with some function q(z|ϕ), or q(z|x, ϕ) to include the dependence on x, and by maximizing ELBO over the variational parameters ϕ.
","['E step', 'variational distribu- tion function q', 'z|ϕ', 'z|x', 'ϕ', 'dependence x', 'ELBO', 'variational parameters']
","['approximated parametrizing', 'include', 'maximizing', 'ϕ'] 
",1
"This approach underlies the popular variational autoencoder technique [7].
","['This approach', 'popular variational autoencoder technique', ']']
","['underlies', '['] 
",1
"In the M step, instead, one can approximate the expectation in (19) using Monte Carlo stochastic approximation based on randomly sampled values of z from the current distribution q(z).
","['M step', 'approximate expectation', 'Monte Carlo', 'stochastic approximation', 'values', 'current distribution q', 'z']
","['using', 'based randomly sampled', 'z'] 
",1
"Finally, gradient descent can be used to carry out the mentioned optimizations for both E and M steps (see, e.g.-, [62]).
","['gradient descent', 'carry', 'optimizations E M steps', ']']
","['used', 'mentioned', 'see'] 
",1
"D. Advanced Learning Methods
","['D. Advanced Learning Methods']
","[] 
",0
"As discussed in the previous section, ML is generally prone to overfitting for supervised learning.
","['previous section', 'ML', 'learning']
","['discussed', 'generally prone overfitting supervised'] 
",1
"For unsu- pervised learning, the performance of ML depends on the task of interest.
","['unsu- pervised learning', 'performance ML', 'task interest']
","['depends'] 
",0
"For example, consider the tasks of density estimation or of generation of new samples (see Sec.
","['example', 'tasks density estimation generation', 'new samples', 'Sec']
","['consider', 'see'] 
",1
"V-A).
","['V-A']
","[] 
",0
"In order to illustrate some of the typical issues encountered when applying the ML criterion, in Fig.
","['order illustrate', 'typical issues', 'ML criterion', 'Fig']
","['encountered applying'] 
",0
"14 we report a numerical result for a problem in which the true data distribution p(x) is multi-modal and the model distribution p(x|θ) is assumed to be a mixture of Gaussians, i.e.-, a directed generative model.
","['report', 'numerical result problem', 'true data distribution p', 'multi-modal model distribution p', 'x|θ', 'mixture', 'generative model']
","['assumed', 'directed'] 
",1
"The ML problem is tackled by using EM based on samples generated from the true distribution (see [19] for details).
","['The ML problem', 'EM', 'samples', 'true distribution', '] details']
","['tackled using', 'based', 'generated', 'see'] 
",1
"The learned distribution is seen to be a rather“blurry” estimate that misses the modes of p(x) in an attempt of being inclusive of the full support of p(x).
","['The learned distribution', '“ blurry', '” estimate misses modes', 'x', 'attempt', 'inclusive full support p', 'x']
","['seen', 'p'] 
",1
"Being a poor estimate of the true distribution, the learned model
","['poor estimate', 'true distribution', 'model']
","['Being', 'learned'] 
",1
"15
","[]
","[] 
",0
"-5 0 5 0
","[]
","[] 
",0
"0.05
","[]
","[] 
",0
"0.1
","[]
","[] 
",0
"0.15
","[]
","[] 
",0
"0.2
","[]
","[] 
",0
"0.25
","[]
","[] 
",0
"0.3
","[]
","[] 
",0
"0.35
","[]
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"14.
","[]
","[] 
",0
"Illustration of the limitations of ML unsupervised learning, here obtained via the EM algorithm: The ML solution tends to be blurry, missing the modes of the true distribution p(x).
","['Illustration limitations ML', 'learning', 'EM algorithm', 'The ML solution', 'blurry', 'modes', 'true distribution p', 'x']
","['unsupervised', 'obtained', 'tends', 'missing'] 
",1
"can clearly also be problematic for sample generation in the sense that samples generated from the model would tend to be quite different from the data samples.
","['problematic sample generation sense samples', 'model', 'different data samples']
","['generated', 'tend'] 
",1
"In the rest of this section, we briefly review advanced learning methods that address this limitation of ML.
","['rest section', 'briefly review', 'learning methods', 'address limitation ML']
","['advanced'] 
",0
"In order to move beyond ML, we first observe that ML can be proven to minimize the KL divergence
","['order move', 'ML', 'ML', 'KL divergence']
","['first observe', 'proven minimize'] 
",1
"KL(pD(x)||p(x|θ)) = Ez∼pD(x) [ ln pD(x)
","['KL', 'pD', 'x', '||p', 'x|θ', 'Ez∼pD', 'x', 'ln pD', 'x']
","['['] 
",0
"p(x|θ)
","['p', 'x|θ']
","[] 
",0
"] (20)
","[']']
","[] 
",0
"between the empirical distribution, or histogram, of the data
","['empirical distribution', 'histogram', 'data']
","[] 
",0
"pD(x) = N [x]
","['pD', 'x', 'N [ x ]']
","['='] 
",0
"N , (21)
","['N']
","[] 
",0
"where N [x] counts the number of occurrences of value x in the data, and the parameterized model distribution p(x|θ).
","['N [ x ]', 'number occurrences value x data', 'model distribution p', 'x|θ']
","['counts', 'parameterized'] 
",1
"In other words, ML fits the model to the his- togram of the data by using the KL divergence as a measure of fitness.
","['words', 'ML', 'his- togram data', 'KL divergence measure fitness']
","['fits', 'using'] 
",1
"Indeed, as mentioned in Sec.
","['Sec']
","['mentioned'] 
",0
"V-C, the KL divergence is a quantitative measure of “difference” between two distributions.
","['V-C', 'KL divergence', 'quantitative measure “ difference', 'distributions']
","[] 
",0
"More precisely, as per (20), the KL divergence KL(p||q) quantifies the difference between two distributions p(x) and q(x) by evaluating the average of the LLR ln(p(x)/q(x)) with respect to p(x).
","['KL divergence KL', 'p||q', 'difference', 'distributions', 'x', 'q', 'x', 'average LLR ln', 'p', 'x', '/q', 'x', 'respect p', 'x']
","['quantifies', 'p', 'evaluating'] 
",1
"Consider now the problem illustrated in Fig.
","['problem', 'Fig']
","['Consider', 'illustrated'] 
",1
"15, in which a discriminator wishes to distinguish between two hypotheses, namely the hypothesis that the data x is a sample from distribution p(x) and the hypothesis that it is instead generated from q(x).
","['discriminator wishes', 'hypotheses', 'hypothesis data', 'sample distribution p', 'x', 'hypothesis', 'q', 'x']
","['x', 'instead generated'] 
",1
"To fix the ideas, one can focus as an example on the case where p(x) and q(x) are two Gaussian distributions with different means.
","['ideas', 'focus example case p', 'x', 'q', 'Gaussian distributions', 'different means']
","['fix'] 
",0
"To this end, the discriminator computes a statistic, that is, a function, T (x) of the data x, and then decides for the former hypothesis if T (x) is sufficiently large and for
","['discriminator computes', 'function', 'T', 'x', 'data x', 'former hypothesis T', 'x']
","['end', 'decides'] 
",1
"𝑇(𝑥)
","['𝑇', '𝑥']
","[] 
",0
"𝑥~𝑝(𝑥)
","['𝑥~𝑝', '𝑥']
","[] 
",0
"𝑥~𝑞(𝑥)
","['𝑥~𝑞', '𝑥']
","[] 
",0
"𝑝 𝑥 if 𝑇 𝑥 large
","['𝑝 𝑥 𝑇 𝑥']
","[] 
",0
"discriminator
","['discriminator']
","[] 
",0
"𝑞 𝑥 if 𝑇 𝑥 small
","['𝑞 𝑥 𝑇 𝑥']
","[] 
",0
"Fig.
","['Fig']
","[] 
",0
"15.
","[]
","[] 
",0
"Discriminator between the hypotheses x ∼ p(x) and x ∼ q(x) based on the statistic T (x).
","['Discriminator', 'x ∼ p', 'x', '∼ q', 'x', 'statistic T', 'x']
","['hypotheses', 'x', 'based'] 
",1
"The performance of the optimal discriminator function T (x) under different design criteria yields a measure of the difference between the two distributions.
","['The performance', 'optimal discriminator function T', 'x', 'different design criteria yields measure difference', 'distributions']
","[] 
",0
"the latter hypothesis otherwise.
","['latter hypothesis']
","[] 
",0
"Intuitively, one should expect that, the more distinct the two distributions p(x) and q(x) are, the easier it is to design a discriminator that is able to choose the correct hypothesis with high probability.
","['expect', 'distributions', 'x', 'q', 'x', 'design discriminator', 'able choose correct hypothesis', 'high probability']
","['p'] 
",0
"The connection between the hypothesis testing prob- lem in Fig.
","['The connection hypothesis', 'prob- lem Fig']
","['testing'] 
",0
"15 and the KL divergence becomes evident if one recalls that the LLR ln(p(x)/q(x)) is known to be the best statistic T (x) in the Neyman-Pearson sense [63].
","['KL divergence', 'LLR ln', 'p', 'x', '/q', 'x', 'statistic T', 'x', 'Neyman-Pearson sense', ']']
","['becomes', 'recalls', 'known', '['] 
",1
"The KL divergence is hence associated to a particular way of evaluating the performance of the discriminator between the two distributions.
","['The KL divergence hence', 'particular way', 'performance discriminator', 'distributions']
","['associated', 'evaluating'] 
",1
"Considering a broader formulation of the problem of designing the discriminator in Fig.
","['formulation problem', 'discriminator Fig']
","['Considering', 'designing'] 
",1
"15, one can generalize the notion of KL divergence to the class of f -divergences.
","['generalize notion KL divergence class f -divergences']
","[] 
",0
"These are defined as
","[]
","['defined'] 
",0
"Df (p||q) = max T (x)
","['Df', 'p||q', 'max T', 'x']
","['='] 
",0
"Ex∼p(x)[T (x)]− Ex∼q(x)[g(T (x))], (22)
","['Ex∼p', 'x', 'T', 'x', '− Ex∼q', 'x', 'g', 'T', 'x', ']']
","['[', ']', '['] 
",1
"for some concave increasing function g(·).
","['function g', '·']
","['concave increasing'] 
",0
"The expres- sion above can be interpreted as measuring the perfor- mance of the best discriminator T (x) when the design criterion is given by the right-hand side of (22), i.e.-, Ex∼p(x)[T (x)] − Ex∼q(x)[g(T (x))], for a given function g(·).
","['The expres- sion', 'perfor- mance', 'discriminator T', 'x', 'design criterion', 'right-hand side', 'Ex∼p', 'x', 'T', 'x', '− Ex∼q', 'x', 'g', 'T', 'x', ']', 'function g', '·']
","['interpreted measuring', 'given', '[', ']', '[', 'given'] 
",1
"Note that this criterion is indeed larger for a discriminator that is able to output a large value of the statistic T (x) under p(x) and a small value under q(x).
","['Note criterion', 'discriminator', 'able output', 'large value', 'statistic T', 'x', 'p', 'x', 'small value q', 'x']
","[] 
",0
"The KL divergence corresponds to a specific choice of such function (see [19] for details).
","['The KL divergence corresponds', 'specific choice function', '] details']
","['see'] 
",0
"In order to move beyond ML, one can then consider fitting the model distribution to the data histogram by using a divergence measure that is tailored to the data and that captures the features of the empirical distribution that are most relevant for a given application.
","['order move', 'ML', 'consider', 'model distribution data histogram', 'divergence measure', 'data captures', 'empirical distribution', 'application']
","['fitting', 'using', 'tailored', 'features', 'relevant given'] 
",1
"Such a divergence measure can be obtained by choosing a suitable function g(·) in (22) and by optimizing (22) over a parameterized (differentiable) discriminator function Tϕ(x).
","['Such divergence measure', 'suitable function g', '·', 'optimizing', 'discriminator function Tϕ', 'x']
","['obtained choosing', 'parameterized'] 
",1
"Integrating the evaluation of the divergence with the problem of learning the model parameters yields the
","['evaluation divergence problem', 'model parameters yields']
","['Integrating', 'learning'] 
",1
"16
","[]
","[] 
",0
"min-max problem
","['min-max problem']
","[] 
",0
"min θ
","['min θ']
","[] 
",0
"max ϕ
","['max ϕ']
","[] 
",0
"Ex∼pD(x)[Tϕ(x)]− Ex∼p(x|θ)[g(Tϕ(x))].
","['Ex∼pD', 'x', 'Tϕ', 'x', '− Ex∼p', 'x|θ', 'g', 'Tϕ', 'x', ']']
","['[', ']', '['] 
",1
"(23)
","[]
","[] 
",0
"This can be famously interpreted as a game between the learner, which optimizes the model parameters θ, and the discriminator, which tries to find the best function Tϕ(x) to distinguish between data and generated samples.
","['interpreted game learner', 'model parameters', 'discriminator', 'function Tϕ', 'x', 'distinguish data', 'samples']
","['optimizes', 'θ', 'tries find', 'generated'] 
",1
"The resulting method, known as GAN, has recently led to impressive improvements of ML for sample generation [64].
","['method', 'GAN', 'impressive improvements ML sample generation', ']']
","['resulting', 'known', 'recently led', '['] 
",1
"VI.
","['VI']
","[] 
",0
"APPLICATIONS OF UNSUPERVISED LEARNING TO COMMUNICATION SYSTEMS
","['APPLICATIONS OF UNSUPERVISED LEARNING TO COMMUNICATION SYSTEMS']
","[] 
",0
"In this section, we highlight some applications of unsupervised learning to communication networks.
","['section', 'highlight applications', 'communication networks']
","['unsupervised learning'] 
",0
"A.
","[]
","[] 
",0
"At the Edge
","['Edge']
","[] 
",0
"1) Physical Layer: Let us first consider some appli- cations of autoencoders at the physical layer as imple- mented by the network edge nodes.
","['Physical Layer', 'appli- cations autoencoders', 'physical layer imple-', 'network edge nodes']
","['Let', 'consider', 'mented'] 
",1
"A fundamental idea is to treat the chain of encoder, channel, and decoder in a communication link as an autoencoder, where, with reference to Fig.
","['A fundamental idea treat chain encoder', 'channel', 'decoder communication link autoencoder', 'reference Fig']
","[] 
",0
"11(d), the input message is x, the transmitted codewords and received signals represent the intermediate representation z, and the output of the decoder should match the input [30].
","['input message x', 'transmitted codewords', 'signals', 'intermediate representation z', 'output decoder match input', ']']
","['received', 'represent', '['] 
",1
"Note that, for this particular autoencoder, the mapping p(x|z) can only be partially learned, as it includes not only the encoder but also the communication channel, while the conditional distribution p(x|z) defining the decoder can be learned.
","['Note', 'particular autoencoder', 'p', 'x|z', 'encoder', 'communication channel', 'conditional distribution p', 'x|z', 'decoder']
","['mapping', 'partially learned', 'includes', 'defining', 'learned'] 
",1
"We should now ask when this viewpoint can be beneficial in light of the criteria reviewed in Sec.
","['viewpoint beneficial light criteria', 'Sec']
","['ask', 'reviewed'] 
",1
"I-C.
","['I-C']
","[] 
",0
"To address this question, one should check whether a model or algorithm deficit exists to justify the use of machine learning tools.
","['question', 'check', 'model algorithm deficit', 'justify use machine learning tools']
","['address', 'exists'] 
",1
"Training an autoencoder requires the availability of a model for the channel, and hence a model deficit would make this approach inapplicable unless further mechanisms are put in place (see below).
","['autoencoder', 'availability model channel', 'model deficit', 'approach', 'mechanisms', 'place']
","['Training', 'requires', 'make', 'put', 'see'] 
",1
"Examples of algorithm deficit include channels with complex non-linear dynamical models, such as optical links [65]; Gaussian channels with feedback, for which optimal practical encoding schemes are not known [66]; multiple access channels with sparse transmission codes [67]; and joint source-channel coding [68].
","['Examples', 'deficit', 'channels', 'complex non-linear dynamical models', 'optical links', ']', 'Gaussian channels feedback', 'schemes', ']', 'multiple access channels', 'transmission codes', ']', 'joint source-channel', ']']
","['algorithm', 'include', '[', 'encoding', 'known', 'sparse', '[', 'coding'] 
",1
"Other applications at the physical layer leverage the use of autoencoders as compressors (see Sec.
","['Other applications', 'physical layer leverage use autoencoders compressors', 'Sec']
","['see'] 
",0
"V-B) or denoisers.
","['V-B', 'denoisers']
","[] 
",0
"For channels with a complex structure with unavailable channel models or with unknown optimal compression algorithms, autoencoders can be used to compress channel state information for the purpose of feedback on frequency-division duplex links [69].
","['channels', 'complex structure', 'unavailable channel models', 'optimal compression algorithms', 'autoencoders', 'compress channel state information', 'purpose feedback frequency-division', 'duplex links', ']']
","['used', '['] 
",1
"Autoencoders can also be used for their capacity to denoise the input signal by means of filtering through the lower dimensional representation z.
","['Autoencoders', 'capacity denoise', 'signal means', 'dimensional representation z']
","['also used', 'input', 'filtering'] 
",1
"This is done in [70] for the task of localization on the basis of the received baseband signal.
","['[', '] task localization basis', 'baseband signal']
","['done', 'received'] 
",1
"To this end, an autoencoder is learned for every reference position in space with the objective of denoising signals received from the given location.
","['autoencoder', 'every reference position space', 'objective denoising signals', 'location']
","['end', 'learned', 'received given'] 
",1
"At test time, the location that corresponds to the autoencoder with the smallest reconstruction error is taken as an estimate of the unknown transmitting device.
","['test time', 'location corresponds', 'reconstruction error', 'estimate', 'device']
","['autoencoder', 'taken', 'transmitting'] 
",1
"We now review some applications of the generative models illustrated in Fig.
","['applications', 'generative models', 'Fig']
","['review', 'illustrated'] 
",1
"11(a).
","[]
","[] 
",0
"A natural idea is that of using generative models to learn how to generate samples from a given channel [71], [72].
","['A natural idea', 'generative models', 'generate samples', 'channel', ']', ']']
","['using', 'learn', 'given', '['] 
",1
"This approach is sound for scenarios that lack tractable channel models.
","['This approach', 'scenarios', 'tractable channel models']
","['sound', 'lack'] 
",1
"As a pertinent example, generative models can be used to mimic and identify non-linear channels for satellite com- munications [2].
","['pertinent example', 'generative models', 'mimic identify non-linear channels', 'com- munications', ']']
","['used', 'satellite', '['] 
",1
"The early works on the subject carried out in the nineties are also notable for the integration of the domain knowledge into the definition of machine learning models (see Sec.
","['The early works', 'nineties', 'notable integration domain knowledge definition machine learning models', 'Sec']
","['carried', 'see'] 
",1
"IV).
","['IV']
","[] 
",0
"In fact, mindful of the strong linear components of the channels, these works posit a learnable model that includes linear filters and non-linearities [2].
","['fact', 'mindful strong linear components channels', 'posit', 'learnable model', 'linear filters non-linearities', ']']
","['works', 'includes', '['] 
",1
"Another approach that can be considered as unsu- pervised was proposed in [73] in order to solve the challenging problem of power control for interference channels.
","['Another approach', 'unsu- pervised', '] order solve', 'problem power control interference channels']
","['considered', 'proposed', 'challenging'] 
",1
"The approach tackles the resulting algorithm deficit by means of a direct optimization of the sum-rate with the aim of obtaining the power allocation vector (as fractions of the maximal available powers) at the output of a neural network.
","['The approach', 'algorithm deficit', 'direct optimization', 'sum-rate aim', 'power allocation vector', 'fractions', 'available powers', 'output', 'neural network']
","['tackles resulting', 'means', 'obtaining', 'maximal'] 
",1
"Related supervised learning methods were discussed in Sec.
","['methods', 'Sec']
","['Related supervised learning', 'discussed'] 
",1
"IV.
","['IV']
","[] 
",0
"A similar approach – also based on the idea of directly maximizing the criterion of interest so as to obtain an approximate solution at the output of a neural network – was considered in [74] for minimum mean squared error channel estimation with non-Gaussian channels, e.g.-, multi-path channels.
","['A similar approach –', 'idea', 'criterion interest', 'approximate solution output', 'neural network –', ']', 'minimum mean', 'error channel estimation', 'non-Gaussian channels', 'multi-path channels']
","['also based', 'directly maximizing', 'obtain', 'considered', 'squared'] 
",1
"2) Medium Access Layer: At the medium access layer, generative models have been advocated in [75] as a way to generate new examples so as to augment a data set used to train a classifier for spectrum sensing (see Sec.
","['Medium Access Layer', 'medium access layer', 'generative models', '] way', 'new examples', 'augment data set', 'train classifier spectrum sensing', 'Sec']
","['advocated', 'generate', 'used', 'see'] 
",1
"IV).
","['IV']
","[] 
",0
"An unsupervised learning task that has found many applications in communications is clustering.
","['An unsupervised learning task', 'many applications communications']
","['found', 'clustering'] 
",1
"For example, in [76], clustering is used to support radio resource allocation in a heterogeneous network.
","['example', ']', 'support radio resource allocation', 'heterogeneous network']
","['[', 'clustering used'] 
",1
"B.
","['B']
","[] 
",0
"At the Cloud
","['Cloud']
","[] 
",0
"1) Network Layer: Another typical application of clustering is to enable hierarchical clustering for routing in self-organizing multi-hop networks.
","['Network Layer', 'Another typical application', 'self-organizing multi-hop networks']
","['clustering', 'clustering routing'] 
",1
"Thanks to cluster- ing, routing can be carried out more efficiently by routing
","['Thanks', 'cluster- ing']
","['routing carried', 'efficiently routing'] 
",1
"17
","[]
","[] 
",0
"first at the level of clusters, and then locally within each cluster [77].
","['level clusters', 'cluster', ']']
","['['] 
",0
"For an application of the unsupervised learning task of density estimation, consider the problem of detecting anomalies in networks.
","['application', 'unsupervised learning task density estimation', 'problem', 'anomalies networks']
","['consider', 'detecting'] 
",1
"For instance, by learning the typical distribution of the features of a working link, one can identify malfunctioning ones.
","['instance', 'typical distribution features', 'link', 'identify', 'ones']
","['learning', 'working', 'malfunctioning'] 
",1
"This approach may be applied, e.g.-, to optical networks [54].
","['This approach', 'optical networks', ']']
","['applied', '['] 
",1
"2) Application Layer: Finally, we point to two in- stances of unsupervised learning at the application layer that are usually carried out at data centers in the cloud.
","['Application Layer', 'point', 'in- stances', 'application layer', 'data centers']
","['unsupervised learning', 'usually carried', 'cloud'] 
",1
"These tasks follow a conceptually different approach as they are based on discovering structure in graphs.
","['These tasks', 'different approach', 'discovering structure graphs']
","['follow', 'based'] 
",1
"The first problem is community detection in social networks.
","['The first problem community detection', 'social networks']
","[] 
",0
"This amounts to a clustering problem whereby one wishes to isolate communities of nodes in a social graph on the basis of the observation of a realization of the underlying true graph of relationships [78].
","['problem', 'isolate communities', 'social graph basis observation realization', 'true graph relationships', ']']
","['amounts clustering', 'wishes', 'underlying', '['] 
",1
"Another application is the ranking of webpages based on the graph of hyperlinks carried out by PageRank [19], [79].
","['Another application', 'webpages', 'graph hyperlinks', 'PageRank [', ']', ']']
","['ranking', 'based', 'carried', '['] 
",1
"VII.
","['VII']
","[] 
",0
"CONCLUDING REMARKS
","['CONCLUDING REMARKS']
","[] 
",0
"In the presence of modelling or algorithmic deficien- cies in the conventional engineering flow based on the acquisition of domain knowledge, data-driven machine learning tools can speed up the design cycle, reduce the complexity and cost of implementation, and improve over the performance of known algorithms.
","['presence', 'algorithmic deficien- cies', 'conventional engineering flow', 'acquisition domain knowledge', 'data-driven machine learning tools', 'design cycle', 'complexity cost implementation', 'performance', 'algorithms']
","['modelling', 'based', 'speed', 'reduce', 'improve', 'known'] 
",1
"To this end, machine learning can leverage the availability of data and computing resources in many engineering domains, including modern communication systems.
","['machine learning leverage availability data', 'resources', 'many engineering domains', 'modern communication systems']
","['end', 'computing', 'including'] 
",1
"Supervised, unsupervised, and reinforcement learning paradigms lend themselves to different tasks depending on the availabil- ity of examples of desired behaviour or of feedback.
","['different tasks', 'availabil- ity examples', 'behaviour feedback']
","['Supervised', 'learning', 'lend', 'depending', 'desired'] 
",1
"The applicability of learning methods hinges on specific features of the problem under study, including its time variability and its tolerance to errors.
","['The applicability', 'methods hinges', 'specific features problem study', 'time variability tolerance errors']
","['learning', 'including'] 
",1
"As such, a data- driven approach should not be considered as a universal solution, but rather as a useful tool whose suitability should be assessed on a case-by-case basis.
","['data- driven approach', 'universal solution', 'useful tool', 'suitability', 'case-by-case basis']
","['considered', 'assessed'] 
",1
"Further- more, machine learning tools allow for the integration of traditional model-based engineering techniques and of existing domain knowledge in order to leverage the complementarity and synergy of the two solutions (see Fig.
","['Further-', 'machine learning tools', 'integration', 'traditional model-based engineering techniques', 'domain knowledge order leverage complementarity', 'solutions', 'Fig']
","['allow', 'existing', 'synergy', 'see'] 
",1
"2).
","[]
","[] 
",0
"As a final note, while this paper has focused on appli- cations of machine learning to communication systems, communication is conversely a key element of distributed machine learning platforms.
","['final note', 'paper', 'appli- cations machine', 'communication systems', 'communication', 'key element', 'machine', 'platforms']
","['focused', 'learning', 'distributed', 'learning'] 
",1
"In these systems, learning tasks are carried out at distributed machines that need to coordinate via communication, e.g.-, by transferring the results of intermediate computations.
","['systems', 'tasks', 'distributed machines', 'communication', 'results', 'intermediate computations']
","['learning', 'carried', 'need', 'transferring'] 
",1
"A recent line
","['A recent line']
","[] 
",0
"of work investigates the resulting interplay between computation and communication [80].
","['work investigates', 'interplay computation communication', ']']
","['resulting', '['] 
",1
"REFERENCES [1] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed,
","['REFERENCES', '] G. Hinton', 'L. Deng', 'D. Yu', 'G. E. Dahl', 'A.-r. Mohamed']
","['['] 
",0
"N. Jaitly, A.
","['N. Jaitly', 'A']
","[] 
",0
"Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al., “Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups,” IEEE Signal processing magazine, vol.
","['Senior', 'V. Vanhoucke', 'P. Nguyen', 'T. N. Sainath', 'al.', '“ Deep', 'neural networks', 'speech recognition', 'views', 'research groups', '” IEEE Signal processing magazine', 'vol']
","['modeling', 'shared'] 
",1
"29, no.
","[]
","[] 
",0
"6, pp.
","['pp']
","[] 
",0
"82–97, 2012.
","[]
","[] 
",0
"[2] M. Ibnkahla, “Applications of neural networks to digital communications–a survey,” Signal processing, vol.
","['] M. Ibnkahla', '“ Applications', 'neural networks', 'digital communications–a survey', '” Signal processing', 'vol']
","[] 
",0
"80, no.
","[]
","[] 
",0
"7, pp.
","['pp']
","[] 
",0
"1185–1215, 2000.
","[]
","[] 
",0
"[3] H. J. Levesque, Common Sense, the Turing Test, and the Quest for Real AI: Reflections on Natural and Artificial Intelligence.
","['] H. J. Levesque', 'Common Sense', 'Turing Test', 'Quest Real AI', 'Reflections Natural Artificial Intelligence']
","[] 
",0
"MIT Press, 2017.
","['MIT Press']
","[] 
",0
"[4] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning internal representations by error propagation,” California Univ San Diego La Jolla Inst for Cognitive Science, Tech.
","['] D. E. Rumelhart', 'G. E. Hinton', 'R. J. Williams', '“ Learning', 'internal representations', 'propagation', '” California Univ San Diego La Jolla Inst Cognitive Science', 'Tech']
","['error'] 
",0
"Rep., 1985.
","['Rep.']
","[] 
",0
"[5] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum likelihood from incomplete data via the em algorithm,” Journal of the royal statistical society.
","['] A. P. Dempster', 'N. M. Laird', 'D. B. Rubin', '“ Maximum', 'incomplete data', 'em algorithm', '” Journal', 'statistical society']
","['likelihood', 'royal'] 
",1
"Series B (methodological), pp.
","['Series B', 'pp']
","[] 
",0
"1–38, 1977.
","[]
","[] 
",0
"[6] C. Watkins, “Learning form delayed rewards,” Ph.
","['] C. Watkins', '“ Learning form delayed rewards', '” Ph']
","[] 
",0
"D. thesis, King’s College, University of Cambridge, 1989.
","['D. thesis', 'King ’ College', 'University Cambridge']
","[] 
",0
"[7] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning.
","['] I. Goodfellow', 'Y. Bengio', 'A. Courville', 'Y. Bengio', 'Deep learning']
","[] 
",0
"MIT press Cambridge, 2016, vol.
","['MIT press Cambridge', 'vol']
","[] 
",0
"1.
","[]
","[] 
",0
"[8] J. Pearl and D. Mackenzie, The Book of Why: The New Science of Cause and Effect.
","['] J. Pearl D. Mackenzie', 'The Book', 'The New Science Cause Effect']
","[] 
",0
"Basic Books, 2018.
","['Basic Books']
","[] 
",0
"[9] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, “Machine learning in wireless sensor networks: Algorithms, strategies, and applications,” IEEE Communications Surveys & Tutorials, vol.
","['] M. A. Alsheikh', 'S. Lin', 'D. Niyato', 'H.-P. Tan', '“ Machine', 'wireless sensor networks', 'Algorithms', 'strategies', 'applications', '” IEEE Communications Surveys', 'Tutorials', 'vol']
","['learning'] 
",0
"16, no.
","[]
","[] 
",0
"4, pp.
","['pp']
","[] 
",0
"1996–2018, 2014.
","[]
","[] 
",0
"[10] C. Jiang, H. Zhang, Y. Ren, Z. Han, K.-C. Chen, and L. Hanzo, “Machine learning paradigms for next-generation wireless net- works,” IEEE Wireless Communications, vol.
","['] C. Jiang', 'H. Zhang', 'Y. Ren', 'Z. Han', 'K.-C. Chen', 'L. Hanzo', '“ Machine', 'paradigms next-generation wireless', 'net- works', '” IEEE Wireless Communications', 'vol']
","['learning'] 
",0
"24, no.
","[]
","[] 
",0
"2, pp.
","['pp']
","[] 
",0
"98– 105, 2017.
","[]
","[] 
",0
"[11] Z. Qin, H. Ye, G. Y. Li, and B.-H. F. Juang, “Deep Learning in Physical Layer Communications,” ArXiv e-prints, Jul.
","['] Z. Qin', 'H. Ye', 'G. Y. Li', 'B.-H. F. Juang', '“ Deep Learning Physical Layer Communications', '” ArXiv e-prints', 'Jul']
","[] 
",0
"2018.
","[]
","[] 
",0
"[12] S. Lin and D. J. Costello, Error control coding.
","['] S. Lin D. J. Costello', 'Error control coding']
","[] 
",0
"Pearson Education India, 2001.
","['Pearson Education India']
","[] 
",0
"[13] T. Gruber, S. Cammerer, J. Hoydis, and S. ten Brink, “On deep learning-based channel decoding,” in CISS 2017, 2017, pp.
","['] T. Gruber', 'S. Cammerer', 'J. Hoydis', 'S.', 'Brink', '“', 'deep learning-based channel decoding', '” CISS', 'pp']
","['ten'] 
",0
"1–6.
","[]
","[] 
",0
"[14] S. Shalev-Shwartz and S. Ben-David, Understanding machine learning: From theory to algorithms.
","['] S. Shalev-Shwartz S. Ben-David', 'Understanding machine learning', 'theory algorithms']
","[] 
",0
"Cambridge university press, 2014.
","['Cambridge university press']
","[] 
",0
"[15] D. Arpit, S. Jastrzȩbski, N. Ballas, D. Krueger, E. Bengio, M. S. Kanwal, T. Maharaj, A. Fischer, A. Courville, Y. Bengio, and S. Lacoste-Julien, “A Closer Look at Memorization in Deep Networks,” ArXiv e-prints, Jun.
","['] D. Arpit', 'S. Jastrzȩbski', 'N. Ballas', 'D. Krueger', 'E. Bengio', 'M. S. Kanwal', 'T. Maharaj', 'A. Fischer', 'A. Courville', 'Y. Bengio', 'S. Lacoste-Julien', 'A Closer Look Memorization Deep Networks', '” ArXiv e-prints', 'Jun']
","['“'] 
",0
"2017.
","[]
","[] 
",0
"[16] T. Hastie, R. Tibshirani, and J. Friedman, “Unsupervised learn- ing,” in The elements of statistical learning.
","['] T. Hastie', 'R. Tibshirani', 'J. Friedman', '“', 'learn- ing', 'The elements', 'statistical learning']
","['Unsupervised', '”'] 
",1
"Springer, 2009, pp.
","['Springer', 'pp']
","[] 
",0
"485–585.
","[]
","[] 
",0
"[17] R. S. Sutton, A. G. Barto et al., Reinforcement learning: An introduction.
","['] R. S. Sutton', 'A. G. Barto', 'al.', 'Reinforcement learning', 'An introduction']
","[] 
",0
"MIT press, 2018.
","['MIT press']
","[] 
",0
"[18] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershel- vam, M. Lanctot et al., “Mastering the game of go with deep neural networks and tree search,” Nature, vol.
","['] D. Silver', 'A. Huang', 'C. J. Maddison', 'A. Guez', 'L. Sifre', 'G. Van Den Driessche', 'J. Schrittwieser', 'I. Antonoglou', 'V. Panneershel- vam', 'M. Lanctot', 'al.', '“ Mastering game', 'deep neural networks', 'search', '” Nature', 'vol']
","['go', 'tree'] 
",1
"529, no.
","[]
","[] 
",0
"7587, p. 484, 2016.
","[]
","['p.'] 
",0
"[19] O. Simeone, “A brief introduction to machine learning for en- gineers,” Foundations and Trends in Signal Processing, vol.
","['] O. Simeone', 'A', 'brief introduction machine', 'en- gineers', '” Foundations Trends Signal Processing', 'vol']
","['“', 'learning'] 
",1
"12, no.
","[]
","[] 
",0
"3-4, pp.
","['pp']
","[] 
",0
"200–431, 2018.
","[]
","[] 
",0
"[20] E. Brynjolfsson and T. Mitchell, “What can machine learning do?
","['] E. Brynjolfsson T. Mitchell', 'machine learning']
","['“'] 
",0
"Workforce implications,” Science, vol.
","['Workforce implications', '” Science', 'vol']
","[] 
",0
"358, no.
","[]
","[] 
",0
"6370, pp.
","['pp']
","[] 
",0
"1530–1534, 2017.
","[]
","[] 
",0
"18
","[]
","[] 
",0
"[21] S. Kannan, H. Kim, and S. Oh, “Deep learning and information theory: An emerging interface,” IEEE ISIT 2018 Tutorial.
","['] S. Kannan', 'H. Kim', 'S. Oh', '“ Deep', 'information theory', 'interface', '” IEEE ISIT', 'Tutorial']
","['learning', 'emerging'] 
",1
"[22] M. Davies, N. Srinivasa, T.-H. Lin, G. Chinya, Y. Cao, S. H. Choday, G. Dimou, P. Joshi, N. Imam, S. Jain et al., “Loihi: A neuromorphic manycore processor with on-chip learning,” IEEE Micro, vol.
","['] M. Davies', 'N. Srinivasa', 'T.-H. Lin', 'G. Chinya', 'Y. Cao', 'S. H. Choday', 'G. Dimou', 'P. Joshi', 'N. Imam', 'S. Jain', 'al.', '“ Loihi', 'A neuromorphic manycore processor', 'on-chip learning', '” IEEE Micro', 'vol']
","[] 
",0
"38, no.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"82–99, 2018.
","[]
","[] 
",0
"[23] A. Bagheri, O. Simeone, and B. Rajendran, “Training proba- bilistic spiking neural networks with first-to-spike decoding,” arXiv preprint arXiv:1710.10704, 2017.
","['] A. Bagheri', 'O. Simeone', 'B. Rajendran', '“ Training', 'neural networks', 'first-to-spike decoding', '”', 'preprint arXiv:1710.10704']
","['spiking', 'arXiv'] 
",1
"[24] J. Chen, L. Song, M. J. Wainwright, and M. I. Jordan, “Learn- ing to explain: An information-theoretic perspective on model interpretation,” arXiv preprint arXiv:1802.07814, 2018.
","['] J. Chen', 'L. Song', 'M. J. Wainwright', 'M. I. Jordan', '“ Learn-', 'explain', 'An information-theoretic perspective model interpretation', '”', 'preprint arXiv:1802.07814']
","['ing', 'arXiv'] 
",1
"[25] M. Polese, R. Jana, V. Kounev, K. Zhang, S. Deb, and M. Zorzi, “Machine Learning at the Edge: A Data-Driven Architecture with Applications to 5G Cellular Networks,” ArXiv e-prints, Aug. 2018.
","['] M. Polese', 'R. Jana', 'V. Kounev', 'K. Zhang', 'S. Deb', 'M. Zorzi', '“ Machine Learning Edge', 'A Data-Driven Architecture Applications', 'Cellular Networks', '” ArXiv e-prints', 'Aug.']
","[] 
",0
"[26] G. Paschos, E. Bastug, I.
","['] G. Paschos', 'E. Bastug']
","[] 
",0
"Land, G. Caire, and M. Debbah, “Wireless caching: Technical misconceptions and business bar- riers,” IEEE Communications Magazine, vol.
","['Land', 'G. Caire', 'M. Debbah', '“ Wireless caching', 'Technical misconceptions business bar- riers', '” IEEE Communications Magazine', 'vol']
","[] 
",0
"54, no.
","[]
","[] 
",0
"8, pp.
","['pp']
","[] 
",0
"16– 22, 2016.
","[]
","[] 
",0
"[27] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Machine learning for wireless networks with artificial in- telligence: A tutorial on neural networks,” arXiv preprint arXiv:1710.02913, 2017.
","['] M. Chen', 'U. Challita', 'W. Saad', 'C. Yin', 'M. Debbah', '“ Machine', 'wireless networks', 'artificial in- telligence', 'A tutorial neural networks', '”', 'preprint arXiv:1710.02913']
","['learning', 'arXiv'] 
",1
"[28] M. Angjelichinoski, K. F. Trillingsgaard, and P. Popovski, “A statistical learning approach to ultra-reliable low latency communication,” arXiv preprint arXiv:1809.05515, 2018.
","['] M. Angjelichinoski', 'K. F. Trillingsgaard', 'P. Popovski', 'A', 'statistical learning approach', 'ultra-reliable low latency communication', '”', 'preprint arXiv:1809.05515']
","['“', 'arXiv'] 
",1
"[29] M. Seeger, “A taxonomy for semi-supervised learning methods,” MIT Press, Tech.
","['] M. Seeger', 'A taxonomy semi-supervised learning methods', '” MIT Press', 'Tech']
","['“'] 
",0
"Rep., 2006.
","['Rep.']
","[] 
",0
"[30] T. J. O’Shea and J. Hoydis, “An introduction to machine learning communications systems,” arXiv preprint, vol.
","['] T. J. O ’ Shea J. Hoydis', '“', 'An introduction machine', 'communications systems', '” arXiv preprint', 'vol']
","['learning'] 
",0
"1702, 2017.
","[]
","[] 
",0
"[31] N. Farsad and A. Goldsmith, “Neural network detection of data sequences in communication systems,” arXiv preprint arXiv:1802.02046, 2018.
","['] N. Farsad A. Goldsmith', '“ Neural network detection data sequences communication systems', '” arXiv preprint arXiv:1802.02046']
","[] 
",0
"[32] S. Bouchired, D. Roviras, and F. Castanié, “Equalisation of satellite mobile channels with neural network techniques,” Space Communications, vol.
","['] S. Bouchired', 'D. Roviras', 'F. Castanié', '“ Equalisation satellite mobile channels', 'neural network techniques', '” Space Communications', 'vol']
","[] 
",0
"15, no.
","[]
","[] 
",0
"4, pp.
","['pp']
","[] 
",0
"209–220, 1998.
","[]
","[] 
",0
"[33] Y. Wang, M. Martonosi, and L.-S. Peh, “A supervised learning approach for routing optimizations in wireless sensor networks,” in Proc.
","['] Y. Wang', 'M. Martonosi', 'L.-S. Peh', 'A', 'approach', 'optimizations wireless sensor networks', '” Proc']
","['“', 'supervised learning', 'routing'] 
",1
"Int.
","['Int']
","[] 
",0
"Workshop on Multi-hop ad hoc Networks.
","['Workshop Multi-hop ad hoc Networks']
","[] 
",0
"ACM, 2006, pp.
","['ACM', 'pp']
","[] 
",0
"79–86.
","[]
","[] 
",0
"[34] G. De Veciana and A. Zakhor, “Neural net-based continuous phase modulation receivers,” IEEE Transactions on Communi- cations, vol.
","['] G. De Veciana A. Zakhor', '“ Neural', 'net-based continuous phase modulation receivers', '” IEEE Transactions Communi- cations', 'vol']
","[] 
",0
"40, no.
","[]
","[] 
",0
"8, pp.
","['pp']
","[] 
",0
"1396–1408, 1992.
","[]
","[] 
",0
"[35] X. Jin and H.-N. Kim, “Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels,” ArXiv e-prints, Jul.
","['] X. Jin H.-N. Kim', '“ Deep Learning Detection Networks MIMO Decode-Forward Relay Channels', '” ArXiv e-prints', 'Jul']
","[] 
",0
"2018.
","[]
","[] 
",0
"[36] E. Nachmani, E. Marciano, L. Lugosch, W. J.
","['] E. Nachmani', 'E. Marciano', 'L. Lugosch', 'W. J']
","[] 
",0
"Gross, D. Bur- shtein, and Y. Be’ery, “Deep learning methods for improved decoding of linear codes,” IEEE Journal of Selected Topics in Signal Processing, vol.
","['Gross', 'D. Bur- shtein', 'Y. Be', '’ ery', '“ Deep learning methods', 'linear codes', '” IEEE Journal Selected Topics Signal Processing', 'vol']
","['improved decoding'] 
",0
"12, no.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"119–131, 2018.
","[]
","[] 
",0
"[37] L. Lugosch and W. J.
","['] L. Lugosch W. J']
","[] 
",0
"Gross, “Neural offset min-sum decoding,” in IEEE int.
","['Gross', '“ Neural', 'min-sum decoding', '” IEEE int']
","['offset'] 
",0
"Symp.
","['Symp']
","[] 
",0
"Information Theory (ISIT 2017).
","['Information Theory', 'ISIT']
","[] 
",0
"IEEE, 2017, pp.
","['IEEE', 'pp']
","[] 
",0
"1361–1365.
","[]
","[] 
",0
"[38] S. Cammerer, T. Gruber, J. Hoydis, and S. ten Brink, “Scaling deep learning-based decoding of polar codes via partitioning,” in IEEE GLOBECOM 2017, 2017, pp.
","['] S. Cammerer', 'T. Gruber', 'J. Hoydis', 'S.', 'Brink', '“ Scaling', 'polar codes', 'partitioning', '” IEEE GLOBECOM', 'pp']
","['ten', 'decoding'] 
",1
"1–6.
","[]
","[] 
",0
"[39] S. Schibisch, S. Cammerer, S. Dörner, J. Hoydis, and S. t. Brink, “Online label recovery for deep learning-based com- munication through error correcting codes,” arXiv preprint arXiv:1807.00747, 2018.
","['] S. Schibisch', 'S. Cammerer', 'S. Dörner', 'J. Hoydis', 'S. t. Brink', '“ Online label recovery', 'deep learning-based com- munication error', 'codes', '”', 'preprint arXiv:1807.00747']
","['correcting', 'arXiv'] 
",1
"[40] F. Liang, C. Shen, and F. Wu, “An iterative bp-cnn architecture for channel decoding,” IEEE Journal of Selected Topics in Signal Processing, vol.
","['] F. Liang', 'C. Shen', 'F. Wu', '“', 'An iterative bp-cnn architecture channel decoding', '” IEEE Journal Selected Topics Signal Processing', 'vol']
","[] 
",0
"12, no.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"144–159, Feb 2018.
","['Feb']
","[] 
",0
"[41] H. Agirman-Tosun, Y. Liu, A. M. Haimovich, O. Simeone, W. Su, J. Dabin, and E. Kanterakis, “Modulation classification of mimo-ofdm signals by independent component analysis and support vector machines,” in Proc.
","['] H. Agirman-Tosun', 'Y. Liu', 'A. M. Haimovich', 'O. Simeone', 'W. Su', 'J. Dabin', 'E. Kanterakis', '“ Modulation classification mimo-ofdm signals', 'independent component analysis support vector machines', '” Proc']
","[] 
",0
"ASILOMAR 2011, 2011, pp.
","['ASILOMAR', 'pp']
","[] 
",0
"1903–1907.
","[]
","[] 
",0
"[42] S.-H. Fang and T.-N. Lin, “Indoor location system based on discriminant-adaptive neural network in ieee 802.11 environ- ments,” IEEE Transactions on Neural networks, vol.
","['] S.-H. Fang T.-N. Lin', '“ Indoor location system', 'discriminant-adaptive neural network', 'environ- ments', '” IEEE Transactions Neural networks', 'vol']
","['based'] 
",0
"19, no.
","[]
","[] 
",0
"11, pp.
","['pp']
","[] 
",0
"1973–1978, 2008.
","[]
","[] 
",0
"[43] Q. Wang, H. Li, Z. Chen, D. Zhao, S. Ye, and J. Cai, “Su- pervised and Semi-Supervised Deep Neural Networks for CSI- Based Authentication,” ArXiv e-prints, Jul.
","['] Q. Wang', 'H. Li', 'Z. Chen', 'D. Zhao', 'S. Ye', 'J. Cai', '“ Su-', 'Semi-Supervised Deep Neural Networks CSI-', 'Authentication', '” ArXiv e-prints', 'Jul']
","['pervised', 'Based'] 
",1
"2018.
","[]
","[] 
",0
"[44] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropou- los, “Learning to optimize: Training deep neural networks for wireless resource management,” in IEEE Signal Processing Advances in Wireless Communications (SPAWC) 2017, 2017, pp.
","['] H. Sun', 'X. Chen', 'Q. Shi', 'M. Hong', 'X. Fu', 'N. D. Sidiropou- los', '“ Learning optimize', 'Training', 'deep neural networks', 'resource management', '” IEEE Signal Processing Advances Wireless Communications', 'SPAWC', 'pp']
","['wireless'] 
",0
"1–6.
","[]
","[] 
",0
"[45] A. Zappone, M. Di Renzo, M. Debbah, T. T. Lam, and X. Qian, “Model-Aided Wireless Artificial Intelligence: Embedding Ex- pert Knowledge in Deep Neural Networks Towards Wireless Systems Optimization,” ArXiv e-prints, Aug. 2018.
","['] A. Zappone', 'M. Di Renzo', 'M. Debbah', 'T. T. Lam', 'X. Qian', '“ Model-Aided Wireless Artificial Intelligence', 'Ex- pert Knowledge Deep Neural Networks Towards Wireless', 'Optimization', '” ArXiv e-prints', 'Aug.']
","['Embedding'] 
",0
"[46] J. Shu, Z. Xu, and D. Meng, “Small Sample Learning in Big Data Era,” ArXiv e-prints, Aug. 2018.
","['] J. Shu', 'Z. Xu', 'D. Meng', '“ Small Sample Learning Big Data Era', '” ArXiv e-prints', 'Aug.']
","[] 
",0
"[47] A. Balatsoukas-Stimming, “Non-linear digital self-interference cancellation for in-band full-duplex radios using neural net- works,” arXiv preprint arXiv:1711.00379, 2017.
","['] A. Balatsoukas-Stimming', '“ Non-linear', 'digital self-interference cancellation', 'in-band full-duplex radios', 'neural net- works', '”', 'preprint arXiv:1711.00379']
","['using', 'arXiv'] 
",1
"[48] N. Strodthoff, B. Göktepe, T. Schierl, C. Hellge, and W. Samek, “Enhanced Machine Learning Techniques for Early HARQ Feedback Prediction in 5G,” ArXiv e-prints, Jul.
","['] N. Strodthoff', 'B. Göktepe', 'T. Schierl', 'C. Hellge', 'W. Samek', '“ Enhanced Machine Learning Techniques Early HARQ Feedback Prediction', '” ArXiv e-prints', 'Jul']
","[] 
",0
"2018.
","[]
","[] 
",0
"[49] V. K. Tumuluru, P. Wang, and D. Niyato, “A neural net- work based spectrum prediction scheme for cognitive radio,” in IEEE International Conference on Communications (ICC 2010), 2010, pp.
","['] V. K. Tumuluru', 'P. Wang', 'D. Niyato', 'A neural net- work', 'spectrum prediction scheme', 'cognitive radio', '” IEEE International Conference Communications', 'ICC', 'pp']
","['“', 'based'] 
",1
"1–5.
","[]
","[] 
",0
"[50] D. Del Testa, M. Danieletto, G. M. Di Nunzio, and M. Zorzi, “Estimating the number of receiving nodes in 802.11 networks via machine learning techniques,” in IEEE Global Communica- tions Conference (GLOBECOM), 2016, pp.
","['] D. Del Testa', 'M. Danieletto', 'G. M. Di Nunzio', 'M. Zorzi', '“ Estimating number', 'nodes', 'networks', 'machine', 'techniques', '” IEEE Global Communica- tions Conference', 'GLOBECOM', 'pp']
","['receiving', 'learning'] 
",1
"1–7.
","[]
","[] 
",0
"[51] H. Okamoto, T. Nishio, K. Nakashima, Y. Koda, K. Ya- mamoto, M. Morikura, Y. Asai, and R. Miyatake, “Machine- learning-based future received signal strength prediction using depth images for mmwave communications,” arXiv preprint arXiv:1803.09698, 2018.
","['] H. Okamoto', 'T. Nishio', 'K. Nakashima', 'Y. Koda', 'K. Ya- mamoto', 'M. Morikura', 'Y. Asai', 'R. Miyatake', '“ Machine-', 'learning-based future', 'signal strength prediction', 'depth images', 'communications', '”', 'preprint arXiv:1803.09698']
","['received', 'using', 'mmwave', 'arXiv'] 
",1
"[52] M. Chen, W. Saad, C. Yin, and M. Debbah, “Echo state networks for proactive caching in cloud-based radio access networks with mobile users,” IEEE Transactions on Wireless Communications, vol.
","['] M. Chen', 'W. Saad', 'C. Yin', 'M. Debbah', '“ Echo state networks', 'cloud-based radio access networks', 'users', '” IEEE Transactions Wireless Communications', 'vol']
","['caching'] 
",0
"16, no.
","[]
","[] 
",0
"6, pp.
","['pp']
","[] 
",0
"3520–3535, 2017.
","[]
","[] 
",0
"[53] M. Zorzi, A. Zanella, A. Testolin, M. D. F. De Grazia, and M. Zorzi, “Cognition-based networks: A new perspective on network optimization using learning and distributed intelli- gence,” IEEE Access, vol.
","['] M. Zorzi', 'A. Zanella', 'A. Testolin', 'M. D. F. De Grazia', 'M. Zorzi', '“', 'Cognition-based networks', 'A new perspective network optimization', 'intelli- gence', '” IEEE Access', 'vol']
","['using learning distributed'] 
",0
"3, pp.
","['pp']
","[] 
",0
"1512–1530, 2015.
","[]
","[] 
",0
"[54] F. Musumeci, C. Rottondi, A.
","['] F. Musumeci', 'C. Rottondi', 'A']
","[] 
",0
"Nag, I. Macaluso, D. Zibar, M. Ruffini, and M. Tornatore, “A survey on application of ma- chine learning techniques in optical networks,” arXiv preprint arXiv:1803.07976, 2018.
","['Nag', 'I. Macaluso', 'D. Zibar', 'M. Ruffini', 'M. Tornatore', 'A survey application', 'ma- chine', 'techniques', 'optical networks', '”', 'preprint arXiv:1803.07976']
","['“', 'learning', 'arXiv'] 
",1
"[55] F. Tang, B. Mao, Z. M. Fadlullah, N. Kato, O. Akashi, T. Inoue, and K. Mizutani, “On removing routing protocol from future wireless networks: A real-time deep learning approach for intel- ligent traffic control,” IEEE Wireless Communications, vol.
","['] F. Tang', 'B. Mao', 'Z. M. Fadlullah', 'N. Kato', 'O. Akashi', 'T. Inoue', 'K. Mizutani', '“', 'protocol future wireless networks', 'A real-time deep', 'approach intel- ligent traffic control', '” IEEE Wireless Communications', 'vol']
","['removing routing', 'learning'] 
",1
"25, no.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"154–160, 2018.
","[]
","[] 
",0
"[56] T. T. Nguyen and G. Armitage, “A survey of techniques for internet traffic classification using machine learning,” IEEE Communications Surveys & Tutorials, vol.
","['] T. T. Nguyen G. Armitage', 'A survey techniques', 'traffic classification', 'machine learning', '” IEEE Communications Surveys', 'Tutorials', 'vol']
","['“', 'internet', 'using'] 
",1
"10, no.
","[]
","[] 
",0
"4, pp.
","['pp']
","[] 
",0
"56–76, 2008.
","[]
","[] 
",0
"[57] C. M. Bishop, Pattern recognition and machine learning.
","['] C. M. Bishop', 'Pattern recognition machine learning']
","[] 
",0
"springer, 2006.
","['springer']
","[] 
",0
"19
","[]
","[] 
",0
"[58] K. P. Murphy, Machine learning: a probabilistic perspective.
","['] K. P. Murphy', 'Machine learning', 'probabilistic perspective']
","[] 
",0
"MIT press, 2012.
","['MIT press']
","[] 
",0
"[59] T. M. Cover and J.
","['] T. M. Cover J']
","[] 
",0
"A. Thomas, Elements of information theory.
","['A. Thomas', 'Elements information theory']
","[] 
",0
"John Wiley & Sons, 2012.
","['John Wiley', 'Sons']
","[] 
",0
"[60] O. Simeone, “Introducing information measures via inference [lecture notes],” IEEE Signal Processing Magazine, vol.
","['] O. Simeone', '“ Introducing information measures', 'inference', '[ lecture notes', '” IEEE Signal Processing Magazine', 'vol']
","[']'] 
",0
"35, no.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"167–171, 2018.
","[]
","[] 
",0
"[61] Y.
","['] Y']
","[] 
",0
"Sun, P. Babu, and D. P. Palomar, “Majorization-minimization algorithms in signal processing, communications, and machine learning,” IEEE Transactions on Signal Processing, vol.
","['Sun', 'P. Babu', 'D. P. Palomar', '“ Majorization-minimization', 'signal processing', 'communications', 'machine learning', '” IEEE Transactions Signal Processing', 'vol']
","[] 
",0
"65, no.
","[]
","[] 
",0
"3, pp.
","['pp']
","[] 
",0
"794–816, 2017.
","[]
","[] 
",0
"[62] A. Mnih and K. Gregor, “Neural variational inference and learning in belief networks,” arXiv preprint arXiv:1402.0030, 2014.
","['] A. Mnih K. Gregor', '“ Neural', 'variational inference', 'belief networks', '”', 'preprint arXiv:1402.0030']
","['learning', 'arXiv'] 
",1
"[63] H. V. Poor, An introduction to signal detection and estimation.
","['] H. V. Poor', 'An introduction', 'signal detection estimation']
","[] 
",0
"Springer Science & Business Media, 2013.
","['Springer Science', 'Business Media']
","[] 
",0
"[64] I. Goodfellow, “NIPS 2016 tutorial: Generative adversarial networks,” arXiv preprint arXiv:1701.00160, 2016.
","['] I. Goodfellow', '“ NIPS', 'tutorial', 'Generative adversarial networks', '”', 'preprint arXiv:1701.00160']
","['arXiv'] 
",0
"[65] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. Bülow, D. Lavery, P. Bayvel, and L. Schmalen, “End-to-end deep learning of optical fiber communications,” arXiv preprint arXiv:1804.04097, 2018.
","['] B. Karanov', 'M. Chagnon', 'F. Thouin', 'T. A. Eriksson', 'H. Bülow', 'D. Lavery', 'P. Bayvel', 'L. Schmalen', '“ End-to-end', 'deep learning', 'optical fiber communications', '”', 'preprint arXiv:1804.04097']
","['arXiv'] 
",0
"[66] H. Kim, Y. Jiang, S. Kannan, S. Oh, and P. Viswanath, “Deepcode: Feedback codes via deep learning,” arXiv preprint arXiv:1807.00801, 2018.
","['] H. Kim', 'Y. Jiang', 'S. Kannan', 'S. Oh', 'P. Viswanath', '“ Deepcode', 'Feedback', 'deep learning', '”', 'preprint arXiv:1807.00801']
","['codes', 'arXiv'] 
",1
"[67] M. Kim, N. I. Kim, W. Lee, and D. H. Cho, “Deep learning- aided scma,” IEEE Communications Letters, vol.
","['] M. Kim', 'N. I. Kim', 'W. Lee', 'D. H. Cho', '“ Deep learning-', 'scma', '” IEEE Communications Letters', 'vol']
","['aided'] 
",0
"22, no.
","[]
","[] 
",0
"4, pp.
","['pp']
","[] 
",0
"720–723, April 2018.
","['April']
","[] 
",0
"[68] E. Bourtsoulatze, D. Burth Kurka, and D. Gunduz, “Deep Joint Source-Channel Coding for Wireless Image Transmission,” ArXiv e-prints, Sep. 2018.
","['] E. Bourtsoulatze', 'D. Burth Kurka', 'D. Gunduz', '“ Deep Joint Source-Channel Coding Wireless Image Transmission', '” ArXiv e-prints', 'Sep.']
","[] 
",0
"[69] C.-K. Wen, W.-T. Shih, and S. Jin, “Deep learning for massive mimo csi feedback,” IEEE Wireless Communications Letters, 2018.
","['] C.-K. Wen', 'W.-T. Shih', 'S. Jin', '“ Deep', 'massive mimo csi feedback', '” IEEE Wireless Communications Letters']
","['learning'] 
",0
"[70] C. Xiao, D. Yang, Z. Chen, and G. Tan, “3-d ble indoor localization based on denoising autoencoder,” IEEE Access, vol.
","['] C. Xiao', 'D. Yang', 'Z. Chen', 'G. Tan', '“ 3-d', 'ble indoor localization', 'autoencoder', '” IEEE Access', 'vol']
","['based denoising'] 
",0
"5, pp.
","['pp']
","[] 
",0
"12 751–12 760, 2017.
","[]
","[] 
",0
"[71] T. J. O’Shea, T. Roy, and N. West, “Approximating the void: Learning stochastic channel models from observation with variational generative adversarial networks,” arXiv preprint arXiv:1805.06350, 2018.
","['] T. J. O ’ Shea', 'T. Roy', 'N. West', '“ Approximating void', 'Learning', 'stochastic channel models', 'variational generative adversarial networks', '”', 'preprint arXiv:1805.06350']
","['observation', 'arXiv'] 
",1
"[72] H. Ye, G. Y. Li, B.-H. F. Juang, and K. Sivanesan, “Channel agnostic end-to-end learning based communication systems with conditional gan,” arXiv preprint arXiv:1807.00447, 2018.
","['] H. Ye', 'G. Y. Li', 'B.-H. F. Juang', 'K. Sivanesan', '“ Channel', 'agnostic end-to-end learning', 'communication systems', 'conditional gan', '”', 'preprint arXiv:1807.00447']
","['based', 'arXiv'] 
",1
"[73] F. Liang, C. Shen, W. Yu, and F. Wu, “Towards Optimal Power Control via Ensembling Deep Neural Networks,” ArXiv e-prints, Jul.
","['] F. Liang', 'C. Shen', 'W. Yu', 'F. Wu', '“ Towards Optimal Power Control', 'Ensembling Deep Neural Networks', '” ArXiv e-prints', 'Jul']
","[] 
",0
"2018.
","[]
","[] 
",0
"[74] D. Neumann, T. Wiese, and W. Utschick, “Learning the mmse channel estimator,” IEEE Transactions on Signal Processing, 2018.
","['] D. Neumann', 'T. Wiese', 'W. Utschick', '“ Learning', 'mmse channel estimator', '” IEEE Transactions Signal Processing']
","[] 
",0
"[75] K. Davaslioglu and Y. E. Sagduyu, “Generative ad- versarial learning for spectrum sensing,” arXiv preprint arXiv:1804.00709, 2018.
","['] K. Davaslioglu Y. E. Sagduyu', '“ Generative', 'ad- versarial learning spectrum sensing', '”', 'preprint arXiv:1804.00709']
","['arXiv'] 
",0
"[76] A. Abdelnasser, E. Hossain, and D. I. Kim, “Clustering and resource allocation for dense femtocells in a two-tier cellular ofdma network,” IEEE Transactions on Wireless Communica- tions, vol.
","['] A. Abdelnasser', 'E. Hossain', 'D. I. Kim', '“ Clustering resource allocation dense', 'two-tier cellular ofdma network', '” IEEE Transactions Wireless Communica- tions', 'vol']
","['femtocells'] 
",0
"13, no.
","[]
","[] 
",0
"3, pp.
","['pp']
","[] 
",0
"1628–1641, 2014.
","[]
","[] 
",0
"[77] A.
","[]
","[']'] 
",0
"A. Abbasi and M. Younis, “A survey on clustering algo- rithms for wireless sensor networks,” Computer communica- tions, vol.
","['A. Abbasi M. Younis', 'A survey', 'algo- rithms wireless sensor networks', '” Computer communica- tions', 'vol']
","['“', 'clustering'] 
",1
"30, no.
","[]
","[] 
",0
"14-15, pp.
","['pp']
","[] 
",0
"2826–2841, 2007.
","[]
","[] 
",0
"[78] E. Abbe, A. S. Bandeira, and G. Hall, “Exact recovery in the stochastic block model,” arXiv preprint arXiv:1405.3267, 2014.
","['] E. Abbe', 'A. S. Bandeira', 'G. Hall', '“ Exact recovery', 'stochastic block model', '”', 'preprint arXiv:1405.3267']
","['arXiv'] 
",0
"[79] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank citation ranking: Bringing order to the web.” Stanford InfoLab, Tech.
","['] L. Page', 'S. Brin', 'R. Motwani', 'T. Winograd', 'The PageRank citation ranking', 'Bringing order web. ” Stanford InfoLab', 'Tech']
","['“'] 
",0
"Rep., 1999.
","['Rep.']
","[] 
",0
"[80] C. Karakus, Y.
","['] C. Karakus', 'Y']
","[] 
",0
"Sun, S. Diggavi, and W. Yin, “Redundancy techniques for straggler mitigation in distributed optimization and learning,” arXiv preprint arXiv:1803.05397, 2018.
","['Sun', 'S. Diggavi', 'W. Yin', '“ Redundancy', 'mitigation', 'optimization learning', '”', 'preprint arXiv:1803.05397']
","['techniques', 'distributed', 'arXiv'] 
",1
"20
","[]
","[] 
",0
"IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY
","['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']
","[] 
",0
"DOI: 10.21917/ijsc.2015.0133
","['DOI']
","[] 
",0
"946
","[]
","[] 
",0
"SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY
","['SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']
","[] 
",0
"Iqbal Muhammad 1  and Zhu Yan
","['Iqbal Muhammad', 'Zhu Yan']
","[] 
",0
"2
","[]
","[] 
",0
"School of Information Sciences and Technology, Southwest Jiaotong University, China
","['School Information Sciences Technology', 'Southwest Jiaotong University', 'China']
","[] 
",0
"E-mail:  1 muhammadiqbal72@yahoo.com,
","['E-mail', 'muhammadiqbal72 @ yahoo.com']
","[] 
",0
"2 yzhu@swjtu.edu.cn
","['yzhu @ swjtu.edu.cn']
","[] 
",0
"Abstract
","['Abstract']
","[] 
",0
"One of the core objectives of machine learning is to instruct
","['core objectives machine', 'instruct']
","['learning'] 
",0
"computers to use data or past experience to solve a given problem.
","['computers', 'data', 'past experience solve', 'problem']
","['use', 'given'] 
",1
"A
","[]
","[] 
",0
"good number of successful applications of machine learning exist
","['good number', 'successful applications machine']
","['learning exist'] 
",0
"already, including classifier to be trained on email messages to learn
","['classifier', 'email messages']
","['including', 'trained', 'learn'] 
",1
"in order to distinguish between spam and non-spam messages,
","['order', 'distinguish spam', 'non-spam messages']
","[] 
",0
"systems that analyze past sales data to predict customer buying
","['systems', 'past sales data', 'customer buying']
","['analyze', 'predict'] 
",1
"behavior, fraud detection etc.
","['behavior', 'fraud detection etc']
","[] 
",0
"Machine learning can be applied as
","['Machine learning']
","['applied'] 
",0
"association analysis through Supervised learning, Unsupervised
","['association analysis', 'learning']
","['Supervised', 'Unsupervised'] 
",1
"learning and Reinforcement Learning but in this study we will focus
","['Reinforcement Learning study focus']
","['learning'] 
",0
"on strength and weakness of supervised learning classification
","['strength weakness', 'learning classification']
","['supervised'] 
",0
"algorithms.
","['algorithms']
","[] 
",0
"The goal of supervised learning is to build a concise
","['The goal', 'build concise']
","['supervised learning'] 
",0
"model of the distribution of class labels in terms of predictor features.
","['model distribution class labels terms predictor features']
","[] 
",0
"The resulting classifier is then used to assign class labels to the testing
","['classifier', 'assign class labels']
","['resulting', 'used', 'testing'] 
",1
"instances where the values of the predictor features are known, but
","['instances values', 'features']
","['predictor', 'known'] 
",1
"the value of the class label is unknown.
","['value class label unknown']
","[] 
",0
"We are optimistic that this
","[]
","[] 
",0
"study will help new researchers to guiding new research areas and to
","['study', 'new researchers', 'new research areas']
","['help', 'guiding'] 
",1
"compare the effectiveness and impuissance of supervised learning
","['compare effectiveness impuissance', 'learning']
","['supervised'] 
",0
"algorithms.
","['algorithms']
","[] 
",0
"Keywords:
","['Keywords']
","[] 
",0
"Supervised Machine Learning, SVM, DT, Classifier
","['Machine Learning', 'SVM', 'DT', 'Classifier']
","['Supervised'] 
",0
"1.
","[]
","[] 
",0
"INTRODUCTION
","['INTRODUCTION']
","[] 
",0
"Machine Learning (ML) can be considered as a subfield of
","['Machine Learning', 'ML', 'subfield']
","['considered'] 
",0
"Artificial Intelligence since those algorithms can be seen as
","['Artificial Intelligence', 'algorithms']
","['seen'] 
",0
"building blocks to make computers learn to behave more
","['building blocks', 'computers']
","['make', 'learn behave'] 
",1
"intelligently by somehow generalizing rather that just storing
","[]
","['intelligently somehow generalizing', 'rather storing'] 
",1
"and retrieving data items like a database system and other
","['data items', 'database system']
","['retrieving'] 
",0
"applications would do.
","['applications']
","[] 
",0
"Machine learning has got its inspiration
","['Machine', 'inspiration']
","['learning got'] 
",0
"from a variety of academic disciplines, including computer
","['variety', 'academic disciplines', 'computer']
","['including'] 
",0
"science, statistics, biology, and psychology.
","['science', 'statistics', 'biology', 'psychology']
","[] 
",0
"The core function of
","['The core function']
","[] 
",0
"Machine learning attempts is to tell computers how to
","['Machine', 'attempts', 'computers']
","['learning', 'tell'] 
",1
"automatically find a good predictor based on past experiences
","['good predictor', 'past experiences']
","['automatically find', 'based'] 
",1
"and this job is done by good classifier.
","['job', 'good classifier']
","['done'] 
",0
"Classification is the
","['Classification']
","[] 
",0
"process of using a model to predict unknown values (output
","['process', 'model', 'predict unknown values', 'output']
","['using'] 
",0
"variables), using a number of known values (input variables).
","['variables', 'number', 'values', 'variables']
","['using', 'known', 'input'] 
",1
"The classification process is performed on data set D which
","['The classification process', 'data set D']
","['performed'] 
",0
"holds following objects:
","['objects']
","['holds following'] 
",0
" Set size →  AAAAA ,,2,1  , where A  denotes the number of attributes or the size of the set A.
","['\uf0b7 Set size → \uf07b \uf07dAAAAA', ',2,1 \uf04b\uf03d', 'A', 'number attributes size', 'A']
","['denotes', 'set'] 
",1
" Class label→ C: Target attribute;  CcccC ,,2,1  , where C  is the number of classes and 2C .
","['\uf0b7 Class label→ C', 'Target attribute', ',2,1 \uf04b\uf03d', 'C number']
","['\uf07dCcccC', 'classes'] 
",1
"Given a data set D, the core objective of ML is to produce a
","['data', 'D', 'objective ML produce']
","['Given', 'set'] 
",1
"prediction/classification function to relate values of attributes in
","['prediction/classification function relate values attributes']
","[] 
",0
"A and classes in C.
","['A classes C']
","[] 
",0
"Data mining is one of the most tools of machine learning
","['Data mining', 'machine learning']
","['tools'] 
",0
"among the number of different applications.
","['number', 'different applications']
","[] 
",0
"It is common that
","[]
","[] 
",0
"people are often choosing a wrong choices during analysis phase
","['people', 'wrong choices analysis phase']
","['often choosing'] 
",0
"or, possibly, when trying to establish relationships between
","['relationships']
","['trying establish'] 
",0
"multiple features.
","['multiple features']
","[] 
",0
"Ultimately this makes it difficult for them to
","[]
","['Ultimately makes'] 
",0
"explore solutions to certain problems.
","['solutions', 'certain problems']
","[] 
",0
"Machine learning can
","['Machine learning']
","[] 
",0
"often be successfully applied to these problems, improving the
","['problems']
","['often successfully applied', 'improving'] 
",1
"efficiency of systems and the designs of machines [1].
","['efficiency systems', 'machines', ']']
","['designs'] 
",0
"In
","[]
","[] 
",0
"machine learning algorithms every instance of particular dataset
","['machine', 'every instance', 'particular dataset']
","['learning'] 
",0
"is represented by using the same set of features.
","['set features']
","['represented using'] 
",0
"The nature of
","['The nature']
","[] 
",0
"these features could be continuous, categorical or binary.
","['features', 'categorical binary']
","['continuous'] 
",0
"If
","[]
","[] 
",0
"instances are given with known labels (i.e.- the corresponding
","['instances', 'labels', 'i.e.- corresponding']
","['given known'] 
",0
"correct outputs) then the learning scheme is known as supervised
","['correct outputs']
","['learning', 'known supervised'] 
",1
"(see Table.1), while in unsupervised learning approach the
","['Table.1', 'unsupervised learning approach']
","['see'] 
",0
"instances are unlabeled.
","['instances']
","['unlabeled'] 
",0
"Through applying these unsupervised
","[]
","['applying'] 
",0
"(clustering) algorithms, researchers are optimistic to discover
","['algorithms', 'researchers', 'optimistic discover']
","['clustering'] 
",0
"unknown, but useful, classes of items [3].
","['items', ']']
","['classes'] 
",0
"Another kind of
","['Another kind']
","[] 
",0
"machine learning is reinforcement learning.
","['machine', 'reinforcement learning']
","['learning'] 
",0
"Here the training
","[]
","['Here training'] 
",0
"information provided to the learning system by the environment
","['information', 'learning system environment']
","['provided'] 
",0
"(i.e.- external trainer) is in the form of a scalar reinforcement
","['i.e.- external trainer', 'form', 'scalar reinforcement']
","[] 
",0
"signal that constitutes a measure of how well the system
","['signal constitutes', 'system']
","['measure'] 
",0
"operates.
","['operates']
","[] 
",0
"The learner is not told which action has to take, as in
","['The learner', 'action take']
","['told'] 
",0
"most forms of machine learning, but instead must discover
","['forms machine learning']
","['discover'] 
",0
"which actions yield the most reward by trying them [1].
","['actions', ']']
","['yield reward trying'] 
",0
"A
","[]
","[] 
",0
"number of ML applications involve tasks that can be set up as
","['number ML applications', 'tasks']
","['involve', 'set'] 
",1
"supervised.
","[]
","['supervised'] 
",0
"The below figure depicts the general classification
","['The figure', 'general classification']
","['depicts'] 
",0
"architecture.
","['architecture']
","[] 
",0
"Fig.1.
","['Fig.1']
","[] 
",0
"Classification Architecture
","['Classification Architecture']
","[] 
",0
"In this study, we will focus our attention on the methods
","['study', 'attention methods']
","['focus'] 
",0
"which are being used for supervised learning.
","['learning']
","['used supervised'] 
",0
"This study will
","['This study']
","[] 
",0
"contribute to new researchers for getting up-to-date knowledge
","['new researchers', 'up-to-date knowledge']
","['contribute', 'getting'] 
",1
"about supervised ML approaches.
","['ML approaches']
","['supervised'] 
",0
"Table.1.
","['Table.1']
","[] 
",0
"Instances with known labels
","['Instances', 'labels']
","['known'] 
",0
"Data in standard Format
","['Data standard Format']
","[] 
",0
"Case Feature 1 Feature 2 … Feature n Class
","['Case Feature', 'Feature', '… Feature', 'n Class']
","[] 
",0
"1 aaa bbb … nnn Yes
","['aaa bbb …']
","['nnn'] 
",0
"2 aaa bbb … nnn Yes
","['aaa bbb …']
","['nnn'] 
",0
"3 aaa bbb … nnn No
","['aaa bbb …']
","['nnn'] 
",0
"… … … … … …
","['… … … … … …']
","[] 
",0
"In this work we have limited our references to refereed
","['work', 'limited references']
","['refereed'] 
",0
"journals, published books, web data and conferences.
","['journals', 'books', 'web data conferences']
","['published'] 
",0
"Our major
","[]
","[] 
",0
"goal for this work has been to provide a representative sample of
","['goal work', 'representative sample']
","[] 
",0
"Training
","['Training']
","[] 
",0
"Data
","['Data']
","[] 
",0
"Machine
","['Machine']
","[] 
",0
"Learning
","[]
","['Learning'] 
",0
"Program
","['Program']
","[] 
",0
"Classification
","['Classification']
","[] 
",0
"Rules
","['Rules']
","[] 
",0
"Predicted
","[]
","['Predicted'] 
",0
"Classification
","['Classification']
","[] 
",0
"Testing Data
","['Data']
","['Testing'] 
",0
"ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03
","['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']
","[] 
",0
"947
","[]
","[] 
",0
"existing lines of research in each learning technique.
","['lines research learning technique']
","['existing'] 
",0
"In each of
","[]
","[] 
",0
"our listed areas, there are many other papers/books that could be
","['areas', 'many papers/books']
","['listed'] 
",0
"more comprehensively help the interested readers.
","['help', 'interested readers']
","[] 
",0
"In the next section, we will cover wide-ranging issues of
","['next section', 'wide-ranging issues']
","['cover'] 
",0
"supervised machine learning such as selection of features and
","['machine', 'selection features']
","['supervised', 'learning'] 
",1
"data pre-processing.
","['data pre-processing']
","[] 
",0
"Logical/Symbolic techniques are being
","['Logical/Symbolic techniques']
","[] 
",0
"described in section 3, whereas statistical techniques for ML are
","['section', 'statistical techniques ML']
","['described'] 
",0
"discussed in section 4.
","['section']
","['discussed'] 
",0
"Section 5 will cover instance based
","['Section', 'cover instance']
","['based'] 
",0
"learners, SVM is discussed in section 6.
","['learners', 'SVM', 'section']
","['discussed'] 
",0
"The last section
","['The last section']
","[] 
",0
"concludes this work.
","['concludes work']
","[] 
",0
"2.
","[]
","[] 
",0
"ISSUES OF SUPERVISED LEARNING  ALGORITHMS
","['ISSUES OF SUPERVISED LEARNING ALGORITHMS']
","[] 
",0
"Learning from the past experiences is an attribute of humans
","['past experiences', 'humans']
","['Learning', 'attribute'] 
",1
"while the computers do not have this ability.
","['computers ability']
","[] 
",0
"In supervised or
","[]
","[] 
",0
"Inductive machine learning, our main goal is to learn a target
","['Inductive machine learning', 'main goal learn target']
","[] 
",0
"function that can be used to predict the values of a class.
","['function', 'predict values class']
","['used'] 
",0
"The
","[]
","[] 
",0
"process of applying supervised ML to a real-world problem is
","['process', 'ML real-world problem']
","['applying supervised'] 
",0
"described in below figure.
","['described figure']
","[] 
",0
"Fig.2.
","['Fig.2']
","[] 
",0
"Supervised Machine Learning Model
","['Machine Learning Model']
","['Supervised'] 
",0
"In supervised learning the first step is dealing with dataset.
","['supervised learning', 'first step', 'dataset']
","['dealing'] 
",0
"In
","[]
","[] 
",0
"order to perform a better training on data set an appropriate
","['order perform', 'training data']
","['set'] 
",0
"expert could suggest better selection of features.
","['expert', 'selection features']
","['suggest'] 
",0
"If concerned
","[]
","['concerned'] 
",0
"expert is not in reach, then the other approach is “brute-force”,
","['expert reach', 'approach', 'brute-force ”']
","['“'] 
",0
"which means measuring everything available in the hope that the
","['means', 'everything', 'available hope']
","['measuring'] 
",0
"right (informative, relevant) features can be isolated.
","['features']
","['isolated'] 
",0
"However, a
","[]
","[] 
",0
"dataset collected by the “brute-force” method is not directly
","['dataset', '“ brute-force ” method']
","['collected'] 
",0
"suitable for induction.
","['suitable induction']
","[] 
",0
"Ultimately, in most cases it contains noise
","['cases contains']
","['noise'] 
",0
"and missing feature values, and therefore requires significant
","['feature values']
","['missing', 'therefore requires'] 
",1
"pre-processing [1].
","['pre-processing [', ']']
","[] 
",0
"In the next step, data preparation and data
","['next step', 'data preparation data']
","[] 
",0
"preprocessing is a key function of researcher in Supervised
","['key function researcher']
","['preprocessing', 'Supervised'] 
",1
"Machine Learning (SML).
","['Machine Learning', 'SML']
","[] 
",0
"A number of techniques have been
","['A number techniques']
","[] 
",0
"introduced by different researchers to deal with missing data
","['different researchers', 'data']
","['introduced', 'deal missing'] 
",1
"issue.
","['issue']
","[] 
",0
"Hodge & Austin [4] have conducted a survey of
","['Hodge', 'Austin', ']', 'survey']
","['[', 'conducted'] 
",1
"contemporary techniques for outlier (noise) detection.
","['contemporary techniques', 'noise', 'detection']
","[] 
",0
"Karanjit
","['Karanjit']
","[] 
",0
"& Shuchita [5] have also discussed different outlier detection
","['Shuchita', ']', 'detection']
","['[', 'also discussed'] 
",1
"methods which are being used in different machine learning.
","['methods', 'different machine learning']
","['used'] 
",0
"H.
","['H']
","[] 
",0
"Jair [6] has done comparison on 6 different outlier detection
","['Jair', ']', 'comparison', 'detection']
","['[', 'done'] 
",1
"methods by performing experiment on benchmark datasets and a
","['methods', 'experiment benchmark datasets']
","['performing'] 
",0
"synthetic astronomical domain.
","['synthetic astronomical domain']
","[] 
",0
"2.1 ALGORITHM SELECTION
","['ALGORITHM SELECTION']
","[] 
",0
"The selection of algorithm for achieving good results is an
","['The selection', 'good results']
","['achieving'] 
",0
"important step.
","['important step']
","[] 
",0
"The algorithm evaluation is mostly judge by
","['The algorithm evaluation', 'judge']
","[] 
",0
"prediction accuracy.
","['prediction accuracy']
","[] 
",0
"The classifier’s (Algorithm) evaluation is
","['The classifier ’', 'Algorithm', 'evaluation']
","[] 
",0
"most often based on prediction accuracy and it can be measured
","['prediction accuracy']
","['often based', 'measured'] 
",1
"by given below formula
","['formula']
","['given'] 
",0
"  cases test of number Total
","['cases', 'number Total']
","['test'] 
",0
"tionsclassifica Correct of Number Accuracy   (1)
","['tionsclassifica Correct Number Accuracy \uf03d']
","[] 
",0
"There are number of methods which are being used by
","['number methods']
","['used'] 
",0
"different researchers to calculate classifier’s accuracy.
","['different researchers', '’ accuracy']
","['calculate'] 
",0
"Some
","[]
","[] 
",0
"researcher’s splits the training set in such a way that, two-thirds
","['researcher ’ splits', 'set way', 'two-thirds']
","['training'] 
",0
"retain for training and the other third for estimating performance.
","['retain training', 'performance']
","['estimating'] 
",0
"Cross-Validation (CV) or Rotation Estimation is another
","['Cross-Validation', 'CV', 'Rotation Estimation']
","[] 
",0
"approach.
","['approach']
","[] 
",0
"CV provides a way to make a better use of the
","['CV', 'way', 'use']
","['provides', 'make'] 
",1
"available sample.
","['available sample']
","[] 
",0
"In k-fold cross-validation scheme, we divide
","['k-fold cross-validation scheme', 'divide']
","[] 
",0
"the learning sample into k disjoint subsets of the same size, i.e.-
","['sample k', 'disjoint subsets size']
","['learning'] 
",0
" klslslsls  211  (2)
","['klslslsls']
","['\uf0c8\uf0c8\uf03d'] 
",0
"A model is then inferred by the learning algorithm from each
","['A model', 'inferred learning algorithm']
","[] 
",0
"sample ls\ls, i = 1,..,k and its performance is determined on the
","['sample ls\\ls', '..', 'performance']
","['k', 'determined'] 
",1
"held out sample lsi.
","['sample lsi']
","['held'] 
",0
"Final performance is computed as the
","['Final performance']
","['computed'] 
",0
"average performance over all these models.
","['average performance models']
","[] 
",0
"Notice that when k is
","['Notice k']
","[] 
",0
"equal to the number of objects in the learning sample, this
","['equal number objects', 'sample']
","['learning'] 
",0
"method is called leave-one-out.
","['method', 'leave-one-out']
","['called'] 
",0
"Typically, smaller values of k
","['values']
","['k'] 
",0
"(10 or 20) are however preferred for computational reasons [7].
","['preferred computational reasons', ']']
","['['] 
",0
"The comparison between supervised ML methods can be done
","['The comparison', 'ML methods']
","['supervised', 'done'] 
",1
"through to perform statistical comparisons of the accuracies of
","['statistical comparisons accuracies']
","['perform'] 
",0
"trained classifiers on specific datasets.
","['trained classifiers', 'specific datasets']
","[] 
",0
"For doing this we can run
","['run']
","[] 
",0
"two different learning algorithms on samples of training set of size
","['algorithms samples', 'set size']
","['learning', 'training'] 
",1
"N, estimate the difference in accuracy for each pair of classifiers
","['N', 'estimate difference accuracy pair classifiers']
","[] 
",0
"on a large test set[1].
","['large test', ']']
","['set'] 
",0
"For classification of data, a good number of
","['classification data', 'good number']
","[] 
",0
"techniques have been developed by researchers, such as logical
","['techniques', 'researchers']
","['developed'] 
",0
"statistics based techniques.
","['statistics', 'techniques']
","['based'] 
",0
"In next sections, we will precisely
","['next sections']
","[] 
",0
"discuss the most important supervised machine learning
","['discuss', 'machine learning']
","['supervised'] 
",0
"techniques, starting with logical techniques [1].
","['techniques', 'logical techniques', ']']
","['starting', '['] 
",1
"3.
","[]
","[] 
",0
"LOGIC BASED ALGORITHMS
","['LOGIC BASED ALGORITHMS']
","[] 
",0
"In this section we will discuss two logical (symbolic)
","['section discuss']
","[] 
",0
"learning methods: decision trees and rule-based classifiers.
","['methods', 'decision trees', 'rule-based classifiers']
","['learning'] 
",0
"3.1 DECISION TREES
","['DECISION TREES']
","[] 
",0
"In machine learning domain the Decision Tree Induction [8,
","['machine learning domain Decision Tree Induction [']
","[] 
",0
"9] is currently one of the most important supervised learning
","[']', 'learning']
","['supervised'] 
",0
"algorithms.
","['algorithms']
","[] 
",0
"In Artificial Intelligence (AI) field, Quinlan has
","['Artificial Intelligence', 'AI', 'field', 'Quinlan']
","[] 
",0
"contributed through his ID3 and C4.5 algorithms.
","['ID3 C4.5 algorithms']
","['contributed'] 
",0
"C4.5 is one of
","['C4.5']
","[] 
",0
"the most popular and the efficient method in decision tree-based
","['popular efficient method decision']
","[] 
",0
"approach.
","['approach']
","[] 
",0
"Here C4.5 algorithm creates a tree model by using
","['C4.5 algorithm', 'tree model']
","['creates', 'using'] 
",1
"values of only one attribute at a time [10].
","['values', 'attribute time', ']']
","['['] 
",0
"According to authors
","['authors']
","['According'] 
",0
"[7], the decision tree induction, which was initially designed to
","[']', 'decision tree induction']
","['initially designed'] 
",0
"solve classification problems, has been extended to deal with
","['classification problems', 'deal']
","['solve', 'extended'] 
",1
"single or multi-dimensional regression.
","['single multi-dimensional regression']
","[] 
",0
"The major benefits of
","['The major benefits']
","[] 
",0
"decision trees are i) produce intensive results, ii) easy to
","['decision trees', 'intensive results', 'ii', 'easy']
","['produce'] 
",0
"understand, iii) and holds well-organized knowledge structure
","['understand', 'iii', 'well-organized knowledge structure']
","['holds'] 
",0
"[28].
","[']']
","[] 
",0
"Decision Trees (DT) are trees that classify instances by
","['Decision Trees', 'DT', 'classify instances']
","['trees'] 
",0
"sorting them based on feature values, where each node in a
","['feature values', 'node']
","['sorting based'] 
",0
"decision tree represents a feature in an instance to be classified,
","['decision tree', 'feature instance']
","['represents', 'classified'] 
",1
"and each branch represents a value that the node can assume [1].
","['branch', 'value node', ']']
","['represents', 'assume'] 
",1
"Instances are classified starting at the root node and sorted based
","['Instances', 'root']
","['classified starting', 'node sorted based'] 
",1
"on their feature values.
","['feature values']
","[] 
",0
"IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY
","['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']
","[] 
",0
"948
","[]
","[] 
",0
"The Fig.3 is an example of a decision tree for the training set
","['The Fig.3 example decision', 'training set']
","[] 
",0
"of Table.2.
","['Table.2']
","[] 
",0
"DT are extensively used is different computational
","['DT']
","['extensively used'] 
",0
"fields to classify data.
","['fields', 'data']
","['classify'] 
",0
"The reasons behinds the widely
","['The reasons']
","['behinds'] 
",0
"acceptability of DT learning algorithms are their flexibility to
","['acceptability DT', 'algorithms flexibility']
","['learning'] 
",0
"apply in wide range of problems.
","['wide range problems']
","['apply'] 
",0
"An interesting and important
","[]
","[] 
",0
"property of a decision tree and its resulting set of rules is that the
","['property decision tree', 'rules']
","['resulting set'] 
",0
"tree paths or the rules are mutually exclusive and exhaustive.
","['tree paths rules', 'exclusive exhaustive']
","[] 
",0
"This means that every data instance/record/example/vector/case
","['every data instance/record/example/vector/case']
","['means'] 
",0
"is covered by a single rule.
","['single rule']
","['covered'] 
",0
"According to Pierre et al.
","['Pierre et al']
","['According'] 
",0
"[7], DT
","[']', 'DT']
","[] 
",0
"algorithms combined with ensemble methods, can provide better
","['algorithms', 'ensemble methods']
","['combined', 'provide'] 
",1
"results in terms of predictive accuracy and significantly in the
","['results terms', 'predictive accuracy']
","[] 
",0
"context of high-throughput data sets, tree-based methods are also
","['context high-throughput data sets', 'tree-based methods']
","[] 
",0
"highly scalable from a computational point of view.
","['scalable computational point view']
","[] 
",0
"Fig.3.
","['Fig.3']
","[] 
",0
"A Sample Decision Tree
","['A Sample Decision Tree']
","[] 
",0
"By using the DT depicted in Fig.3 as an example, the
","['DT', 'Fig.3 example']
","['using', 'depicted'] 
",1
"instance (at1 = a1, at2 = b2, at3 = a3, at4 = b4) would sort to the
","['instance', 'at1 = a1', 'at2 = b2', 'at3 = a3', 'at4 = b4']
","['sort'] 
",0
"nodes: at1, at2, and finally at3, which would classify the instance
","['nodes', 'at1', 'at2', 'instance']
","['classify'] 
",0
"as being positive (represented by the values “Yes”).
","['values', 'Yes ”']
","['represented', '“'] 
",1
"Table.2.
","['Table.2']
","[] 
",0
"Sample Training set
","['Sample Training set']
","[] 
",0
"at1 at2 at3 at4 Class
","['at1 at2 at3 at4 Class']
","[] 
",0
"a1 a2 a3 a4 Yes
","['a1 a2', 'a3 a4 Yes']
","[] 
",0
"a1 a2 a3 b4 Yes
","['a1 a2', 'a3 b4 Yes']
","[] 
",0
"a1 b2 a3 a4 Yes
","['a1 b2', 'a3 a4 Yes']
","[] 
",0
"a1 b2 b3 b4 No
","['a1 b2 b3']
","['b4'] 
",0
"a1 c2 a3 a4 Yes
","['a1 c2', 'a3 a4 Yes']
","[] 
",0
"a1 c2 a3 b4 No
","['a1 c2 a3']
","['b4'] 
",0
"b1 b2 b3 b4 No
","['b1 b2 b3']
","['b4'] 
",0
"c1 b2 b3 b4 No
","['c1 b2 b3']
","['b4'] 
",0
"The feature that best divides the training data would be the
","['The feature', 'divides', 'data']
","['training'] 
",0
"root node of the tree.
","['root', 'node tree']
","[] 
",0
"There are different methods to extract the
","['different methods extract']
","[] 
",0
"features that best divides the training data such as information
","['features', 'divides', 'data information']
","['training'] 
",0
"gain [11] and gini index [12].
","['gain', '] gini index', ']']
","['['] 
",0
"Fig.4.
","['Fig.4']
","[] 
",0
"General pseudo-code for building decision trees
","['General pseudo-code building decision trees']
","[] 
",0
"3.2 LEARNING SET OF RULES
","['LEARNING SET OF RULES']
","[] 
",0
"It is also possible that decision trees can be translated into a
","['possible decision trees']
","['translated'] 
",0
"set of rules by creating a separate rule for each path from the
","['set rules', 'separate rule path']
","['creating'] 
",0
"root to a leaf in the tree [13].
","['root leaf tree', ']']
","['['] 
",0
"However, rules can also be directly
","['rules']
","[] 
",0
"induced from training data using a variety of rule-based
","['induced training data', 'variety']
","['using'] 
",0
"algorithms.
","['algorithms']
","[] 
",0
"In [14], the author has provided an excellent
","[']', 'author']
","['provided'] 
",0
"overview of existing work in rule-based methods.
","['overview', 'work', 'rule-based methods']
","['existing'] 
",0
"The
","[]
","[] 
",0
"classification rules represent each class by Disjunctive Normal
","['classification rules', 'class Disjunctive Normal']
","['represent'] 
",0
"Form (DNF).
","['Form', 'DNF']
","[] 
",0
"A statement is in DNF if it is a disjunction
","['A statement DNF disjunction']
","[] 
",0
"(sequence of ORs) consisting of one or more disjuncts, each of
","['sequence ORs', 'disjuncts']
","['consisting'] 
",0
"which is a conjunction (AND) of one or more literals.
","['conjunction', 'literals']
","[] 
",0
"Below is
","[]
","[] 
",0
"an example of disjunctive normal forms.
","['example', 'disjunctive normal forms']
","[] 
",0
"A k-DNF expression is of the form:
","['A k-DNF expression form']
","[] 
",0
"       nnnn AAAAAA 22121     knnknk AAA   2111 , where k is the number of
","['\uf028 \uf029 \uf028 \uf029\uf028 \uf029\uf0da\uf0da\uf0d9\uf0d9\uf0da\uf0d9\uf0d9 \uf02b\uf02b \uf04b\uf04b\uf04b', 'AAAAAA', '\uf028 \uf029 \uf028 \uf029\uf028 \uf029knnknk AAA \uf0d9\uf0d9\uf0d9 \uf02b\uf02d\uf02b\uf02d \uf04b2111', 'number']
","['nnnn', 'k'] 
",1
"disjunctions, n is the number of conjunctions in each disjunction,
","['disjunctions', 'n number conjunctions disjunction']
","[] 
",0
"and An is defined over the alphabet
","['An defined alphabet']
","[] 
",0
"jj AAAAAA  2121 ~,~,,,,  .
","['jj AAAAAA \uf04b\uf04b', '~', '~']
","[] 
",0
"Here the objective is to build
","['objective build']
","[] 
",0
"the smallest rule-set that is consistent with the training data [1].
","['rule-set consistent training data', ']']
","[] 
",0
"A good number of learned rules is usually a positive sign that the
","['A good number', 'rules', 'positive sign']
","['learned'] 
",0
"learning algorithm is attempting to remember the training set,
","['training set']
","['learning', 'attempting remember'] 
",1
"instead of discovering the assumptions that govern it.
","['assumptions']
","['instead discovering', 'govern'] 
",1
"A
","[]
","[] 
",0
"separate-and-conquer algorithm (recursively breaking down a
","['separate-and-conquer algorithm']
","['recursively breaking'] 
",0
"problem into sub-problems) search for a rule that explains a part
","['problem sub-problems', 'search rule', 'part']
","['explains'] 
",0
"of its training instances, separates these instances and recursively
","['training instances', 'separates instances']
","[] 
",0
"conquers the remaining instances by learning more rules, until
","['conquers', 'instances', 'rules']
","['remaining', 'learning'] 
",1
"no instances remain [1].
","['instances', ']']
","['remain'] 
",0
"In below Fig.5, a general pseudo-code
","['Fig.5', 'general pseudo-code']
","[] 
",0
"for rule learners is presented.
","['rule learners']
","['presented'] 
",0
"Fig.5.
","['Fig.5']
","[] 
",0
"A general Pseudo code for rule learners
","['A general Pseudo code rule learners']
","[] 
",0
"The core difference between heuristics for rule learning
","['The core difference heuristics rule']
","['learning'] 
",0
"algorithms and heuristics for decision trees algorithms is that the
","['algorithms heuristics decision trees']
","['algorithms'] 
",0
"latter evaluate the average quality of a number of disjointed sets,
","['latter evaluate average quality number', 'sets']
","['disjointed'] 
",0
"while rule learners only evaluate the quality of the set of
","['rule learners', 'quality set']
","['evaluate'] 
",0
"instances that is covered by the candidate rule [1].
","['instances', 'candidate rule', ']']
","['covered', '['] 
",1
"One of the
","[]
","[] 
",0
"most useful characteristic of rule based classifiers is their
","['useful characteristic rule', 'classifiers']
","['based'] 
",0
"comprehensibility.
","['comprehensibility']
","[] 
",0
"In order to achieve better performance, even
","['order', 'performance']
","['achieve'] 
",0
"though some rule-based classifiers can deal with numerical
","['rule-based classifiers']
","['deal'] 
",0
"features, some experts propose these features should be
","['features', 'experts', 'features']
","['propose'] 
",0
"discredited before induction, so as to reduce training time and
","['induction', 'training time']
","['discredited', 'reduce'] 
",1
"increase classification accuracy [15].
","['increase classification accuracy', ']']
","['['] 
",0
"4.
","[]
","[] 
",0
"STATISTICAL LEARNING ALGORITHMS
","['STATISTICAL LEARNING ALGORITHMS']
","[] 
",0
"Statistical learning is a framework for machine learning
","['Statistical learning framework machine learning']
","[] 
",0
"drawing from the fields of statistics and functional analysis [16].
","['fields statistics', 'functional analysis', ']']
","['drawing', '['] 
",1
"1.
","[]
","[] 
",0
"Initialize rule set to a default   2.
","['Initialize rule', 'default']
","['set'] 
",0
"Initialize examples to either all available examples
","['Initialize', 'available examples']
","['examples'] 
",0
"or all examples not correctly handled by rule set.
","['examples', 'rule set']
","['correctly handled'] 
",0
"3.
","[]
","[] 
",0
"Repeat
","['Repeat']
","[] 
",0
"     (a) Find best, the best rule with respect to examples.
","['Find', 'rule respect examples']
","[] 
",0
"     (b) If such a rule can be found
","['b', 'rule']
","['found'] 
",0
"i.
","[]
","[] 
",0
"Add best to rule set.
","['Add', 'rule set']
","[] 
",0
"ii.
","['ii']
","[] 
",0
"Set examples to all examples not handled
","['Set examples examples']
","['handled'] 
",0
"correctly by rule set.
","['rule set']
","[] 
",0
"4.
","[]
","[] 
",0
"Until no rule best can be found
","['rule']
","['best found'] 
",0
"1.
","[]
","[] 
",0
"Check for base cases   2.
","['Check base cases']
","[] 
",0
"For each attribute “a”  calculate
","['attribute “ ” calculate']
","[] 
",0
"i. Normalized the information gain (IG) from splitting  on attribute “a”.
","['i. Normalized information gain', 'IG', 'attribute “ ”']
","['splitting'] 
",0
"3.
","[]
","[] 
",0
"Find the best “a”, attribute that has highest IG   4.
","['Find', '“ ”']
","[] 
",0
"Create a decision node: node that splits on best of “a”  5.
","['Create decision node', 'node splits', '“ ”']
","[] 
",0
"Recurse on the sub-lists obtained by Splitting on a best
","['Recurse sub-lists', 'Splitting']
","['obtained'] 
",0
"and add those nodes as children of node
","['nodes children']
","['add'] 
",0
"at1
","['at1']
","[] 
",0
"at2 No No
","['No No']
","[] 
",0
"at4 at3  No
","['at4']
","['at3'] 
",0
"Yes
","[]
","[] 
",0
"No
","[]
","[] 
",0
"Yes No
","[]
","[] 
",0
"ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03
","['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']
","[] 
",0
"949
","[]
","[] 
",0
"Statistical learning theory deals with the problem of finding a
","['theory deals problem finding']
","['learning'] 
",0
"predictive function based on data and it has a good number of
","['predictive function', 'data', 'good number']
","['based'] 
",0
"applications in the field of AI.
","['applications field AI']
","[] 
",0
"The major of goal of statistical
","['The major goal statistical']
","[] 
",0
"learning algorithms is to provide a framework for studying the
","['algorithms provide framework']
","['learning', 'studying'] 
",1
"problem of inference that is obtaining knowledge, making
","['problem inference', 'knowledge']
","['obtaining', 'making'] 
",1
"predictions and making decision by constructing model from a
","['predictions', 'decision', 'model']
","['making', 'constructing'] 
",1
"set of data [17].
","['data', ']']
","['set'] 
",0
"Bayesian networks are the most well known representative of
","['Bayesian networks', 'representative']
","['well known'] 
",0
"statistical learning algorithms.
","['algorithms']
","['learning'] 
",0
"A good source for learning
","['A good source learning']
","[] 
",0
"Bayesian Networks (BN) theory is [18], where readers can learn
","['Bayesian Networks', 'BN', 'theory', ']', 'readers']
","['learn'] 
",0
"applications of BN.
","['applications BN']
","[] 
",0
"Statistical methods are characterized by having an explicit
","['Statistical methods', 'explicit']
","['characterized'] 
",0
"underlying probability model, which provides a probability that an
","['probability model', 'probability']
","['underlying', 'provides'] 
",1
"instance belongs in each class, rather than simply a classification.
","['instance belongs class', 'classification']
","[] 
",0
"Linear Discriminate Analysis (LDA),which was developed in
","['Linear Discriminate Analysis', 'LDA']
","['developed'] 
",0
"1936, and the related Fisher’s linear discriminate are famous
","['Fisher', '’ linear discriminate']
","['related'] 
",0
"methods used in statistics and machine learning to retrieve the
","['methods', 'statistics machine learning retrieve']
","['used'] 
",0
"linear combination of features which best separate two or more
","['linear combination features']
","['best separate'] 
",0
"classes of object [1].
","['classes', ']']
","['object'] 
",0
"The purpose of discriminate analysis is to
","['The purpose discriminate analysis']
","[] 
",0
"classify objects (nations, people, customers…) into one of two or
","['classify objects', 'nations', 'people', 'customers…']
","[] 
",0
"more groups based on set of features that describe the objects (e.g.-
","['groups', 'features', 'describe objects']
","['based set'] 
",0
"gender, marital status, income, height, weight...).
","['gender', 'marital status', 'income', 'height', 'weight']
","[] 
",0
"The another
","[]
","[] 
",0
"method for estimating probability distributions from data is
","['method', 'probability distributions data']
","['estimating'] 
",0
"maximum entropy.
","['maximum entropy']
","[] 
",0
"According to the base theory of maximum
","['base theory maximum']
","['According'] 
",0
"entropy, if nothing is known about a distribution except that it
","['entropy', 'nothing', 'distribution']
","['known'] 
",0
"belongs to a certain class, then the distribution with the largest
","['belongs', 'certain class', 'distribution']
","[] 
",0
"entropy should be chosen as the default.
","['entropy', 'default']
","['chosen'] 
",0
"4.1 NAIVE BAYES CLASSIFIERS
","['NAIVE BAYES CLASSIFIERS']
","[] 
",0
"Bayesian networks are widely used to perform classification
","['Bayesian networks', 'perform classification']
","['widely used'] 
",0
"tasks.
","['tasks']
","[] 
",0
"Naive Bayesian Networks (NBN) are very simple
","['Naive Bayesian Networks', 'NBN', 'simple']
","[] 
",0
"Bayesian networks which are composed of directed acyclic
","['Bayesian networks']
","['composed directed'] 
",0
"graphs with only one parent (representing the unobserved node)
","['graphs', 'parent', 'unobserved node']
","['representing'] 
",0
"and several children (corresponding to observed nodes) with a
","['several children', 'nodes']
","['corresponding observed'] 
",0
"strong assumption of independence among child nodes in the
","['strong assumption independence', 'child nodes']
","[] 
",0
"context of their parent [21].
","['context parent', ']']
","['['] 
",0
"According to author [20] the
","['author [', ']']
","['According'] 
",0
"independence model (Naive Bayes) is based on estimating:
","['independence model', 'Naive Bayes', 'estimating']
","['based'] 
",0
"     
","['\uf028 \uf029 \uf028 \uf029']
","[] 
",0
"       
","['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029']
","[] 
",0
"       JXPjP
","['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029JXPjP']
","[] 
",0
"XPPiP
","['XPPiP']
","[] 
",0
"JXPjP
","['JXPjP']
","[] 
",0
"XPiP
","['XPiP']
","[] 
",0
"XJP
","['XJP']
","[] 
",0
"XP R
","['XP R']
","[] 
",0
"r
","['r']
","[] 
",0
"r |
","['r |']
","[] 
",0
"|
","['|']
","[] 
",0
"|
","['|']
","[] 
",0
"|
","['|']
","[] 
",0
"|
","['|']
","[] 
",0
"|
","['|']
","[] 
",0
"
","['\uf050']
","[] 
",0
" 
","['\uf050 \uf03d\uf03d\uf03d']
","[] 
",0
"  (3)
","['\uf069\uf069\uf069']
","[] 
",0
"Here comparing these two probabilities, the larger
","['probabilities']
","['Here comparing'] 
",0
"probability indicates that the class label value that is more likely
","['probability', 'class label value']
","['indicates'] 
",0
"to be the actual label (if R>1: predict i else predict j) [1].
","['actual label', 'R', 'predict', 'j', ']']
","['>', 'else predict', '['] 
",1
"As
","[]
","[] 
",0
"shown in the below figure, the links in a Naive Bayes model are
","['figure', 'Naive Bayes model']
","['shown', 'links'] 
",1
"directed from output to input, which gives the model its
","['output input', 'model']
","['directed', 'gives'] 
",1
"simplicity, as there are no interactions between the inputs, except
","['simplicity', 'interactions inputs']
","[] 
",0
"indirectly via the output.
","['output']
","[] 
",0
"Fig.6.
","['Fig.6']
","[] 
",0
"Naive Bayes model
","['Naive Bayes model']
","[] 
",0
"An advantage of the Naive Bayes classifier is that it requires
","['An advantage', 'Naive Bayes classifier']
","['requires'] 
",0
"a small amount of training data to estimate the parameters
","['small amount training data estimate parameters']
","[] 
",0
"necessary for classification.
","['necessary classification']
","[] 
",0
"4.2 BAYESIAN NETWORKS
","['BAYESIAN NETWORKS']
","[] 
",0
"Bayesian Networks (BN) are graphical models that are used
","['Bayesian Networks', 'BN', 'graphical models']
","['used'] 
",0
"to illustrate relationships between events or ideas to infer
","['illustrate relationships events ideas']
","['infer'] 
",0
"probabilities or uncertainties associated with those ideas or
","['probabilities uncertainties', 'ideas']
","['associated'] 
",0
"events.
","['events']
","[] 
",0
"Information retrieval, predictions based on limited input
","['Information retrieval', 'predictions', 'limited input']
","['based'] 
",0
"or recognition software is some main applications of BN.
","['recognition software', 'main applications BN']
","[] 
",0
"The Bayesian network structure S is a directed acyclic graph
","['The Bayesian network structure S', 'acyclic graph']
","['directed'] 
",0
"(DAG) and the nodes in S are in one-to-one correspondence with
","['DAG', 'S one-to-one correspondence']
","['nodes'] 
",0
"the features X.
","['features X']
","[] 
",0
"The arcs represent casual influences among the
","['The arcs represent', 'casual influences']
","[] 
",0
"features while the lack of possible arcs in S encodes conditional
","['features', 'possible arcs S']
","['lack', 'encodes'] 
",1
"independencies.
","['independencies']
","[] 
",0
"Moreover, a feature (node) is conditionally
","['feature', 'node']
","[] 
",0
"independent from its non-descendants given its parents (X1 is
","['independent non-descendants', 'parents', 'X1']
","['given'] 
",0
"conditionally independent from X2).
","['independent X2']
","[] 
",0
"The below example shows that there are two events which
","['The example', 'events']
","['shows'] 
",0
"could cause grass to be wet i.e.- either the sprinkler is on or it’s
","['grass', 'either sprinkler ’']
","['cause'] 
",0
"raining.
","['raining']
","[] 
",0
"Additionally here we also, suppose that the rain has a
","['rain']
","['suppose'] 
",0
"direct effect on the use of the sprinkler (namely that when it
","['direct effect use sprinkler']
","[] 
",0
"rains, the sprinkler is usually not turned on).
","['rains', 'sprinkler']
","['usually turned'] 
",0
"Then the situation
","['situation']
","[] 
",0
"can be modeled with a Bayesian network.
","['Bayesian network']
","['modeled'] 
",0
"All three variables
","['variables']
","[] 
",0
"have two possible values, T (for true) and F (for false) [22].
","['possible values', 'T', 'F', ']']
","['['] 
",0
"Fig.7.
","['Fig.7']
","[] 
",0
"Bayesian network with conditional probability tables
","['Bayesian network', 'conditional probability tables']
","[] 
",0
"The below is a joint probability function:
","['The joint probability function']
","[] 
",0
"        RPRSPRSGPRSGP ,,,   (4)  where, the names of the variables have been abbreviated to:
","['\uf028 \uf029 \uf028 \uf029 \uf028 \uf029 \uf028 \uf029RPRSPRSGPRSGP', '\uf03d', 'names variables']
","['abbreviated'] 
",0
"G = Grass wet (yes/no)
","['G = Grass wet', 'yes/no']
","[] 
",0
"S = Sprinkler turned on (yes/no)
","['S = Sprinkler', 'yes/no']
","['turned'] 
",0
"R = Raining (yes/no).
","['R = Raining', 'yes/no']
","[] 
",0
"Cheng et al.
","['Cheng', 'al']
","[] 
",0
"draw the attention of a problem of BN classifiers
","['draw attention problem BN classifiers']
","[] 
",0
"that it is not suitable for datasets with many features.
","['suitable datasets', 'many features']
","[] 
",0
"The reason
","['The reason']
","[] 
",0
"for this is that trying to construct a very large network is simply
","['construct', 'large network']
","['trying'] 
",0
"not feasible in terms of time and space [23].
","['feasible terms time space [', ']']
","[] 
",0
"The pseudo code of
","['The pseudo code']
","[] 
",0
"training BN is shown in below figure:
","['BN', 'figure']
","['training', 'shown'] 
",1
"Input 1
","[]
","[] 
",0
"Input 2
","[]
","[] 
",0
"Input 3
","[]
","[] 
",0
"Input 4
","[]
","[] 
",0
"Output 1
","[]
","[] 
",0
"IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY
","['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']
","[] 
",0
"950
","[]
","[] 
",0
"Fig.8.
","['Fig.8']
","[] 
",0
"Pseudo-code for training of BN
","['Pseudo-code training BN']
","[] 
",0
"5.
","[]
","[] 
",0
"INSTANCE-BASED LEARNING
","['INSTANCE-BASED LEARNING']
","[] 
",0
"About this learning scheme, the author [24] describes it as
","['scheme', 'author', '] describes']
","['learning', '['] 
",1
"lazy-learning algorithms, as they delay the induction or
","['lazy-learning algorithms', 'delay induction']
","[] 
",0
"generalization process until classification is performed.
","['generalization process classification']
","['performed'] 
",0
"These
","[]
","[] 
",0
"algorithms require less computational time during the training
","['algorithms require', 'computational time training']
","[] 
",0
"phase than other eager-learning algorithms (such as decision trees,
","['phase', 'eager-learning algorithms', 'decision trees']
","[] 
",0
"neural and Bayes nets) but need more computation time during the
","['neural Bayes nets', 'computation time']
","['need'] 
",0
"classification process.
","['classification process']
","[] 
",0
"Nearest Neighbor algorithm is an example
","['Neighbor algorithm example']
","[] 
",0
"of instance-based learning algorithms [1].
","[']']
","['learning'] 
",0
"Aha [25] and De et.
","['Aha', '] De']
","['['] 
",0
"al
","['al']
","[] 
",0
"[26] discussed the instance-based learning classifiers.
","[']', 'instance-based learning classifiers']
","['discussed'] 
",0
"k-Nearest-Neighbor (kNN) classification  is one of the most
","['k-Nearest-Neighbor', 'kNN', 'classification']
","[] 
",0
"widely used method for a classification of objects when there is
","['method classification objects']
","['widely used'] 
",0
"little or no prior knowledge about the distribution of the data.
","['little prior knowledge distribution data']
","[] 
",0
"kNN is a good choice to perform discriminate analysis when
","['good choice perform discriminate analysis']
","[] 
",0
"reliable parametric estimates of probability densities are
","['reliable parametric estimates probability densities']
","[] 
",0
"unknown or difficult to determine[27].
","['unknown difficult determine', ']']
","[] 
",0
"kNN is a example of supervised learning algorithm  in which
","['kNN example', 'algorithm']
","['supervised learning'] 
",0
"the result of new instance query is classified based on majority
","['new instance query', 'majority']
","['result', 'classified based'] 
",1
"of k-nearest neighbor category.
","['k-nearest neighbor category']
","[] 
",0
"The core function of algorithm is
","['The core function algorithm']
","[] 
",0
"to classify a new object based on attributes and training samples.
","['new object', 'samples']
","['classify', 'based attributes training'] 
",1
"Here the classification is using majority vote among the
","['classification', 'majority vote']
","['using'] 
",0
"classification of the k objects.
","['classification k objects']
","[] 
",0
"For example we have conducted a
","['example']
","['conducted'] 
",0
"survey on consumption of any particular item to know it’s worth
","['survey consumption', 'particular item', 'worth']
","['know'] 
",0
"in the market.
","['market']
","[] 
",0
"Below is a sample training table.
","['sample training table']
","[] 
",0
"Table.3.
","['Table.3']
","[] 
",0
"Training sample
","['sample']
","['Training'] 
",0
"X1 X2 Result
","['X1 X2 Result']
","[] 
",0
"8 8 NO
","['NO']
","[] 
",0
"8 5 NO
","['NO']
","[] 
",0
"4 5 Yes
","['Yes']
","[] 
",0
"1 5 Yes
","['Yes']
","[] 
",0
"The outcome “Yes” or “No” is depended on the variable
","['The outcome “ Yes ” “ No ”']
","['depended'] 
",0
"values of X1 and X2, so if we want to know the outcome of that
","['values X1 X2', 'know outcome']
","['want'] 
",0
"combination which is not available in data table, for example,
","['combination', 'available data table', 'example']
","[] 
",0
"when  x1 = 4, and x2 = 8 then without doing lengthy exercise of
","['x1 =', 'x2 =', 'lengthy exercise']
","[] 
",0
"conducting surveys, we can predict the results by using kNN
","['surveys', 'results', 'kNN']
","['conducting', 'predict', 'using'] 
",1
"classification method.
","['classification method']
","[] 
",0
"The below pseudo code is an example for the instance base
","['The pseudo code example instance base']
","[] 
",0
"learning methods.
","['methods']
","['learning'] 
",0
"Fig.9.
","['Fig.9']
","[] 
",0
"Pseudo-code for instance-based learners
","['Pseudo-code instance-based learners']
","[] 
",0
"6.
","[]
","[] 
",0
"SUPPORT VECTOR MACHINES
","['SUPPORT VECTOR MACHINES']
","[] 
",0
"Support Vector Machines (SVMs) are a set of supervised
","['Support Vector Machines', 'SVMs']
","['set supervised'] 
",0
"learning methods which have been used for classification,
","['methods', 'classification']
","['learning', 'used'] 
",1
"regression and outlier’s detection.
","['regression', '’ detection']
","[] 
",0
"There are number of benefits
","['number benefits']
","[] 
",0
"for using SVM such as: i) It is effective is high dimensional
","['SVM', 'effective high dimensional']
","['using'] 
",0
"space, ii) Uses a subset of training points in the decision function
","['space', 'ii', 'subset training points decision function']
","['Uses'] 
",0
"(called support vectors), so it is also memory efficient, iii) It is
","['support vectors', 'memory efficient', 'iii']
","['called'] 
",0
"versatile because holds different kernel functions can be
","['different kernel functions']
","['holds'] 
",0
"specified for the decision function.
","['decision function']
","['specified'] 
",0
"Common kernels are
","['Common kernels']
","[] 
",0
"provided, but it is also possible to specify custom kernels.
","['possible specify custom kernels']
","['provided'] 
",0
"Most real-world problems involve non-separable data for
","['real-world problems', 'non-separable data']
","['involve'] 
",0
"which no hyperplane exists that successfully separates the
","['hyperplane', 'separates']
","['exists'] 
",0
"positive from negative instances in the training set.
","['positive negative instances', 'set']
","['training'] 
",0
"One good
","[]
","[] 
",0
"solution to this inseparability problem is to map the data onto a
","['solution inseparability problem map data']
","[] 
",0
"higher dimensional space and define a separating hyperplane
","['dimensional space define', 'hyperplane']
","['separating'] 
",0
"there.
","[]
","[] 
",0
"This higher-dimensional space is called the transformed
","['This higher-dimensional space']
","['called transformed'] 
",0
"feature space, as opposed to the input space occupied by the
","['feature space', 'input space']
","['opposed', 'occupied'] 
",1
"training instances [1].
","['training instances', ']']
","['['] 
",0
"Fig.10.
","['Fig.10']
","[] 
",0
"Maximum margin through SVM
","['Maximum margin SVM']
","[] 
",0
"In order to get better results the selection of an appropriate
","['order', 'results selection']
","['get', 'appropriate'] 
",1
"kernel function is important, since the kernel function defines
","['kernel function', 'kernel function defines']
","[] 
",0
"the transformed feature space in which the training set instances
","['transformed feature space training', 'instances']
","['set'] 
",0
"Procedure InstanceBaseLearner (Testing Instances)
","['Procedure InstanceBaseLearner', 'Testing Instances']
","[] 
",0
"   for each testing instance
","['instance']
","['testing'] 
",0
"   {
","[]
","[] 
",0
"find the k most nearest instances of the
","['instances']
","['find'] 
",0
"training set according to a distance metric
","['training', 'distance']
","['set according'] 
",0
"     Resulting Class: most frequent class
","['Class', 'frequent class']
","['Resulting'] 
",0
"     label of the k nearest instances
","['label k', 'instances']
","[] 
",0
"   }
","[]
","[] 
",0
"Initialize an Empty Bayesian Network G containing n
","['Initialize Empty Bayesian Network G', 'n']
","['containing'] 
",0
"nodes (i.e.-, a BN with n nodes but no edges)
","['nodes', 'BN', 'nodes edges']
","[] 
",0
"1) Evaluate the score of G: Score (G)   2) G’ = G   3) for i = 1 to n do   4) for j = 1 to n do   5) if i • j then   6) if there is no edge between the nodes i and
","['Evaluate score G', 'Score', 'G', 'G ’ = G', 'j', '•', 'edge nodes']
","['='] 
",0
"j in G• then
","['j G•']
","[] 
",0
"7) Modify G’ by adding an edge between  the nodes i and j in G• such that i is a
","['Modify G ’', 'edge nodes', 'G•']
","['adding', 'j'] 
",1
"parent of j: (i • j)
","['parent j', '• j']
","[] 
",0
"8) if the resulting G’ is a DAG then   9) if (Score(G’) > Score (G)) then   10) G = G’   11) end if   12) end if   13) end if   14) end if   15) G’ = G   16) end for
","['G ’ DAG', 'Score', 'G ’', 'Score', 'G', 'G = G ’', 'G ’ = G', 'end']
","['resulting', '>', 'end', 'end', 'end', 'end'] 
",1
"17) end for
","['end']
","[] 
",0
"f(x)
","['f', 'x']
","[] 
",0
"ISSN: 2229-6956(ONLINE)                                                                                                                             ICTACT JOURNAL ON SOFT COMPUTING, APRIL 2015, VOLUME: 05, ISSUE: 03
","['ISSN', 'ONLINE', 'ICTACT JOURNAL ON SOFT COMPUTING', 'APRIL', 'VOLUME', 'ISSUE']
","[] 
",0
"951
","[]
","[] 
",0
"will be classified.
","[]
","['classified'] 
",0
"Some new kernels are being proposed by
","['Some new kernels']
","['proposed'] 
",0
"researchers but given bellow is list of some popular kernels:
","['researchers', 'bellow list', 'popular kernels']
","['given'] 
",0
" Linear:   j T iji XXXXK ,
","['\uf0b7 Linear', '\uf028 \uf029 j T iji XXXXK \uf03d']
","[] 
",0
" Polynomial:     0,,   djTiji rXXXXK    Radial Basis Function (RBF):
","['\uf0b7 Polynomial', '\uf028 \uf029 \uf028 \uf029', '\uf03e\uf02b\uf03d \uf067\uf067 djTiji rXXXXK \uf0b7 Radial Basis Function', 'RBF']
","[] 
",0
"  0,exp, 2
","['\uf028 \uf029', 'exp']
","[] 
",0
" 
","['\uf03e\uf0f7 \uf0f8']
","[] 
",0
"  
","['\uf0f6 \uf0e7 \uf0e8']
","[] 
",0
"   jiji XXXXK
","['\uf0e6 \uf02d\uf02d\uf03d \uf067\uf067 jiji XXXXK']
","[] 
",0
" Sigmoid:    rXXXXK jTiji  tanh,   Here dr  and ,  are the kernel parameters.
","['\uf0b7 Sigmoid', '\uf028 \uf029 \uf028 \uf029rXXXXK jTiji \uf02b\uf03d \uf067tanh', 'dr', '\uf067 kernel parameters']
","[] 
",0
"Where, iX is a
","[]
","['iX'] 
",0
"training vector and mapped into a high dimensional space by the  function  and    jji XXXK ,  is known as kernel function.
","['vector', 'high dimensional space function \uf066 \uf028 \uf029 \uf028 \uf029jji XXXK \uf066\uf0ba', 'kernel function']
","['training', 'mapped', 'known'] 
",1
"7.
","[]
","[] 
",0
"DEEP LEARNING
","['DEEP LEARNING']
","[] 
",0
"The use of deep artificial neural networks has gain popularity
","['The use', 'deep artificial neural networks', 'popularity']
","['gain'] 
",0
"for the last few years in pattern recognition and machine
","['last years', 'pattern recognition machine']
","[] 
",0
"learning.
","['learning']
","[] 
",0
"Most of the popular Deep Learning Techniques are
","['popular Deep Learning Techniques']
","[] 
",0
"built from Artificial Neural Network (ANN).
","['Artificial Neural Network', 'ANN']
","['built'] 
",0
"Deep learning can
","['Deep learning']
","[] 
",0
"be defined as a model (e.g.-, neural network) with many layers,
","['model', 'neural network', 'many layers']
","['defined'] 
",0
"trained in a layer- wise fashion.
","['layer- wise fashion']
","['trained'] 
",0
"Deep learning has had a
","['Deep learning']
","[] 
",0
"tremendous impact on various applications such as computer
","['tremendous impact', 'various applications computer']
","[] 
",0
"vision, speech recognition, natural language processing [29], and
","['vision', 'speech recognition', 'natural language processing', ']']
","[] 
",0
"crawling deep web [30].
","['deep web', ']']
","['crawling', '['] 
",1
"Samy et al.
","['Samy', 'al']
","[] 
",0
"[29] have discussed
","[']']
","['discussed'] 
",0
"challenges and new applications of deep learning in their study.
","['challenges', 'new applications', 'study']
","['deep learning'] 
",0
"Fig.11.
","['Fig.11']
","[] 
",0
"Deep network Architecture
","['Deep network Architecture']
","[] 
",0
"The Fig.11 depicts the deep learning network architecture
","['The Fig.11', 'deep learning network architecture']
","['depicts'] 
",0
"with one 3-unit input layer, one 2-unit output layer, and two 5-
","['3-unit input layer', '2-unit output layer']
","[] 
",0
"unit hidden layers.
","['unit', 'hidden layers']
","[] 
",0
"Deep learning has also been successfully implemented in
","['Deep learning']
","['also successfully implemented'] 
",0
"industry products that ultimately take advantage of the large
","['industry products', 'advantage']
","['ultimately take'] 
",0
"volume of data.
","['volume data']
","[] 
",0
"Top Information Technology (IT) companies
","['Top Information Technology', 'IT', 'companies']
","[] 
",0
"like Microsoft, Google, Apple, Yahoo, Baidu, Amazon and
","['Microsoft', 'Google', 'Apple', 'Yahoo', 'Baidu', 'Amazon']
","[] 
",0
"Facebook, who collect and analyze massive amounts of data on a
","['Facebook', 'analyze massive amounts data']
","['collect'] 
",0
"daily basis, have been investing a good share on finances on
","['daily basis', 'good share finances']
","['investing'] 
",0
"deep learning related projects.
","['deep learning', 'related projects']
","[] 
",0
"For example, Apple's Siri and
","['example', 'Apple', 'Siri']
","[] 
",0
"Google Voice Search offer a wide variety of services including
","['Google Voice Search offer', 'wide variety services']
","['including'] 
",0
"weather reports, sport news, answers to user’s questions, and
","['weather reports', 'sport news', 'answers', '’ questions']
","['user'] 
",0
"reminders etc., by utilizing deep learning algorithms [31].
","['reminders', 'utilizing deep learning', ']']
","['etc.'] 
",0
"Currently, these two applications support wide range spoken
","['applications support', 'wide range spoken']
","[] 
",0
"languages.
","['languages']
","[] 
",0
"Table.4.
","['Table.4']
","[] 
",0
"Large scale deep learning research progress
","['Large scale', 'deep learning research progress']
","[] 
",0
"Method Computing power  # of examples and
","['Method Computing power', 'examples']
","[] 
",0
"parameters
","['parameters']
","[] 
",0
"Average
","[]
","[] 
",0
"running
","[]
","['running'] 
",0
"Time
","['Time']
","[] 
",0
"DBN [32]  NVIDIA GTX 280
","['DBN', '] NVIDIA GTX']
","['['] 
",0
"GPU (1 GB RAM)
","['GPU', 'GB RAM']
","[] 
",0
"1million images and
","['images']
","[] 
",0
"1006 parameters  ~ 1 day
","['parameters', 'day']
","['~'] 
",0
"CNN [33]  Two GTX 580
","['CNN', 'GTX']
","['['] 
",0
"GPUs( 6 GB RAM)
","['GPUs', 'GB RAM']
","[] 
",0
"1.2 million high  resolution (256 × 256)
","['high resolution']
","[] 
",0
"images and 606
","['images']
","[] 
",0
"parameters
","['parameters']
","[] 
",0
"~ 5-6 days
","['~ 5-6 days']
","[] 
",0
"DisBelief [34]
","['DisBelief', ']']
","['['] 
",0
"1000 CPUs with
","['CPUs']
","[] 
",0
"Downpour SGD with
","['Downpour SGD']
","[] 
",0
"Adagrad
","['Adagrad']
","[] 
",0
"1.1 billion audio
","['audio']
","[] 
",0
"examples with 42 million
","['examples']
","[] 
",0
"parameters
","['parameters']
","[] 
",0
"~ 16 hours
","['hours']
","[] 
",0
"Sparse  Autoencoder
","['Sparse Autoencoder']
","[] 
",0
"[35]
","[']']
","[] 
",0
"1000 CPUs with
","['CPUs']
","[] 
",0
"16,000 core
","['core']
","[] 
",0
"10 million (200 × 200 )  Images and 1 billion
","[]
","['Images'] 
",0
"parameters
","['parameters']
","[] 
",0
"~ 3Days
","[]
","[] 
",0
"COTS HPC
","['COTS HPC']
","[] 
",0
"[36]
","[']']
","[] 
",0
"64 NVIDIA GTX  680 GPUs
","['NVIDIA GTX', 'GPUs']
","[] 
",0
"(256 GB RAM)
","['GB RAM']
","[] 
",0
"10 million (200 × 200 )  Images and 11 billion
","[]
","['Images'] 
",0
"parameters
","['parameters']
","[] 
",0
"~ 3Days
","[]
","[] 
",0
"The Table.4 summarizes the current progress in deep
","['The Table.4', 'current progress deep']
","['summarizes'] 
",0
"learning algorithms.
","['algorithms']
","['learning'] 
",0
"It has been observed that different deep
","['different deep']
","['observed'] 
",0
"learning technologies [32-36] required huge computational
","['technologies', '32-36 ]', 'huge computational']
","['learning', '[', 'required'] 
",1
"resources to achieve significant results.
","['resources', 'significant results']
","['achieve'] 
",0
"8.
","[]
","[] 
",0
"CONCLUSION
","['CONCLUSION']
","[] 
",0
"Supervised machine learning methods are being applied in
","['machine', 'methods']
","['Supervised', 'learning', 'applied'] 
",1
"different domains.
","['different domains']
","[] 
",0
"Due to scope of this paper, it is very difficult to
","['Due scope paper']
","[] 
",0
"discuss the strength and weaknesses of each algorithm of ML.
","['discuss strength weaknesses', 'ML']
","['algorithm'] 
",0
"The
","[]
","[] 
",0
"selection of algorithm in ML is mainly depends on task nature.
","['selection', 'ML', 'task nature']
","['algorithm', 'mainly depends'] 
",1
"The
","[]
","[] 
",0
"performance of SVM and Neural Networks is better when dealing
","['performance SVM Neural Networks']
","['better dealing'] 
",0
"with multidimensions and continuous features.
","['multidimensions', 'continuous features']
","[] 
",0
"While logic-based
","[]
","[] 
",0
"systems tend to perform better when dealing with
","['systems']
","['tend perform', 'dealing'] 
",1
"discrete/categorical features.
","['discrete/categorical features']
","[] 
",0
"For neural network models and SVMs,
","['neural network models SVMs']
","[] 
",0
"a large sample size is required in order to achieve its maximum
","['large sample size', 'order achieve maximum']
","['required'] 
",0
"prediction accuracy whereas NB may need a relatively small
","['prediction accuracy', 'NB']
","['need'] 
",0
"dataset.
","['dataset']
","[] 
",0
"For the last few years deep learning is becoming a
","['last years']
","['deep learning becoming'] 
",0
"mainstream technology for variety of application domains, like face
","['mainstream technology variety application domains', 'face']
","[] 
",0
"detection, speech recognition and detection, object recognition,
","['detection', 'speech recognition detection', 'object recognition']
","[] 
",0
"natural language processing and robotics.
","['natural language processing robotics']
","[] 
",0
"We believe that the
","[]
","['believe'] 
",0
"challenges posed by big data will bring ample opportunities for ML
","['challenges', 'big data', 'ample opportunities ML']
","['posed', 'bring'] 
",1
"algorithms and especially to deep learning methods.
","['algorithms', 'methods']
","['learning'] 
",0
"ACKNOWLEDGEMENT
","['ACKNOWLEDGEMENT']
","[] 
",0
"I would like to express my gratitude to my teacher, Dr. Wang
","['express gratitude teacher', 'Dr. Wang']
","['like'] 
",0
"Hongjun, whose expertise and guidance added considerably to
","['Hongjun', 'expertise guidance']
","['added'] 
",0
"my graduate experience.
","['graduate experience']
","[] 
",0
"I appreciate his vast knowledge and his
","['vast knowledge']
","['appreciate'] 
",0
"consistent assistance in completing this work.
","['consistent assistance', 'work']
","['completing'] 
",0
"I would also like
","[]
","['also like'] 
",0
"to thank the other PhD Scholars of my school, Mr. Amjad
","['thank PhD Scholars school', 'Mr. Amjad']
","[] 
",0
"Ahmed, and Mr. Mehtab Afzal for the assistance they provided
","['Ahmed', 'Mr. Mehtab Afzal assistance']
","['provided'] 
",0
"to understand machine learning.
","['understand machine learning']
","[] 
",0
"Very special thanks goes to Dr.
","['special thanks', 'Dr']
","['goes'] 
",0
"Zhu Yan, without whose motivation and encouragement, I
","['Zhu Yan', 'motivation encouragement']
","[] 
",0
"confess that it would be difficult for me to move forward in my
","['confess']
","['move'] 
",0
"PhD Program.
","['PhD Program']
","[] 
",0
"REFERENCES
","['REFERENCES']
","[] 
",0
"[1] S. B. Kotsiantis, “Supervised Machine Learning: A Review  of Classification Techniques”, Informatica, Vol.
","['] S. B. Kotsiantis', '“', 'Machine Learning', 'A Review Classification Techniques ”', 'Informatica', 'Vol']
","['Supervised'] 
",0
"31, No.
","[]
","[] 
",0
"3,
","[]
","[] 
",0
"pp.
","['pp']
","[] 
",0
"249-268, 2007.
","[]
","[] 
",0
"IQBAL MUHAMMAD AND ZHU YAN: SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY
","['IQBAL MUHAMMAD AND ZHU YAN', 'SUPERVISED MACHINE LEARNING APPROACHES', 'A SURVEY']
","[] 
",0
"952
","[]
","[] 
",0
"[2] James Cussens, “Machine Learning”, IEEE Journal of  Computing and Control, Vol.
","['] James Cussens', '“ Machine Learning ”', 'IEEE Journal Computing Control', 'Vol']
","[] 
",0
"7, No.
","[]
","[] 
",0
"4, pp 164-168, 1996.
","[]
","[] 
",0
"[3] Richard S. Sutton and Andrew G. Barto, “Reinforcement  Learning: An Introduction”, Cambridge, MA: MIT Press, 1998.
","['] Richard S. Sutton Andrew G. Barto', '“ Reinforcement Learning', 'An Introduction ”', 'Cambridge', 'MA', 'MIT Press']
","[] 
",0
"[4] Victoria J. Hodge and Jim Austin, “A Survey of Outlier  Detection Methodologies”, Artificial Intelligence Review,
","['] Victoria J. Hodge Jim Austin', 'A Survey Outlier Detection Methodologies ”', 'Artificial Intelligence Review']
","['“'] 
",0
"Vol.
","['Vol']
","[] 
",0
"22, No.
","[]
","[] 
",0
"2, pp.
","['pp']
","[] 
",0
"85-126, 2004.
","[]
","[] 
",0
"[5] Karanjit Singh and Shuchita Upadhyaya, “Outlier Detection:  Applications and Techniques”, International Journal of Computer
","['] Karanjit Singh Shuchita Upadhyaya', '“ Outlier Detection', 'Applications Techniques ”', 'International Journal Computer']
","[] 
",0
"Science Issues, Vol.
","['Science Issues', 'Vol']
","[] 
",0
"9, Issue.
","['Issue']
","[] 
",0
"1, No.
","[]
","[] 
",0
"3, pp.
","['pp']
","[] 
",0
"307-323, 2012.
","[]
","[] 
",0
"[6] Hugo Jair Escalante, “A Comparison of Outlier Detection  Algorithms for Machine Learning”, CIC-2005 Congreso
","['] Hugo Jair Escalante', 'A Comparison Outlier Detection Algorithms Machine Learning ”', 'CIC-2005 Congreso']
","['“'] 
",0
"Internacional en Computacion-IPN, 2005.
","['Computacion-IPN']
","[] 
",0
"[7] Pierre Geurts, Alexandre Irrthum, Louis Wehenkel,  “Supervised learning with decision tree-based methods in
","['] Pierre Geurts', 'Alexandre Irrthum', 'Louis Wehenkel', '“', 'decision', 'tree-based methods']
","['Supervised learning'] 
",0
"computational and systems biology”, Molecular
","['computational systems biology ”', 'Molecular']
","[] 
",0
"BioSystems, Vol.
","['BioSystems', 'Vol']
","[] 
",0
"5, No.
","[]
","[] 
",0
"12, pp.
","['pp']
","[] 
",0
"1593-1605, 2009.
","[]
","[] 
",0
"[8] L. Breiman, J. Friedman, R. A. Olsen and C. J.
","['] L. Breiman', 'J. Friedman', 'R. A. Olsen C. J']
","[] 
",0
"Stone,  “Classification and Regression Trees”, Belmont,
","['Stone', '“ Classification Regression Trees ”', 'Belmont']
","[] 
",0
"California: Wadsworth International Group, 1984.
","['California', 'Wadsworth International Group']
","[] 
",0
"[9] J. Quinlan, “C4.5: Programs for machine learning”, San  Francisco, CA: Morgan Kaufmann, 1986.
","['] J. Quinlan', '“ C4.5', 'Programs machine', '”', 'San Francisco', 'CA', 'Morgan Kaufmann']
","['learning'] 
",0
"[10] Masud Karim and Rashedur M. Rahman, “Decision Tree  and Naïve Bayes Algorithm for Classification and
","['] Masud Karim Rashedur M. Rahman', '“ Decision Tree Naïve Bayes Algorithm Classification']
","[] 
",0
"Generation of Actionable Knowledge for Direct
","['Generation Actionable Knowledge Direct']
","[] 
",0
"Marketing”, Journal of Software Engineering and
","['”', 'Journal Software Engineering']
","['Marketing'] 
",0
"Applications, Vol.
","['Applications', 'Vol']
","[] 
",0
"6, No.
","[]
","[] 
",0
"4, pp.
","['pp']
","[] 
",0
"196-206, 2013.
","[]
","[] 
",0
"[11] Earl B.
","['] Earl B']
","[] 
",0
"Hunt, Janet Marin and Philip J.
","['Hunt', 'Janet Marin Philip J']
","[] 
",0
"Stone, “Experiments  in Induction”, New York: Academic Press, 1966.
","['Stone', 'Induction ”', 'New York', 'Academic Press']
","[] 
",0
"[12] Leo Breiman, Jerome Friedman, Charles J.
","['] Leo Breiman', 'Jerome Friedman', 'Charles J']
","[] 
",0
"Stone and R. A.  Olshen, “Classification and Regression Trees (Wadsworth
","['Stone R. A. Olshen', '“ Classification Regression Trees', 'Wadsworth']
","[] 
",0
"Statistics/Probability)”, Chapman and Hall/CRC, 1984.
","['Statistics/Probability', '”', 'Chapman Hall/CRC']
","[] 
",0
"[13] Steven L. Salzberg, “Book Review: C4.5: Programs for  Machine Learning by J. Ross Quinlan.
","['] Steven L. Salzberg', '“ Book Review', 'C4.5', 'Programs Machine Learning J. Ross Quinlan']
","[] 
",0
"Inc., 1993”,
","['Inc.', '”']
","[] 
",0
"Machine Learning, Vol.
","['Machine Learning', 'Vol']
","[] 
",0
"16, No.
","[]
","[] 
",0
"3, pp.
","['pp']
","[] 
",0
"235-240, 1994.
","[]
","[] 
",0
"[14] Johannes Fürnkranz, “Separate-and-Conquer Rule Learning”,  Artificial Intelligence Review, Vol.
","['Fürnkranz', '“ Separate-and-Conquer Rule Learning ”', 'Artificial Intelligence Review', 'Vol']
","[] 
",0
"13, pp.
","['pp']
","[] 
",0
"3-54, 1999.
","[]
","[] 
",0
"[15] Aijun An and Nick Cercone, “Discretization of continuous  attributes for learning classification rules”, Third Pacific-
","['] Aijun', 'An Nick Cercone', '“ Discretization', 'continuous attributes', 'classification rules', 'Third Pacific-']
","['learning', '”'] 
",1
"Asia Conference on Methodologies for Knowledge
","['Asia Conference Methodologies Knowledge']
","[] 
",0
"Discovery & Data Mining, Vol.
","['Discovery', 'Data Mining', 'Vol']
","[] 
",0
"1574, pp.
","['pp']
","[] 
",0
"509-514, 1999.
","[]
","[] 
",0
"[16] Mehryar Mohri, Afshin Rostamizadeh and Ameet  Talwalkar, “Foundations of Machine Learning”, One
","['] Mehryar Mohri', 'Afshin Rostamizadeh Ameet Talwalkar', '“ Foundations Machine Learning ”']
","[] 
",0
"Rogers Street Cambridge MA: The MIT Press, 2012.
","['Rogers Street Cambridge MA', 'The MIT Press']
","[] 
",0
"[17] Olivier Bousquet, St´ephane Boucheron and G´abor  Lugosi, “Introduction to Statistical Learning Theory”,
","['] Olivier Bousquet', 'St´ephane Boucheron G´abor Lugosi', '“ Introduction Statistical Learning Theory ”']
","[] 
",0
"Lecture Notes in Computer Science, Vol.
","['Lecture', 'Computer Science', 'Vol']
","['Notes'] 
",0
"3176, pp.
","['pp']
","[] 
",0
"175-
","[]
","[] 
",0
"213, 2004.
","[]
","[] 
",0
"[18] Olivier Pourret, Patrick Naim and Bruce Marcot, “Bayesian  Networks: A Practical Guide to Applications”, Wiley
","['] Olivier Pourret', 'Patrick Naim Bruce Marcot', '“ Bayesian Networks', 'A Practical Guide Applications ”', 'Wiley']
","[] 
",0
"Publishers, 2008.
","['Publishers']
","[] 
",0
"[19] Kamal Nigam, John Lafferty and Andrew McCallum,  “Using Maximum Entropy for Text Classification”,
","['] Kamal Nigam', 'John Lafferty Andrew McCallum', '“ Using Maximum Entropy Text Classification ”']
","[] 
",0
"Workshop on Machine Learning for Information Filtering,
","['Workshop Machine Learning Information Filtering']
","[] 
",0
"pp.
","['pp']
","[] 
",0
"61-67, 1999.
","[]
","[] 
",0
"[20] N. J. Nilsson, “Learning Machines: Foundations of  Trainable Pattern-Classifying Systems”, First Edition, New
","['] N. J. Nilsson', '“ Learning Machines', 'Foundations', '”', 'First Edition', 'New']
","[] 
",0
"York: McGraw-Hill, 1965.
","['York', 'McGraw-Hill']
","[] 
",0
"[21] Isidore Jacob Good, “Probability and the Weighing of  Evidence”, The University of Wisconsin - Madison:
","['] Isidore Jacob Good', '“ Probability Weighing Evidence ”', 'The University Wisconsin', 'Madison']
","[] 
",0
"Charles Griffin, 1950.
","['Charles Griffin']
","[] 
",0
"[22] Shiliang Sun, Changshui Zhang and Guoqiang Yu, “A  Bayesian Network Approach to Traffic Flow Forecasting”,
","['] Shiliang Sun', 'Changshui Zhang Guoqiang Yu', 'A Bayesian Network Approach Traffic Flow Forecasting ”']
","['“'] 
",0
"IEEE Transactions on Intelligent Transportation Systems,
","['IEEE Transactions Intelligent Transportation Systems']
","[] 
",0
"Vol.
","['Vol']
","[] 
",0
"7, No.
","[]
","[] 
",0
"1, pp.
","['pp']
","[] 
",0
"124-132, 2006.
","[]
","[] 
",0
"[23] Jie Cheng, Russell Greiner, Jonathan Kelly, David Bell and  Weiru Liu, “Learning Bayesian networks from data: An
","['] Jie Cheng', 'Russell Greiner', 'Jonathan Kelly', 'David Bell Weiru Liu', '“ Learning Bayesian networks data']
","[] 
",0
"information-Theory based approach”, The Artificial
","['information-Theory', 'approach ”', 'The Artificial']
","['based'] 
",0
"Intelligence Journal, Vol.
","['Intelligence Journal', 'Vol']
","[] 
",0
"137, pp.
","['pp']
","[] 
",0
"43-90, 2002.
","[]
","[] 
",0
"[24] Tom M. Mitchell, “Machine Learning: A Guide to Current  Research”, The Springer International Series in Engineering
","['] Tom M. Mitchell', '“ Machine Learning', 'A Guide Current Research ”', 'The Springer International Series Engineering']
","[] 
",0
"and Computer Science Series, McGraw Hill, 1997.
","['Computer Science Series', 'McGraw Hill']
","[] 
",0
"[25] D. Aha, “Lazy Learning”, Dordrecht: Kluwer Academic  Publishers, 1997.
","['] D. Aha', '“ Lazy Learning ”', 'Dordrecht', 'Kluwer Academic Publishers']
","[] 
",0
"[26] Ramon Lopez De Mantaras and Eva Armengol, “Machine  learning from examples: Inductive and Lazy methods”, Data and
","['] Ramon Lopez De Mantaras Eva Armengol', '“ Machine', 'examples', 'Inductive Lazy methods ”', 'Data']
","['learning'] 
",0
"Knowledge Engineering, Vol.
","['Knowledge Engineering', 'Vol']
","[] 
",0
"25, No.
","[]
","[] 
",0
"1-2, pp.
","['pp']
","[] 
",0
"99-123, 1998.
","[]
","[] 
",0
"[27] Hamid Parvin, Hoseinali Alizadeh and Behrouz Minati, “A  Modification on K-Nearest Neighbor Classifier”, Global
","['] Hamid Parvin', 'Hoseinali Alizadeh Behrouz Minati', 'A Modification K-Nearest Neighbor Classifier ”', 'Global']
","['“'] 
",0
"Journal of Computer Science and Technology, Vol.
","['Journal Computer Science Technology', 'Vol']
","[] 
",0
"10, No.
","[]
","[] 
",0
"14 (Ver.1.0), pp.
","['Ver.1.0', 'pp']
","[] 
",0
"37-41, 2010.
","[]
","[] 
",0
"[28] Yen-Liang Chen and Lucas Tzu-Hsuan Hung, “Using  decision trees to summarize associative classification
","['] Yen-Liang Chen Lucas Tzu-Hsuan Hung', '“ Using decision trees', 'associative classification']
","['summarize'] 
",0
"rules”, Expert Systems with Applications, Vol.
","['rules', 'Expert Systems Applications', 'Vol']
","['”'] 
",0
"36, No.
","[]
","[] 
",0
"2,
","[]
","[] 
",0
"Part 1, pp.
","['Part', 'pp']
","[] 
",0
"2338-2351, 2009.
","[]
","[] 
",0
"[29] Samy Bengio, Li Deng, Hugo Larochelle, Honglak Lee, and  Ruslan Salakhutdinov, “Guest Editors’ Introduction: Special
","['] Samy Bengio', 'Li Deng', 'Hugo Larochelle', 'Honglak Lee', 'Ruslan Salakhutdinov', '“ Guest', '’ Introduction']
","[] 
",0
"Section on Learning Deep Architectures”, IEEE
","['Section Learning Deep Architectures ”', 'IEEE']
","[] 
",0
"Transactions on   Pattern Analysis and Machine
","['Transactions Pattern Analysis Machine']
","[] 
",0
"Intelligence, Vol.
","['Intelligence', 'Vol']
","[] 
",0
"35, No.
","[]
","[] 
",0
"8, pp.
","['pp']
","[] 
",0
"1795-1797, 2013.
","[]
","[] 
",0
"[30] Qinghua Zheng, Zhaohui Wu, Xiaocheng Cheng, Lu Jiang  and Jun Liu, “Learning to crawl deep web”, Information
","['] Qinghua Zheng', 'Zhaohui Wu', 'Xiaocheng Cheng', 'Lu Jiang Jun Liu', '“ Learning', 'crawl deep web ”', 'Information']
","[] 
",0
"Systems, Vol.
","['Systems', 'Vol']
","[] 
",0
"38, No.
","[]
","[] 
",0
"6, pp.
","['pp']
","[] 
",0
"801-819, 2013.
","[]
","[] 
",0
"[31] Xue-Wen Chen and Xiaotong Lin,” Big Data Deep  Learning: Challenges and Perspectives”, IEEE Access
","['] Xue-Wen Chen Xiaotong Lin', '” Big Data Deep Learning', 'Perspectives ”', 'IEEE Access']
","['Challenges'] 
",0
"Practical Innovations: Open Solutions and Access and
","['Practical Innovations', 'Open Solutions Access']
","[] 
",0
"IEEE, Vol.
","['IEEE', 'Vol']
","[] 
",0
"2, pp.
","['pp']
","[] 
",0
"514-525, 2014.
","[]
","[] 
",0
"[32] Rajat Raina, Anand Madhavan and Andrew Yg, “Large- scale Deep Unsupervised Learning using Graphics
","['] Rajat Raina', 'Anand Madhavan Andrew Yg', '“ Large- scale Deep', 'Learning', 'Graphics']
","['Unsupervised', 'using'] 
",1
"Processors”, 26 th  International Conference on Machine
","['Processors', 'th International Conference Machine']
","['”'] 
",0
"Learning, pp.
","['Learning', 'pp']
","[] 
",0
"609-616, 2009.
","[]
","[] 
",0
"[33] Alex Krizhevsky, Ilya Sutskever and Geoffrey E. Hinton,  “ImageNet Classification with Deep Convolutional Neural
","['] Alex Krizhevsky', 'Ilya Sutskever Geoffrey E. Hinton', '“ ImageNet Classification Deep Convolutional Neural']
","[] 
",0
"Networks”, Advances in Neural Information Processing
","['Networks', 'Advances Neural Information Processing']
","['”'] 
",0
"System, pp.
","['System', 'pp']
","[] 
",0
"1106-1114, 2012.
","[]
","[] 
",0
"[34] Jeffrey Dean, Greg S. Corrado and Rajat Monga Kai, “Large  Scale Distributed Deep Networks”, Advances in Neural
","['] Jeffrey Dean', 'Greg S. Corrado Rajat Monga Kai', '“ Large Scale Distributed Deep Networks ”', 'Advances Neural']
","[] 
",0
"Information Processing System, pp.
","['Information Processing System', 'pp']
","[] 
",0
"1232-1240, 2012.
","[]
","[] 
",0
"[35] Quoc V. Le, Marc’Aurelio Ranzato, Rajat Monga, Matthieu  Devin, Kai Chen, Greg S. Corrado, Jeffrey  Dean, and
","['] Quoc V. Le', 'Marc ’ Aurelio Ranzato', 'Rajat Monga', 'Matthieu Devin', 'Kai Chen', 'Greg S. Corrado', 'Jeffrey Dean']
","[] 
",0
"Andrew Y. Ng, “Building High-level Features Using Large
","['Andrew Y. Ng', '“ Building High-level Features Using Large']
","[] 
",0
"Scale Unsupervised Learning”, Proceedings of the 29 th
","['Scale', 'Learning ”', 'Proceedings', 'th']
","['Unsupervised'] 
",0
"International Conference on Machine Learning, 2012.
","['International Conference Machine Learning']
","[] 
",0
"[36] A. Coats and B. Huval, “Deep Learning with COTS HPS  systems”, Journal of Machine Learning Research, Vol.
","['] A. Coats B. Huval', '“ Deep Learning COTS HPS systems ”', 'Journal Machine Learning Research', 'Vol']
","[] 
",0
"28,
","[]
","[] 
",0
"No.
","[]
","[] 
",0
"3, pp.
","['pp']
","[] 
",0
"1337-1345, 2013.
","[]
","[] 
",0
